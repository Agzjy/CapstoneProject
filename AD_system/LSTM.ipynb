{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71ad780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import pickle\n",
    "import zstandard as zstd\n",
    "from utils import read_zst\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from LSTMModel import LSTMModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952a0af",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c0d101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize 'AGE' between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "train_X = read_zst('./stored_files/train_x.zst')\n",
    "train_X['AGE'] = scaler.fit_transform(train_X[['AGE']])\n",
    "pickle.dump(scaler, open('./stored_files/age_scaler.pkl', 'wb'))\n",
    "train_y = read_zst('./stored_files/train_y.zst')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede854e",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c985eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 518  # number of features\n",
    "hidden_size = 64\n",
    "output_size = 49  # number of unique diagnoses\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMModel(input_size, hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49167d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrays to PyTorch tensors and move them to the specified device\n",
    "X_train_tensor = torch.tensor(train_X.values, dtype=torch.float).to(device)\n",
    "y_train_tensor = torch.tensor(train_y.values, dtype=torch.long).to(device)\n",
    "# create TensorDataset and DataLoader for batch processing\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
    "# define the loss function and optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40e50b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of eposhes\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7f80280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Average Loss: 0.1056\n",
      "Saved better model with Average Loss: 0.1056\n",
      "Epoch [2/100], Average Loss: 0.0587\n",
      "Saved better model with Average Loss: 0.0587\n",
      "Epoch [3/100], Average Loss: 0.0515\n",
      "Saved better model with Average Loss: 0.0515\n",
      "Epoch [4/100], Average Loss: 0.0481\n",
      "Saved better model with Average Loss: 0.0481\n",
      "Epoch [5/100], Average Loss: 0.0459\n",
      "Saved better model with Average Loss: 0.0459\n",
      "Epoch [6/100], Average Loss: 0.0444\n",
      "Saved better model with Average Loss: 0.0444\n",
      "Epoch [7/100], Average Loss: 0.0433\n",
      "Saved better model with Average Loss: 0.0433\n",
      "Epoch [8/100], Average Loss: 0.0424\n",
      "Saved better model with Average Loss: 0.0424\n",
      "Epoch [9/100], Average Loss: 0.0417\n",
      "Saved better model with Average Loss: 0.0417\n",
      "Epoch [10/100], Average Loss: 0.0410\n",
      "Saved better model with Average Loss: 0.0410\n",
      "Epoch [11/100], Average Loss: 0.0405\n",
      "Saved better model with Average Loss: 0.0405\n",
      "Epoch [12/100], Average Loss: 0.0401\n",
      "Saved better model with Average Loss: 0.0401\n",
      "Epoch [13/100], Average Loss: 0.0397\n",
      "Saved better model with Average Loss: 0.0397\n",
      "Epoch [14/100], Average Loss: 0.0394\n",
      "Saved better model with Average Loss: 0.0394\n",
      "Epoch [15/100], Average Loss: 0.0391\n",
      "Saved better model with Average Loss: 0.0391\n",
      "Epoch [16/100], Average Loss: 0.0388\n",
      "Saved better model with Average Loss: 0.0388\n",
      "Epoch [17/100], Average Loss: 0.0386\n",
      "Saved better model with Average Loss: 0.0386\n",
      "Epoch [18/100], Average Loss: 0.0383\n",
      "Saved better model with Average Loss: 0.0383\n",
      "Epoch [19/100], Average Loss: 0.0382\n",
      "Saved better model with Average Loss: 0.0382\n",
      "Epoch [20/100], Average Loss: 0.0379\n",
      "Saved better model with Average Loss: 0.0379\n",
      "Epoch [21/100], Average Loss: 0.0378\n",
      "Saved better model with Average Loss: 0.0378\n",
      "Epoch [22/100], Average Loss: 0.0376\n",
      "Saved better model with Average Loss: 0.0376\n",
      "Epoch [23/100], Average Loss: 0.0375\n",
      "Saved better model with Average Loss: 0.0375\n",
      "Epoch [24/100], Average Loss: 0.0373\n",
      "Saved better model with Average Loss: 0.0373\n",
      "Epoch [25/100], Average Loss: 0.0372\n",
      "Saved better model with Average Loss: 0.0372\n",
      "Epoch [26/100], Average Loss: 0.0370\n",
      "Saved better model with Average Loss: 0.0370\n",
      "Epoch [27/100], Average Loss: 0.0370\n",
      "Saved better model with Average Loss: 0.0370\n",
      "Epoch [28/100], Average Loss: 0.0368\n",
      "Saved better model with Average Loss: 0.0368\n",
      "Epoch [29/100], Average Loss: 0.0367\n",
      "Saved better model with Average Loss: 0.0367\n",
      "Epoch [30/100], Average Loss: 0.0366\n",
      "Saved better model with Average Loss: 0.0366\n",
      "Epoch [31/100], Average Loss: 0.0365\n",
      "Saved better model with Average Loss: 0.0365\n",
      "Epoch [32/100], Average Loss: 0.0364\n",
      "Saved better model with Average Loss: 0.0364\n",
      "Epoch [33/100], Average Loss: 0.0363\n",
      "Saved better model with Average Loss: 0.0363\n",
      "Epoch [34/100], Average Loss: 0.0362\n",
      "Saved better model with Average Loss: 0.0362\n",
      "Epoch [35/100], Average Loss: 0.0361\n",
      "Saved better model with Average Loss: 0.0361\n",
      "Epoch [36/100], Average Loss: 0.0360\n",
      "Saved better model with Average Loss: 0.0360\n",
      "Epoch [37/100], Average Loss: 0.0360\n",
      "Saved better model with Average Loss: 0.0360\n",
      "Epoch [38/100], Average Loss: 0.0359\n",
      "Saved better model with Average Loss: 0.0359\n",
      "Epoch [39/100], Average Loss: 0.0358\n",
      "Saved better model with Average Loss: 0.0358\n",
      "Epoch [40/100], Average Loss: 0.0357\n",
      "Saved better model with Average Loss: 0.0357\n",
      "Epoch [41/100], Average Loss: 0.0357\n",
      "Saved better model with Average Loss: 0.0357\n",
      "Epoch [42/100], Average Loss: 0.0356\n",
      "Saved better model with Average Loss: 0.0356\n",
      "Epoch [43/100], Average Loss: 0.0356\n",
      "Saved better model with Average Loss: 0.0356\n",
      "Epoch [44/100], Average Loss: 0.0355\n",
      "Saved better model with Average Loss: 0.0355\n",
      "Epoch [45/100], Average Loss: 0.0355\n",
      "Saved better model with Average Loss: 0.0355\n",
      "Epoch [46/100], Average Loss: 0.0354\n",
      "Saved better model with Average Loss: 0.0354\n",
      "Epoch [47/100], Average Loss: 0.0354\n",
      "Saved better model with Average Loss: 0.0354\n",
      "Epoch [48/100], Average Loss: 0.0353\n",
      "Saved better model with Average Loss: 0.0353\n",
      "Epoch [49/100], Average Loss: 0.0353\n",
      "Saved better model with Average Loss: 0.0353\n",
      "Epoch [50/100], Average Loss: 0.0352\n",
      "Saved better model with Average Loss: 0.0352\n",
      "Epoch [51/100], Average Loss: 0.0351\n",
      "Saved better model with Average Loss: 0.0351\n",
      "Epoch [52/100], Average Loss: 0.0351\n",
      "Saved better model with Average Loss: 0.0351\n",
      "Epoch [53/100], Average Loss: 0.0351\n",
      "Saved better model with Average Loss: 0.0351\n",
      "Epoch [54/100], Average Loss: 0.0351\n",
      "Saved better model with Average Loss: 0.0351\n",
      "Epoch [55/100], Average Loss: 0.0350\n",
      "Saved better model with Average Loss: 0.0350\n",
      "Epoch [56/100], Average Loss: 0.0350\n",
      "Saved better model with Average Loss: 0.0350\n",
      "Epoch [57/100], Average Loss: 0.0349\n",
      "Saved better model with Average Loss: 0.0349\n",
      "Epoch [58/100], Average Loss: 0.0349\n",
      "Saved better model with Average Loss: 0.0349\n",
      "Epoch [59/100], Average Loss: 0.0349\n",
      "Saved better model with Average Loss: 0.0349\n",
      "Epoch [60/100], Average Loss: 0.0348\n",
      "Saved better model with Average Loss: 0.0348\n",
      "Epoch [61/100], Average Loss: 0.0348\n",
      "Saved better model with Average Loss: 0.0348\n",
      "Epoch [62/100], Average Loss: 0.0348\n",
      "Saved better model with Average Loss: 0.0348\n",
      "Epoch [63/100], Average Loss: 0.0347\n",
      "Saved better model with Average Loss: 0.0347\n",
      "Epoch [64/100], Average Loss: 0.0347\n",
      "Saved better model with Average Loss: 0.0347\n",
      "Epoch [65/100], Average Loss: 0.0346\n",
      "Saved better model with Average Loss: 0.0346\n",
      "Epoch [66/100], Average Loss: 0.0347\n",
      "Epoch [67/100], Average Loss: 0.0346\n",
      "Saved better model with Average Loss: 0.0346\n",
      "Epoch [68/100], Average Loss: 0.0346\n",
      "Saved better model with Average Loss: 0.0346\n",
      "Epoch [69/100], Average Loss: 0.0345\n",
      "Saved better model with Average Loss: 0.0345\n",
      "Epoch [70/100], Average Loss: 0.0345\n",
      "Saved better model with Average Loss: 0.0345\n",
      "Epoch [71/100], Average Loss: 0.0345\n",
      "Saved better model with Average Loss: 0.0345\n",
      "Epoch [72/100], Average Loss: 0.0345\n",
      "Saved better model with Average Loss: 0.0345\n",
      "Epoch [73/100], Average Loss: 0.0344\n",
      "Saved better model with Average Loss: 0.0344\n",
      "Epoch [74/100], Average Loss: 0.0344\n",
      "Saved better model with Average Loss: 0.0344\n",
      "Epoch [75/100], Average Loss: 0.0344\n",
      "Saved better model with Average Loss: 0.0344\n",
      "Epoch [76/100], Average Loss: 0.0344\n",
      "Saved better model with Average Loss: 0.0344\n",
      "Epoch [77/100], Average Loss: 0.0343\n",
      "Saved better model with Average Loss: 0.0343\n",
      "Epoch [78/100], Average Loss: 0.0343\n",
      "Saved better model with Average Loss: 0.0343\n",
      "Epoch [79/100], Average Loss: 0.0343\n",
      "Saved better model with Average Loss: 0.0343\n",
      "Epoch [80/100], Average Loss: 0.0343\n",
      "Saved better model with Average Loss: 0.0343\n",
      "Epoch [81/100], Average Loss: 0.0342\n",
      "Saved better model with Average Loss: 0.0342\n",
      "Epoch [82/100], Average Loss: 0.0343\n",
      "Epoch [83/100], Average Loss: 0.0342\n",
      "Saved better model with Average Loss: 0.0342\n",
      "Epoch [84/100], Average Loss: 0.0342\n",
      "Saved better model with Average Loss: 0.0342\n",
      "Epoch [85/100], Average Loss: 0.0342\n",
      "Saved better model with Average Loss: 0.0342\n",
      "Epoch [86/100], Average Loss: 0.0342\n",
      "Saved better model with Average Loss: 0.0342\n",
      "Epoch [87/100], Average Loss: 0.0341\n",
      "Saved better model with Average Loss: 0.0341\n",
      "Epoch [88/100], Average Loss: 0.0341\n",
      "Saved better model with Average Loss: 0.0341\n",
      "Epoch [89/100], Average Loss: 0.0341\n",
      "Saved better model with Average Loss: 0.0341\n",
      "Epoch [90/100], Average Loss: 0.0341\n",
      "Saved better model with Average Loss: 0.0341\n",
      "Epoch [91/100], Average Loss: 0.0340\n",
      "Saved better model with Average Loss: 0.0340\n",
      "Epoch [92/100], Average Loss: 0.0341\n",
      "Epoch [93/100], Average Loss: 0.0340\n",
      "Epoch [94/100], Average Loss: 0.0340\n",
      "Saved better model with Average Loss: 0.0340\n",
      "Epoch [95/100], Average Loss: 0.0340\n",
      "Epoch [96/100], Average Loss: 0.0340\n",
      "Epoch [97/100], Average Loss: 0.0340\n",
      "Saved better model with Average Loss: 0.0340\n",
      "Epoch [98/100], Average Loss: 0.0340\n",
      "Saved better model with Average Loss: 0.0340\n",
      "Epoch [99/100], Average Loss: 0.0339\n",
      "Saved better model with Average Loss: 0.0339\n",
      "Epoch [100/100], Average Loss: 0.0339\n",
      "Saved better model with Average Loss: 0.0339\n"
     ]
    }
   ],
   "source": [
    "# apply the model to the training loop\n",
    "best_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        # assuming labels are initially Long for indices, convert them to float for BCEWithLogitsLoss\n",
    "        labels = labels.float()  # convert labels to float\n",
    "\n",
    "        features = features.unsqueeze(1) # unsqueeze the data's feature to fit the model\n",
    "\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Average Loss: {avg_loss:.4f}')\n",
    "\n",
    "    # Save the model if the average loss of this epoch is the lowest encountered so far\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        # Save the model checkpoint\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f\"Saved better model with Average Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f45ff",
   "metadata": {},
   "source": [
    "### Apply the model to test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c202fdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./stored_files/best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c70c825",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = read_zst('./stored_files/test_x.zst')\n",
    "test_X['AGE'] = scaler.transform(test_X[['AGE']])\n",
    "test_y = read_zst('./stored_files/test_y.zst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6781c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test data to PyTorch tensors and move them to the device\n",
    "X_test_tensor = torch.tensor(test_X.values, dtype=torch.float).to(device)\n",
    "y_test_tensor = torch.tensor(test_y.values, dtype=torch.long).to(device)  # If your task is classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "445f9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model to test dataset\n",
    "model.eval()  # set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for features in DataLoader(X_test_tensor, batch_size=32):\n",
    "        features = features.unsqueeze(1) \n",
    "        outputs = model(features)\n",
    "        predictions = torch.sigmoid(outputs).round()\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "all_labels = y_test_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b773f61",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11559142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACC': 0.997, 'DDR': 0.8920586636340337, 'DDP': 0.888055405722262, 'DDF1': 0.8862359827661974, 'GM': 0.9243636922721007}\n"
     ]
    }
   ],
   "source": [
    "from metric_utils import compute_metric\n",
    "# apply the function to get the compute metric of the model\n",
    "metrics = compute_metric(all_labels, np.array(all_predictions))\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "be474e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"metrics.json\", \"w\") as outfile: \n",
    "    json.dump(metrics, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "91e8ec6dba721733cbabb6041f889efb611577a5423b619a5dcd4b9c77fda5d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
