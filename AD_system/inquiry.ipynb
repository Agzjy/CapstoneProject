{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train = pd.read_csv('../20043374/trainProcessed.csv')\n",
    "validate = pd.read_csv('../20043374/validateProcessed.csv')\n",
    "test = pd.read_csv('../20043374/testProcessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_list_diagnosis(diagnosis_list):\n",
    "    if isinstance(diagnosis_list, str):\n",
    "        try:\n",
    "            return ast.literal_eval(diagnosis_list)\n",
    "        except Exception as e: \n",
    "            return None \n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['DIFFERENTIAL_DIAGNOSIS'] = train['DIFFERENTIAL_DIAGNOSIS'].apply(convert_list_diagnosis)\n",
    "validate['DIFFERENTIAL_DIAGNOSIS'] = validate['DIFFERENTIAL_DIAGNOSIS'].apply(convert_list_diagnosis)\n",
    "test['DIFFERENTIAL_DIAGNOSIS'] = test['DIFFERENTIAL_DIAGNOSIS'].apply(convert_list_diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode_diagnosis(df, column_name):\n",
    "    # ensure that each diagnosis list is correctly formatted\n",
    "    df[column_name] = df[column_name].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "    # flatten the list of all possible diagnoses, taking only the diagnosis name (first item of each sublist)\n",
    "    all_diagnoses = set(diagnosis[0] for sublist in df[column_name] for diagnosis in sublist if isinstance(diagnosis, list) and len(diagnosis) > 0)\n",
    "    \n",
    "    # initialize a dictionary to hold the one-hot encoded data\n",
    "    one_hot_encoded_data = {diagnosis: [] for diagnosis in all_diagnoses}\n",
    "    \n",
    "    # populate the dictionary with 1s and 0s based on diagnosis presence\n",
    "    for index, row in df.iterrows():\n",
    "        present_diagnoses = {diagnosis[0] for diagnosis in row[column_name] if isinstance(diagnosis, list) and len(diagnosis) > 0}\n",
    "        for diagnosis in all_diagnoses:\n",
    "            one_hot_encoded_data[diagnosis].append(1 if diagnosis in present_diagnoses else 0)\n",
    "    \n",
    "    # convert the dictionary to a DataFrame\n",
    "    one_hot_y = pd.DataFrame(one_hot_encoded_data)\n",
    "    \n",
    "    return one_hot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = one_hot_encode_diagnosis(train, 'DIFFERENTIAL_DIAGNOSIS')\n",
    "validate_y = one_hot_encode_diagnosis(validate, 'DIFFERENTIAL_DIAGNOSIS')\n",
    "test_y = one_hot_encode_diagnosis(test, 'DIFFERENTIAL_DIAGNOSIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_age(x):\n",
    "    if x <= 4:\n",
    "        return 1\n",
    "    elif x <= 15:\n",
    "        return 2\n",
    "    elif x <= 30:\n",
    "        return 3\n",
    "    elif x <= 45:\n",
    "        return 4\n",
    "    elif x <= 60:\n",
    "        return 5\n",
    "    else:\n",
    "        return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['PATHOLOGY', 'DIFFERENTIAL_DIAGNOSIS', 'INITIAL_EVIDENCE'], axis=1)\n",
    "validate = validate.drop(['PATHOLOGY', 'DIFFERENTIAL_DIAGNOSIS', 'INITIAL_EVIDENCE'], axis=1)\n",
    "test = test.drop(['PATHOLOGY', 'DIFFERENTIAL_DIAGNOSIS', 'INITIAL_EVIDENCE'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['AGE'] = train['AGE'].apply(parse_age)\n",
    "validate['AGE'] = validate['AGE'].apply(parse_age)\n",
    "test['AGE'] = test['AGE'].apply(parse_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace(0, -1)\n",
    "validate = validate.replace(0, -1)\n",
    "test = test.replace(0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "train.astype(np.int8).to_pickle('train.zst')\n",
    "validate.astype(np.int8).to_pickle('validate.zst')\n",
    "test.astype(np.int8).to_pickle('test.zst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['SEX'] = train['SEX'].replace(-1, 0)\n",
    "# validate['SEX'] = validate['SEX'].replace(-1, 0)\n",
    "# test['SEX'] = test['SEX'].replace(-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zstandard as zstd\n",
    "import pickle\n",
    "with open('train.zst', 'rb') as compressed_file:\n",
    "    decompressor = zstd.ZstdDecompressor()\n",
    "    with decompressor.stream_reader(compressed_file) as reader:\n",
    "        decompressed_data = reader.read()\n",
    "\n",
    "train_wo_sex = pickle.loads(decompressed_data).drop('SEX', axis=1)\n",
    "train_wo_sex = train_wo_sex.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wo_sex = train_wo_sex.replace(-1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_columns = {}\n",
    "for n, col in enumerate(train_wo_sex.columns):\n",
    "    if '_@_' in col:\n",
    "        prefix, _ = col.split('_@_', 1)\n",
    "        if prefix not in prefix_to_columns:\n",
    "            prefix_to_columns[prefix] = []\n",
    "        prefix_to_columns[prefix].append(n)\n",
    "        \n",
    "column_to_prefix = {}\n",
    "for n, col in enumerate(train_wo_sex.columns):\n",
    "    if '_@_' in col:\n",
    "        prefix, _ = col.split('_@_', 1)\n",
    "        column_to_prefix[n] = prefix\n",
    "    else:\n",
    "        column_to_prefix[n] = None\n",
    "        \n",
    "prefix_group_counts = {}\n",
    "for col in train_wo_sex.columns:\n",
    "    if '_@_' in col:\n",
    "        prefix, _ = col.split('_@_', 1)\n",
    "        prefix_group_counts[prefix] = prefix_group_counts.get(prefix, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_entropy(probabilities):\n",
    "    # Ensure no zero probabilities; add a small value\n",
    "    probabilities = probabilities.clamp(min=1e-9)\n",
    "    return -(probabilities * probabilities.log2()).sum(dim=1)\n",
    "\n",
    "# Function to return the n columns with the highest entropies.\n",
    "def calculate_top_entropy_columns(df, columns, top_n=1):\n",
    "    \n",
    "    # df_tensor = torch.where(df == -1, torch.tensor(0, device=df.device), df)\n",
    "    prob = df.float().mean(dim=0)\n",
    "    prob = torch.stack([1 - prob, prob], dim=1)\n",
    "    entropy_values = calculate_entropy(prob)\n",
    "    index_mapping = {value: index for index, value in enumerate(columns)}\n",
    "    entropy_values_group = torch.zeros(len(columns), device=df.device)\n",
    "    \n",
    "    maximun = 0\n",
    "    max_col = None\n",
    "    processed_groups = set()\n",
    "    for n, col in enumerate(columns):\n",
    "        if column_to_prefix[col]:\n",
    "            group_prefix = column_to_prefix.get(col)\n",
    "            # Skip if the group has already been calculated\n",
    "            if group_prefix in processed_groups:\n",
    "                continue\n",
    "            indexes = [index_mapping[i] for i in prefix_to_columns[group_prefix]]\n",
    "            entropy_value = entropy_values[indexes].sum()\n",
    "            entropy_values_group[indexes] = entropy_value\n",
    "            processed_groups.add(group_prefix)\n",
    "        else:\n",
    "            entropy_value = entropy_values[n]\n",
    "            entropy_values_group[n] = entropy_value\n",
    "        # if entropy_value >= maximun:\n",
    "        #     maximun = entropy_value\n",
    "        #     max_col = col\n",
    "    max_entropy_group_id = torch.argmax(entropy_values_group)\n",
    "    max_col = columns[max_entropy_group_id]\n",
    "    maximun = entropy_values_group[max_entropy_group_id].item()\n",
    "        \n",
    "    return (max_col, maximun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 5.451161490500922\n",
      "104 4.18163624932129\n",
      "11 3.352121841444533\n",
      "11 3.346291305087514\n"
     ]
    }
   ],
   "source": [
    "aa, en = calculate_top_entropy_columns(train_wo_sex)\n",
    "print(len(aa), en)\n",
    "b = train_wo_sex.drop(aa, axis=1)\n",
    "cc, en = calculate_top_entropy_columns(b)\n",
    "d = b.drop(cc, axis=1)\n",
    "print(len(cc), en)\n",
    "ee, en = calculate_top_entropy_columns(d)\n",
    "f = d.drop(ee, axis=1)\n",
    "print(len(ee), en)\n",
    "gg, en = calculate_top_entropy_columns(f)\n",
    "print(len(gg), en)\n",
    "# len(calculate_top_entropy_columns(bb.drop(cc, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_wo_sex_tensor = torch.tensor(train_wo_sex.values, dtype=torch.int32).cuda()\n",
    "n = len(train_wo_sex)\n",
    "age_idx = train_wo_sex.columns.get_loc('AGE')  # This is for pandas, done once before conversion\n",
    "original_column_names = train_wo_sex.columns.copy()\n",
    "train_wo_sex.columns = range(len(train_wo_sex.columns))\n",
    "train_wo_age = train_wo_sex.copy()\n",
    "train_wo_age[age_idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 119.80it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from DPTreeNode import DPTreeNode\n",
    "\n",
    "# len(train_wo_sex)\n",
    "train_wo_age_tensor = train_wo_sex_tensor.clone()\n",
    "train_wo_age_tensor[:, age_idx] = 0\n",
    "# col_set = set(train_wo_sex.columns)\n",
    "\n",
    "if os.path.isfile('inquiry_system.pkl'):\n",
    "    tree_root = pickle.load(open('inquiry_system.pkl', 'rb'))\n",
    "    print('Tree loaded!')\n",
    "else:\n",
    "    reveal, en = calculate_top_entropy_columns(train_wo_age_tensor, list(train_wo_sex.columns))\n",
    "    tree_root = DPTreeNode(None, reveal)\n",
    "    tree_root.entropy = en\n",
    "\n",
    "result = None\n",
    "small_chunk = None\n",
    "large_chunk = None\n",
    "stored_tree_param = 10000\n",
    "num_question = 20\n",
    "\n",
    "# len(train_wo_sex)\n",
    "for idx in tqdm(range(0, 2)):\n",
    "    instance_tensor = train_wo_sex_tensor[idx]\n",
    "    instance = train_wo_sex.iloc[idx]\n",
    "    percent = 500\n",
    "    root = tree_root\n",
    "    reveal = []\n",
    "    # dataset = train_wo_age\n",
    "    similarity = None\n",
    "    instance_wo_age = train_wo_age_tensor[idx]\n",
    "    if idx == stored_tree_param:\n",
    "        pickle.dump(root, open('inquiry_system.pkl', 'wb'))\n",
    "        stored_tree_param += 10000\n",
    "    for i in range(num_question):\n",
    "        \n",
    "        new_inquiry = root.next_question\n",
    "        if column_to_prefix[new_inquiry]:\n",
    "            new_inquiry = prefix_to_columns[column_to_prefix[new_inquiry]]\n",
    "        else:\n",
    "            new_inquiry = [new_inquiry]\n",
    "            \n",
    "        reveal += new_inquiry\n",
    "\n",
    "        if i == 3:\n",
    "            # answer = \"\".join(str(x) for x in instance_tensor[new_inquiry + [age_idx]].tolist())\n",
    "            answer = \"\".join(str(x) for x in instance[new_inquiry + [age_idx]].tolist())\n",
    "            reveal += [age_idx]\n",
    "            # dataset = train_wo_sex\n",
    "        else:\n",
    "            # answer = \"\".join(str(x) for x in instance_tensor[new_inquiry].tolist())\n",
    "            answer = \"\".join(str(x) for x in instance[new_inquiry].tolist())\n",
    "        next_node = root.look_up_children(answer)\n",
    "        if next_node:\n",
    "            root = next_node\n",
    "        else: \n",
    "            if i == num_question - 1: continue\n",
    "            cur_node = DPTreeNode(answer, None)\n",
    "            root.add_child(cur_node)\n",
    "            if similarity is not None:\n",
    "                if i == 3:\n",
    "                    for question_idx in new_inquiry:\n",
    "                        similarity += 2 * (train_wo_age_tensor[:, question_idx] != instance_wo_age[question_idx])\n",
    "                    similarity += (train_wo_sex_tensor[:, age_idx] - instance_tensor[age_idx]).abs()\n",
    "                else:\n",
    "                    for question_idx in new_inquiry:\n",
    "                        similarity += 2 * (train_wo_age_tensor[:, question_idx] != instance_tensor[question_idx])\n",
    "            else:\n",
    "                similarity = torch.zeros(train_wo_sex_tensor.size(0), device=\"cuda\")\n",
    "                for question_idx in reveal:\n",
    "                    if question_idx == age_idx:\n",
    "                        similarity += (train_wo_sex_tensor[:, age_idx] - instance_tensor[age_idx]).abs()\n",
    "                    else:\n",
    "                        similarity += 2 * (train_wo_age_tensor[:, question_idx] != instance_wo_age[question_idx])\n",
    "            k = n//10000*percent\n",
    "            values, top_indices = torch.topk(similarity, k, largest=False)\n",
    "            top_actual_indices = top_indices\n",
    "            similar_cases = train_wo_age_tensor[top_actual_indices]\n",
    "            selected_col = [col for col in train_wo_sex.columns if col not in reveal]\n",
    "            new_inquiry, en = calculate_top_entropy_columns(similar_cases[:, selected_col], selected_col)\n",
    "            cur_node.next_question = new_inquiry\n",
    "            cur_node.entropy = np.int8(en//2)\n",
    "            root = cur_node\n",
    "\n",
    "        percent = percent//(1.4**(root.entropy + 1))\n",
    "        percent = int(percent) if percent > 1 else 1\n",
    "        torch.cuda.synchronize()\n",
    "    # result = pd.concat([result, mask_instance.to_frame().T], axis=0)\n",
    "    mask_instance = pd.Series(0, index=range(len(original_column_names)))\n",
    "    mask_instance[reveal] = train_wo_sex.iloc[idx][reveal]\n",
    "    if small_chunk is None:\n",
    "        small_chunk = np.array([mask_instance.to_numpy()])\n",
    "    else:\n",
    "        small_chunk = np.vstack((small_chunk, mask_instance.to_numpy()))\n",
    "    if idx % 100 == 99:\n",
    "        if large_chunk is None:\n",
    "            large_chunk = small_chunk\n",
    "        else:\n",
    "            large_chunk = np.vstack((large_chunk, small_chunk))\n",
    "        small_chunk = None\n",
    "        if idx % 10000 == 9999:\n",
    "            if result is None:\n",
    "                result = large_chunk\n",
    "            else:\n",
    "                result = np.vstack((result, large_chunk))\n",
    "            large_chunk = None\n",
    "    torch.cuda.synchronize()\n",
    "            \n",
    "# Empty the chunk\n",
    "if large_chunk is not None:\n",
    "    if result is None: \n",
    "        result = large_chunk\n",
    "    else:\n",
    "        result = np.vstack((result, large_chunk))\n",
    "if small_chunk is not None:\n",
    "    if result is None: \n",
    "        result = small_chunk\n",
    "    else:\n",
    "        result = np.vstack((result, small_chunk))\n",
    "        \n",
    "result = pd.DataFrame(result, columns=original_column_names)\n",
    "result_file = 'result.zst'\n",
    "if os.path.isfile(result_file):\n",
    "    result_file = 'result_2.zst'\n",
    "result.astype(np.int8).to_pickle(result_file)\n",
    "pickle.dump(tree_root, open('inquiry_system.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1   -1\n",
       "Name: 1, dtype: int8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance[new_inquiry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(new_inquiry[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_tensor[new_inquiry].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-1'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([102, 517])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Time: 0.018001079559326172 seconds\n",
      "GPU Time: 0.0010044574737548828 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "\n",
    "# Sample size for the benchmark\n",
    "n = 1000000  # Adjust this based on your typical dataset size\n",
    "\n",
    "# Generating a sample DataFrame and mask instance\n",
    "np.random.seed(0)\n",
    "train_wo_sex = pd.DataFrame({\n",
    "    'AGE': np.random.randint(18, 65, size=n),\n",
    "    'QUESTION1': np.random.randint(0, 2, size=n),\n",
    "    'QUESTION2': np.random.randint(0, 2, size=n),\n",
    "})\n",
    "mask_instance = pd.Series({'AGE': 30, 'QUESTION1': 1, 'QUESTION2': 0})\n",
    "reveal = ['AGE', 'QUESTION1', 'QUESTION2']\n",
    "\n",
    "# CPU Version\n",
    "start_cpu = time.time()\n",
    "similarity = pd.Series(0, index=train_wo_sex.index)\n",
    "for question in reveal:\n",
    "    if question == 'AGE':\n",
    "        similarity += abs(train_wo_sex['AGE'] - mask_instance.loc[question])\n",
    "    else:\n",
    "        similarity += 2 * (train_wo_sex[question] != mask_instance.loc[question])\n",
    "end_cpu = time.time()\n",
    "time_cpu = end_cpu - start_cpu\n",
    "\n",
    "# GPU Version\n",
    "# start_gpu = time.time()\n",
    "# Initial setup for GPU version as per the earlier provided code\n",
    "similarity_gpu = torch.zeros(len(train_wo_sex), device='cuda')\n",
    "train_columns_gpu = {col: torch.tensor(train_wo_sex[col].values, device='cuda') for col in reveal}\n",
    "start_gpu = time.time()\n",
    "mask_values_gpu = {question: torch.tensor(mask_instance.loc[question], device='cuda') for question in reveal}\n",
    "for question in reveal:\n",
    "    if question == 'AGE':\n",
    "        similarity_gpu += torch.abs(train_columns_gpu[question] - mask_values_gpu[question])\n",
    "    else:\n",
    "        similarity_gpu += 2 * (train_columns_gpu[question] != mask_values_gpu[question]).float()\n",
    "end_gpu = time.time()\n",
    "time_gpu = end_gpu - start_gpu\n",
    "\n",
    "# Print the times\n",
    "print(f\"CPU Time: {time_cpu} seconds\")\n",
    "print(f\"GPU Time: {time_gpu} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tree_root, open('inquiry_system.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_node.parent.children = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur_node.parent.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tree_root.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.iloc[0][result.iloc[0] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'crach_sg', 'douleurxx', 'douleurxx_carac_@_NA',\n",
       "       'douleurxx_carac_@_déchirante',\n",
       "       'douleurxx_carac_@_lancinante_/_choc_électrique',\n",
       "       'douleurxx_carac_@_pénible', 'douleurxx_carac_@_sensible',\n",
       "       'douleurxx_carac_@_un_coup_de_couteau',\n",
       "       'douleurxx_carac_@_un_tiraillement',\n",
       "       ...\n",
       "       'trav1_@_AfriqO', 'trav1_@_AfriqSS', 'trav1_@_AmerC', 'trav1_@_AmerN',\n",
       "       'trav1_@_AmerS', 'trav1_@_Asie', 'trav1_@_AsieSSE', 'trav1_@_Cara',\n",
       "       'trav1_@_Euro', 'trav1_@_N'],\n",
       "      dtype='object', length=319)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.iloc[10][result.iloc[10] != 0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          54\n",
       "1          62\n",
       "2          70\n",
       "3          62\n",
       "4          64\n",
       "           ..\n",
       "1025597    70\n",
       "1025598    70\n",
       "1025599    70\n",
       "1025600    70\n",
       "1025601    70\n",
       "Length: 1025602, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lesions_peau_endroitducorps', 'douleurxx_irrad', 'douleurxx_endroitducorps', 'douleurxx_precis', 'trav1', 'oedeme_endroitducorps', 'lesions_peau_plusqu1cm', 'douleurxx_carac', 'lesions_peau_prurit', 'lesions_peau_intens', 'douleurxx_soudain', 'lesions_peau_couleur', 'lesions_peau_elevee', 'douleurxx_intens', 'lesions_peau_desquame'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_to_columns.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = tree_root\n",
    "pickle.dump(root, open('inquiry_system.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Inference the Inquiry System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zstandard as zstd\n",
    "import pickle\n",
    "with open('test.zst', 'rb') as compressed_file:\n",
    "    decompressor = zstd.ZstdDecompressor()\n",
    "    with decompressor.stream_reader(compressed_file) as reader:\n",
    "        decompressed_data = reader.read()\n",
    "\n",
    "test_wo_sex = pickle.loads(decompressed_data).drop('SEX', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AGE', 'I30', 'diarrhee', 'bode',\n",
       "       'lesions_peau_endroitducorps_@_face_dorsale_main_D_',\n",
       "       'douleurxx_irrad_@_sous_la_machoire',\n",
       "       'douleurxx_irrad_@_cartilage_thyroidien',\n",
       "       'douleurxx_irrad_@_arrière_de_tête',\n",
       "       'douleurxx_endroitducorps_@_hypochondre_G_',\n",
       "       'douleurxx_endroitducorps_@_oreille_G_',\n",
       "       ...\n",
       "       'etourdissement', 'hernie_hiatale', 'douleurxx_irrad_@_trachée',\n",
       "       'douleurxx_endroitducorps_@_orteil__1__G_', 'ww_dd',\n",
       "       'lesions_peau_endroitducorps_@_petite_lèvre_G_',\n",
       "       'lesions_peau_elevee_@_2', 'j17_j18', 'lesions_peau_intens_@_0',\n",
       "       'lesions_peau_endroitducorps_@_vagin'],\n",
       "      dtype='object', length=517)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_wo_sex.columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 134529/134529 [09:52<00:00, 227.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, pairwise_distances\n",
    "from scipy.sparse import csr_matrix\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from DPTreeNode import DPTreeNode\n",
    "\n",
    "n = len(train_wo_sex)\n",
    "train_wo_age = train_wo_sex.copy()\n",
    "train_wo_age['AGE'] = 0\n",
    "\n",
    "if os.path.isfile('inquiry_system.pkl'):\n",
    "    tree_root = pickle.load(open('inquiry_system.pkl', 'rb'))\n",
    "    print('Tree loaded!')\n",
    "else:\n",
    "    reveal = calculate_top_entropy_columns(train_wo_age)\n",
    "    tree_root = DPTreeNode(None, reveal)\n",
    "result = None\n",
    "small_chunk = None\n",
    "large_chunk = None\n",
    "num_question = 25\n",
    "\n",
    "\n",
    "for idx, instance in tqdm(test_wo_sex.iterrows(), total=len(test_wo_sex)):\n",
    "    percent = 1000\n",
    "    root = tree_root\n",
    "    reveal = []\n",
    "    dataset = train_wo_age\n",
    "    similarity = None\n",
    "    for i in range(num_question):\n",
    "        new_inquiry = root.next_question\n",
    "        reveal += new_inquiry \n",
    "\n",
    "        if i == 7:\n",
    "            answer = list(\"\".join('0' if x==-1 else str(x) for x in instance[new_inquiry + ['AGE']]))\n",
    "            reveal += ['AGE']\n",
    "            dataset = train_wo_sex\n",
    "        else:\n",
    "            answer = instance[new_inquiry[0]]\n",
    "            \n",
    "        next_node = root.look_up_children(answer)\n",
    "        if next_node:\n",
    "            root = next_node\n",
    "        else: \n",
    "            mask_instance = pd.Series(0, index=instance.index)\n",
    "            mask_instance[reveal] = instance[reveal]\n",
    "            if i == num_question - 1: continue\n",
    "            cur_node = DPTreeNode(answer, None)\n",
    "            root.add_child(cur_node)\n",
    "            if similarity is not None:\n",
    "                if i == 7:\n",
    "                    f_answer = 1 if int(answer[0]) == 1 else -1\n",
    "                    similarity += (train_wo_sex[new_inquiry[0]] != f_answer)\n",
    "                    similarity += abs(train_wo_sex['AGE'] - int(answer[1]))\n",
    "                else:\n",
    "                    similarity += 2*(train_wo_sex[new_inquiry[0]] != answer)\n",
    "            else:\n",
    "                similarity = pd.Series(0, index=train_wo_sex.index)\n",
    "                for question in reveal:\n",
    "                    if question == 'AGE':\n",
    "                        similarity += abs(train_wo_sex['AGE'] - mask_instance.loc[question])\n",
    "                    similarity += 2*(train_wo_sex[question] != mask_instance.loc[question])\n",
    "\n",
    "            cur_threshold = cur_node.parent.threshold + 2 if i != 7 else cur_node.parent.threshold + 7\n",
    "            sorted_similarity = similarity[similarity <= cur_threshold].argsort() \n",
    "            similar_ind = sorted_similarity.iloc[:n//1000*percent]\n",
    "            cur_node.threshold = similarity[similar_ind.iloc[-1]]\n",
    "            \n",
    "            similar_cases = dataset.iloc[similar_ind]\n",
    "            new_inquiry = calculate_top_entropy_columns(similar_cases.drop(reveal, axis=1))\n",
    "            cur_node.next_question = new_inquiry\n",
    "            root = cur_node\n",
    "        \n",
    "        percent = percent//1.4\n",
    "        percent = int(percent) if percent > 5 else 5\n",
    "    # result = pd.concat([result, mask_instance.to_frame().T], axis=0)\n",
    "    if small_chunk is None:\n",
    "        small_chunk = np.array([mask_instance.to_numpy()])\n",
    "    else:\n",
    "        small_chunk = np.vstack((small_chunk, mask_instance.to_numpy()))\n",
    "    if idx % 100 == 99:\n",
    "        if large_chunk is None:\n",
    "            large_chunk = small_chunk\n",
    "        else:\n",
    "            large_chunk = np.vstack((large_chunk, small_chunk))\n",
    "        small_chunk = None\n",
    "        if idx % 10000 == 9999:\n",
    "            if result is None:\n",
    "                result = large_chunk\n",
    "            else:\n",
    "                result = np.vstack((result, large_chunk))\n",
    "            large_chunk = None\n",
    "            \n",
    "# Empty the chunk\n",
    "if large_chunk is not None:\n",
    "    if result is None: \n",
    "        result = large_chunk\n",
    "    else:\n",
    "        result = np.vstack((result, large_chunk))\n",
    "if small_chunk is not None:\n",
    "    if result is None: \n",
    "        result = small_chunk\n",
    "    else:\n",
    "        result = np.vstack((result, small_chunk))\n",
    "        \n",
    "result = pd.DataFrame(result, columns=train_wo_sex.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.astype(np.int8).to_pickle('test_result.zst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>I30</th>\n",
       "      <th>diarrhee</th>\n",
       "      <th>bode</th>\n",
       "      <th>lesions_peau_endroitducorps_@_face_dorsale_main_D_</th>\n",
       "      <th>douleurxx_irrad_@_sous_la_machoire</th>\n",
       "      <th>douleurxx_irrad_@_cartilage_thyroidien</th>\n",
       "      <th>douleurxx_irrad_@_arrière_de_tête</th>\n",
       "      <th>douleurxx_endroitducorps_@_hypochondre_G_</th>\n",
       "      <th>douleurxx_endroitducorps_@_oreille_G_</th>\n",
       "      <th>...</th>\n",
       "      <th>etourdissement</th>\n",
       "      <th>hernie_hiatale</th>\n",
       "      <th>douleurxx_irrad_@_trachée</th>\n",
       "      <th>douleurxx_endroitducorps_@_orteil__1__G_</th>\n",
       "      <th>ww_dd</th>\n",
       "      <th>lesions_peau_endroitducorps_@_petite_lèvre_G_</th>\n",
       "      <th>lesions_peau_elevee_@_2</th>\n",
       "      <th>j17_j18</th>\n",
       "      <th>lesions_peau_intens_@_0</th>\n",
       "      <th>lesions_peau_endroitducorps_@_vagin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134524</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134525</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134526</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134527</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134528</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134529 rows × 517 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE  I30  diarrhee  bode  \\\n",
       "0         5    0         0     0   \n",
       "1         1    0         0     0   \n",
       "2         5    0         0     0   \n",
       "3         6    0         0     0   \n",
       "4         6    0         0     0   \n",
       "...     ...  ...       ...   ...   \n",
       "134524    5    0         0     0   \n",
       "134525    6    0         0     0   \n",
       "134526    3    0         0     0   \n",
       "134527    2    0         0     0   \n",
       "134528    3    0         0     0   \n",
       "\n",
       "        lesions_peau_endroitducorps_@_face_dorsale_main_D_  \\\n",
       "0                                                       0    \n",
       "1                                                       0    \n",
       "2                                                       0    \n",
       "3                                                       0    \n",
       "4                                                       0    \n",
       "...                                                   ...    \n",
       "134524                                                  0    \n",
       "134525                                                  0    \n",
       "134526                                                  0    \n",
       "134527                                                  0    \n",
       "134528                                                  0    \n",
       "\n",
       "        douleurxx_irrad_@_sous_la_machoire  \\\n",
       "0                                        0   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "...                                    ...   \n",
       "134524                                   0   \n",
       "134525                                   0   \n",
       "134526                                   0   \n",
       "134527                                   0   \n",
       "134528                                   0   \n",
       "\n",
       "        douleurxx_irrad_@_cartilage_thyroidien  \\\n",
       "0                                            0   \n",
       "1                                            0   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "...                                        ...   \n",
       "134524                                       0   \n",
       "134525                                       0   \n",
       "134526                                       0   \n",
       "134527                                       0   \n",
       "134528                                       0   \n",
       "\n",
       "        douleurxx_irrad_@_arrière_de_tête  \\\n",
       "0                                       0   \n",
       "1                                       0   \n",
       "2                                       0   \n",
       "3                                       0   \n",
       "4                                       0   \n",
       "...                                   ...   \n",
       "134524                                  0   \n",
       "134525                                  0   \n",
       "134526                                  0   \n",
       "134527                                  0   \n",
       "134528                                  0   \n",
       "\n",
       "        douleurxx_endroitducorps_@_hypochondre_G_  \\\n",
       "0                                               0   \n",
       "1                                               0   \n",
       "2                                               0   \n",
       "3                                               0   \n",
       "4                                               0   \n",
       "...                                           ...   \n",
       "134524                                          0   \n",
       "134525                                          0   \n",
       "134526                                          0   \n",
       "134527                                          0   \n",
       "134528                                          0   \n",
       "\n",
       "        douleurxx_endroitducorps_@_oreille_G_  ...  etourdissement  \\\n",
       "0                                           0  ...               0   \n",
       "1                                           0  ...               0   \n",
       "2                                           0  ...               0   \n",
       "3                                           0  ...               0   \n",
       "4                                           0  ...               0   \n",
       "...                                       ...  ...             ...   \n",
       "134524                                      0  ...               0   \n",
       "134525                                      0  ...               0   \n",
       "134526                                      0  ...               0   \n",
       "134527                                      0  ...               0   \n",
       "134528                                      0  ...               0   \n",
       "\n",
       "        hernie_hiatale  douleurxx_irrad_@_trachée  \\\n",
       "0                    0                          0   \n",
       "1                    0                          0   \n",
       "2                    0                          0   \n",
       "3                    0                          0   \n",
       "4                    0                          0   \n",
       "...                ...                        ...   \n",
       "134524               0                          0   \n",
       "134525               0                          0   \n",
       "134526               0                          0   \n",
       "134527               0                          0   \n",
       "134528               0                          0   \n",
       "\n",
       "        douleurxx_endroitducorps_@_orteil__1__G_  ww_dd  \\\n",
       "0                                              0      0   \n",
       "1                                              0      0   \n",
       "2                                              0      0   \n",
       "3                                              0      0   \n",
       "4                                              0      0   \n",
       "...                                          ...    ...   \n",
       "134524                                         0      0   \n",
       "134525                                         0      0   \n",
       "134526                                         0      0   \n",
       "134527                                         0      0   \n",
       "134528                                         0      0   \n",
       "\n",
       "        lesions_peau_endroitducorps_@_petite_lèvre_G_  \\\n",
       "0                                                   0   \n",
       "1                                                   0   \n",
       "2                                                   0   \n",
       "3                                                   0   \n",
       "4                                                   0   \n",
       "...                                               ...   \n",
       "134524                                              0   \n",
       "134525                                              0   \n",
       "134526                                              0   \n",
       "134527                                              0   \n",
       "134528                                              0   \n",
       "\n",
       "        lesions_peau_elevee_@_2  j17_j18  lesions_peau_intens_@_0  \\\n",
       "0                             0        0                        0   \n",
       "1                             0        0                        0   \n",
       "2                             0        0                        0   \n",
       "3                             0        0                        0   \n",
       "4                             0        0                        0   \n",
       "...                         ...      ...                      ...   \n",
       "134524                        0        0                        0   \n",
       "134525                        0        0                        0   \n",
       "134526                        0        0                        0   \n",
       "134527                        0        0                        0   \n",
       "134528                        0        0                        0   \n",
       "\n",
       "        lesions_peau_endroitducorps_@_vagin  \n",
       "0                                         0  \n",
       "1                                         0  \n",
       "2                                         0  \n",
       "3                                         0  \n",
       "4                                         0  \n",
       "...                                     ...  \n",
       "134524                                    0  \n",
       "134525                                    0  \n",
       "134526                                    0  \n",
       "134527                                    0  \n",
       "134528                                    0  \n",
       "\n",
       "[134529 rows x 517 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_root.children[0].children[1].children[0].children[0].answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree loaded!\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile('inquiry_system.pkl'):\n",
    "    tree_root = pickle.load(open('inquiry_system.pkl', 'rb'))\n",
    "    print('Tree loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_tree = pickle.load(open('inquiry_system.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '0', '1', '0', '1']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_tree.children[2].answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "91e8ec6dba721733cbabb6041f889efb611577a5423b619a5dcd4b9c77fda5d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
