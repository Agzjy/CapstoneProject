{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wET87_cFH6cP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import scipy.stats as stats\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SequentialFeatureSelector as sfs\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy import stats\n",
        "from scipy.stats import linregress\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import make_classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9B6RsIIIBM-"
      },
      "outputs": [],
      "source": [
        "#import dataset\n",
        "train = pd.read_csv('../data/trainProcessed.csv')\n",
        "validate = pd.read_csv('../data/validateProcessed.csv')\n",
        "test = pd.read_csv('../data/testProcessed.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3vE0YGXID-9"
      },
      "outputs": [],
      "source": [
        "#Our group decided to use Random forest to predict the pathology.\n",
        "\n",
        "def data_pre(df):\n",
        "    y=df['PATHOLOGY']\n",
        "    X=df.drop(['DIFFERENTIAL_DIAGNOSIS','PATHOLOGY','INITIAL_EVIDENCE'], axis=1)\n",
        "    return X,y\n",
        "X,y=data_pre(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wt4eR_F9SgGu"
      },
      "outputs": [],
      "source": [
        "X,y=data_pre(train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SckBJApFY3Kx"
      },
      "source": [
        "In order to get the best parameter of the model, our group decided to use grid search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05tE0QdAUX9c"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# To find the best parameter for the model, we decided to run the grid search.\n",
        "\n",
        "X,y=data_pre(train)\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [10, 15, 20],\n",
        "    'min_samples_split': [2,4],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "\n",
        "myclf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator=myclf, param_grid=param_grid,\n",
        "                           cv=5, n_jobs=-1, verbose=2, scoring='accuracy')\n",
        "\n",
        "grid_search.fit(X, y)\n",
        "\n",
        "best_params_ = grid_search.best_params_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpKtqJSfY9fS"
      },
      "source": [
        "After finding the best parameter, we use it in the model and see the performance on the valifation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "id": "EQ43Kd9gIDq-",
        "outputId": "170ebe11-ba15-4339-e221-4da9a6fc25ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=2, min_samples_split=4,\n",
              "                       random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, min_samples_leaf=2, min_samples_split=4,\n",
              "                       random_state=0)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_depth=20, min_samples_leaf=2, min_samples_split=4,\n",
              "                       random_state=0)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf = RandomForestClassifier(**best_params_, random_state=0, bootstrap=True)\n",
        "clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRPa8YPubDyZ"
      },
      "source": [
        "**Evaluate on validation dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ii6YVo-FUyBv"
      },
      "outputs": [],
      "source": [
        "X_validate,y_validate=data_pre(validate)\n",
        "y_pred_validate=clf.predict(X_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4agFoVwaU-p0",
        "outputId": "44880093-b251-4208-cdb8-c2bc828b74be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9933709833293066\n",
            "Precision: 0.9940952646224286\n",
            "Recall: 0.9868095249391869\n",
            "F1 Score: 0.9931304922059677\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy_v = accuracy_score(y_validate, y_pred_validate)\n",
        "precision_v = precision_score(y_validate, y_pred_validate,average='macro')\n",
        "recall_v = recall_score(y_validate, y_pred_validate,average='macro')\n",
        "f1 = f1_score(y_validate, y_pred_validate, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy_v}\")\n",
        "print(f\"Precision: {precision_v}\")\n",
        "print(f\"Recall: {recall_v}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcnkRCCrZGlA"
      },
      "source": [
        "According to the model's outcome validation set, the Accuracy and F1 score is high enough, so it is good to use in the test set. The reason of its high accuracy and F1 score is because of the enormous size of our dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeUOi0VFbOWU"
      },
      "source": [
        "**Result on Test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hdl8anPmVAJ2"
      },
      "outputs": [],
      "source": [
        "y_test=test['PATHOLOGY']\n",
        "X_test=test.drop(['DIFFERENTIAL_DIAGNOSIS','PATHOLOGY','INITIAL_EVIDENCE'], axis=1)\n",
        "y_pred_test=clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4ZV1b3rVAFF",
        "outputId": "bc15b1f8-38a6-4789-8a35-c087c6431c26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9936519263504523\n",
            "Precision: 0.9941703785457606\n",
            "Recall: 0.9858327643299465\n",
            "F1 Score: 0.9934309272140678\n",
            "Balanced Accuracy: 0.9858327643299465\n"
          ]
        }
      ],
      "source": [
        "from metric_utils import calculate_metric\n",
        "# apply the function to get the evaluation metric\n",
        "test_metric = calculate_metric(y_test, y_pred_test, index=[\"data\"])\n",
        "test_metric = test_metric.loc['data']\n",
        "\n",
        "print(f\"Accuracy: {test_metric['accuracy']}\")\n",
        "print(f\"Precision: {test_metric['precision']}\")\n",
        "print(f\"Recall: {test_metric['recall']}\")\n",
        "print(f\"F1 Score: {test_metric['f1 score']}\")\n",
        "print(f\"Balanced Accuracy: {test_metric['balanced accuracy']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30mst-upZXqo"
      },
      "source": [
        "Our final result on the test set is shown above. We reached the maximum accuracy of 0.9937 and 0.9934 F1 score, which is high enough to predict the pathology."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dssX5oi9buKG"
      },
      "source": [
        "**Accuracy for each pathology**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn5OWyuCbb3N",
        "outputId": "c468c4b0-3aae-461b-de04-4564ced6c0ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for class Anaphylaxie: 1.0\n",
            "Accuracy for class Angine instable: 0.9993086992395691\n",
            "Accuracy for class Angine stable: 0.9993235659225892\n",
            "Accuracy for class Anémie: 1.0\n",
            "Accuracy for class Asthme exacerbé ou bronchospasme: 1.0\n",
            "Accuracy for class Attaque de panique: 1.0\n",
            "Accuracy for class Bronchiectasies: 1.0\n",
            "Accuracy for class Bronchiolite: 0.9999776999754699\n",
            "Accuracy for class Bronchite: 0.99994796660943\n",
            "Accuracy for class Chagas: 1.0\n",
            "Accuracy for class Coqueluche: 0.99998513331698\n",
            "Accuracy for class Céphalée en grappe: 1.0\n",
            "Accuracy for class Ebola: 0.99996283329245\n",
            "Accuracy for class Embolie pulmonaire: 1.0\n",
            "Accuracy for class Exacerbation aigue de MPOC et/ou surinfection associée: 1.0\n",
            "Accuracy for class Fibrillation auriculaire/Flutter auriculaire: 1.0\n",
            "Accuracy for class Fracture de côte spontanée: 0.9997695664131897\n",
            "Accuracy for class Hernie inguinale: 1.0\n",
            "Accuracy for class IVRS ou virémie: 1.0\n",
            "Accuracy for class Laryngite aigue: 0.9996357662660096\n",
            "Accuracy for class Laryngo-trachéo-bronchite (Croup): 0.9996803663150696\n",
            "Accuracy for class Laryngospasme: 0.99994796660943\n",
            "Accuracy for class Lupus érythémateux disséminé (LED): 0.9999776999754699\n",
            "Accuracy for class Myasthénie grave: 1.0\n",
            "Accuracy for class Myocardite: 0.9997844330962098\n",
            "Accuracy for class Néoplasie du pancréas: 1.0\n",
            "Accuracy for class OAP/Surcharge pulmonaire: 1.0\n",
            "Accuracy for class Oedème localisé ou généralisé sans atteinte pulmonaire associée: 1.0\n",
            "Accuracy for class Otite moyenne aigue (OMA): 0.99998513331698\n",
            "Accuracy for class Pharyngite virale: 0.9996357662660096\n",
            "Accuracy for class Pneumonie: 1.0\n",
            "Accuracy for class Pneumothorax spontané: 0.9997621330716797\n",
            "Accuracy for class Possible NSTEMI / STEMI: 0.99998513331698\n",
            "Accuracy for class Possible influenza ou syndrome virémique typique: 1.0\n",
            "Accuracy for class Péricardite: 0.99996283329245\n",
            "Accuracy for class RGO: 1.0\n",
            "Accuracy for class Rhinite allergique: 0.9999702666339599\n",
            "Accuracy for class Rhinosinusite aigue: 0.9956143285090947\n",
            "Accuracy for class Rhinosinusite chronique: 0.9956143285090947\n",
            "Accuracy for class Réaction dystonique aïgue: 1.0\n",
            "Accuracy for class Sarcoïdose: 0.9999776999754699\n",
            "Accuracy for class Scombroïde: 1.0\n",
            "Accuracy for class Syndrome de Boerhaave: 0.99998513331698\n",
            "Accuracy for class Syndrome de Guillain-Barré: 0.9997398330471496\n",
            "Accuracy for class TSVP: 0.9998215998037597\n",
            "Accuracy for class Tuberculose: 0.99994796660943\n",
            "Accuracy for class VIH (Primo-infection): 1.0\n",
            "Accuracy for class néoplasie pulmonaire: 1.0\n",
            "Accuracy for class Épiglottite: 1.0\n"
          ]
        }
      ],
      "source": [
        "classes = np.unique(y_test)\n",
        "accuracies = {}\n",
        "for cls in classes:\n",
        "\n",
        "    cls_true = (y_test == cls).astype(int)\n",
        "    cls_pred = (y_pred_test == cls).astype(int)\n",
        "\n",
        "    accuracies[cls] = accuracy_score(cls_true, cls_pred)\n",
        "\n",
        "for cls, acc in accuracies.items():\n",
        "    print(f\"Accuracy for class {cls}: {acc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iebm2TVGbbMo"
      },
      "source": [
        "\n",
        "However, there is one limitation: the grid search process takes too long, our group is still trying to find a less time consuming way. Also, our dataset only contains pathology that are related with breath, throat and lungth. The model performance on dataset that contain wider pathology range is still unclear."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.11.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
