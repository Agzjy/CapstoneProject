{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71ad780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "import ast\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a954bd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train = pd.read_csv('../../data/trainProcessed.csv')\n",
    "validate = pd.read_csv('../../data/validateProcessed.csv')\n",
    "test = pd.read_csv('../../data/testProcessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0281b560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIFFERENTIAL_DIAGNOSIS</th>\n",
       "      <th>SEX</th>\n",
       "      <th>PATHOLOGY</th>\n",
       "      <th>INITIAL_EVIDENCE</th>\n",
       "      <th>I30</th>\n",
       "      <th>diarrhee</th>\n",
       "      <th>bode</th>\n",
       "      <th>lesions_peau_endroitducorps_@_face_dorsale_main_D_</th>\n",
       "      <th>douleurxx_irrad_@_sous_la_machoire</th>\n",
       "      <th>...</th>\n",
       "      <th>etourdissement</th>\n",
       "      <th>hernie_hiatale</th>\n",
       "      <th>douleurxx_irrad_@_trachée</th>\n",
       "      <th>douleurxx_endroitducorps_@_orteil__1__G_</th>\n",
       "      <th>ww_dd</th>\n",
       "      <th>lesions_peau_endroitducorps_@_petite_lèvre_G_</th>\n",
       "      <th>lesions_peau_elevee_@_2</th>\n",
       "      <th>j17_j18</th>\n",
       "      <th>lesions_peau_intens_@_0</th>\n",
       "      <th>lesions_peau_endroitducorps_@_vagin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>[['Bronchite', 0.19171203430383882], ['Pneumon...</td>\n",
       "      <td>0</td>\n",
       "      <td>IVRS ou virémie</td>\n",
       "      <td>fievre</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>[['VIH (Primo-infection)', 0.5189500564407601]...</td>\n",
       "      <td>0</td>\n",
       "      <td>VIH (Primo-infection)</td>\n",
       "      <td>diaph</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19</td>\n",
       "      <td>[['Bronchite', 0.11278064619119596], ['Pneumon...</td>\n",
       "      <td>1</td>\n",
       "      <td>Pneumonie</td>\n",
       "      <td>expecto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 521 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE                             DIFFERENTIAL_DIAGNOSIS  SEX  \\\n",
       "0   18  [['Bronchite', 0.19171203430383882], ['Pneumon...    0   \n",
       "1   21  [['VIH (Primo-infection)', 0.5189500564407601]...    0   \n",
       "2   19  [['Bronchite', 0.11278064619119596], ['Pneumon...    1   \n",
       "\n",
       "               PATHOLOGY INITIAL_EVIDENCE  I30  diarrhee  bode  \\\n",
       "0        IVRS ou virémie           fievre    0         0     0   \n",
       "1  VIH (Primo-infection)            diaph    0         1     0   \n",
       "2              Pneumonie          expecto    0         0     0   \n",
       "\n",
       "   lesions_peau_endroitducorps_@_face_dorsale_main_D_  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "\n",
       "   douleurxx_irrad_@_sous_la_machoire  ...  etourdissement  hernie_hiatale  \\\n",
       "0                                   0  ...               0               0   \n",
       "1                                   0  ...               0               0   \n",
       "2                                   0  ...               0               0   \n",
       "\n",
       "   douleurxx_irrad_@_trachée  douleurxx_endroitducorps_@_orteil__1__G_  ww_dd  \\\n",
       "0                          0                                         0      0   \n",
       "1                          0                                         0      0   \n",
       "2                          0                                         0      0   \n",
       "\n",
       "   lesions_peau_endroitducorps_@_petite_lèvre_G_  lesions_peau_elevee_@_2  \\\n",
       "0                                              0                        0   \n",
       "1                                              0                        0   \n",
       "2                                              0                        0   \n",
       "\n",
       "   j17_j18  lesions_peau_intens_@_0  lesions_peau_endroitducorps_@_vagin  \n",
       "0        0                        0                                    0  \n",
       "1        0                        0                                    0  \n",
       "2        1                        1                                    0  \n",
       "\n",
       "[3 rows x 521 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the head of the train dataset\n",
    "train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5952a0af",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c0d101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize 'AGE' between 0 and 1\n",
    "scaler = MinMaxScaler()\n",
    "train['AGE'] = scaler.fit_transform(train[['AGE']])\n",
    "validate['AGE'] = scaler.fit_transform(validate[['AGE']])\n",
    "test['AGE'] = scaler.fit_transform(test[['AGE']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e439ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to convert string representation of list to actual list\n",
    "def convert_list_diagnosis(diagnosis_list):\n",
    "    if isinstance(diagnosis_list, str):\n",
    "        try:\n",
    "            return ast.literal_eval(diagnosis_list)\n",
    "        except Exception as e: \n",
    "            return None \n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d29ff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the actual dataset\n",
    "train['DIFFERENTIAL_DIAGNOSIS'] = train['DIFFERENTIAL_DIAGNOSIS'].apply(convert_list_diagnosis)\n",
    "validate['DIFFERENTIAL_DIAGNOSIS'] = validate['DIFFERENTIAL_DIAGNOSIS'].apply(convert_list_diagnosis)\n",
    "test['DIFFERENTIAL_DIAGNOSIS'] = test['DIFFERENTIAL_DIAGNOSIS'].apply(convert_list_diagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d8567f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          [[Bronchite, 0.19171203430383882], [Pneumonie,...\n",
       "1          [[VIH (Primo-infection), 0.5189500564407601], ...\n",
       "2          [[Bronchite, 0.11278064619119596], [Pneumonie,...\n",
       "3          [[IVRS ou virémie, 0.23859396799565236], [Céph...\n",
       "4          [[IVRS ou virémie, 0.23677812769175735], [Poss...\n",
       "                                 ...                        \n",
       "1025597    [[Épiglottite, 0.28156957795466475], [VIH (Pri...\n",
       "1025598    [[Épiglottite, 0.3703962237298842], [Laryngosp...\n",
       "1025599    [[Épiglottite, 0.13193905052537108], [Laryngo-...\n",
       "1025600    [[Épiglottite, 0.3028258988138983], [Laryngite...\n",
       "1025601    [[Épiglottite, 0.12896823203696775], [Laryngit...\n",
       "Name: DIFFERENTIAL_DIAGNOSIS, Length: 1025602, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "train['DIFFERENTIAL_DIAGNOSIS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "306d3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to one-hot-encode the differential diagnosis \n",
    "def one_hot_encode_diagnosis(df, column_name):\n",
    "    # ensure that each diagnosis list is correctly formatted\n",
    "    df[column_name] = df[column_name].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "    # flatten the list of all possible diagnoses, taking only the diagnosis name (first item of each sublist)\n",
    "    all_diagnoses = set(diagnosis[0] for sublist in df[column_name] for diagnosis in sublist if isinstance(diagnosis, list) and len(diagnosis) > 0)\n",
    "    \n",
    "    # initialize a dictionary to hold the one-hot encoded data\n",
    "    one_hot_encoded_data = {diagnosis: [] for diagnosis in all_diagnoses}\n",
    "    \n",
    "    # populate the dictionary with 1s and 0s based on diagnosis presence\n",
    "    for index, row in df.iterrows():\n",
    "        present_diagnoses = {diagnosis[0] for diagnosis in row[column_name] if isinstance(diagnosis, list) and len(diagnosis) > 0}\n",
    "        for diagnosis in all_diagnoses:\n",
    "            one_hot_encoded_data[diagnosis].append(1 if diagnosis in present_diagnoses else 0)\n",
    "    \n",
    "    # convert the dictionary to a DataFrame\n",
    "    one_hot_y = pd.DataFrame(one_hot_encoded_data)\n",
    "    \n",
    "    return one_hot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b5c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function to the dataset to do one-hot-encode for 'Differential Diagnosis'\n",
    "train_y = one_hot_encode_diagnosis(train, 'DIFFERENTIAL_DIAGNOSIS')\n",
    "validate_y = one_hot_encode_diagnosis(validate, 'DIFFERENTIAL_DIAGNOSIS')\n",
    "test_y = one_hot_encode_diagnosis(test, 'DIFFERENTIAL_DIAGNOSIS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89b761c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VIH (Primo-infection)</th>\n",
       "      <th>Asthme exacerbé ou bronchospasme</th>\n",
       "      <th>Pneumonie</th>\n",
       "      <th>Épiglottite</th>\n",
       "      <th>Angine instable</th>\n",
       "      <th>Céphalée en grappe</th>\n",
       "      <th>RGO</th>\n",
       "      <th>Otite moyenne aigue (OMA)</th>\n",
       "      <th>Anémie</th>\n",
       "      <th>Syndrome de Boerhaave</th>\n",
       "      <th>...</th>\n",
       "      <th>Hernie inguinale</th>\n",
       "      <th>Embolie pulmonaire</th>\n",
       "      <th>IVRS ou virémie</th>\n",
       "      <th>Possible influenza ou syndrome virémique typique</th>\n",
       "      <th>Oedème localisé ou généralisé sans atteinte pulmonaire associée</th>\n",
       "      <th>Sarcoïdose</th>\n",
       "      <th>TSVP</th>\n",
       "      <th>Possible NSTEMI / STEMI</th>\n",
       "      <th>Tuberculose</th>\n",
       "      <th>Laryngospasme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   VIH (Primo-infection)  Asthme exacerbé ou bronchospasme  Pneumonie  \\\n",
       "0                      1                                 0          1   \n",
       "1                      1                                 0          0   \n",
       "2                      0                                 0          1   \n",
       "\n",
       "   Épiglottite  Angine instable  Céphalée en grappe  RGO  \\\n",
       "0            0                0                   0    0   \n",
       "1            0                0                   0    0   \n",
       "2            0                1                   0    1   \n",
       "\n",
       "   Otite moyenne aigue (OMA)  Anémie  Syndrome de Boerhaave  ...  \\\n",
       "0                          0       0                      0  ...   \n",
       "1                          0       0                      0  ...   \n",
       "2                          0       0                      1  ...   \n",
       "\n",
       "   Hernie inguinale  Embolie pulmonaire  IVRS ou virémie  \\\n",
       "0                 0                   0                1   \n",
       "1                 0                   0                0   \n",
       "2                 0                   0                1   \n",
       "\n",
       "   Possible influenza ou syndrome virémique typique  \\\n",
       "0                                                 1   \n",
       "1                                                 0   \n",
       "2                                                 0   \n",
       "\n",
       "   Oedème localisé ou généralisé sans atteinte pulmonaire associée  \\\n",
       "0                                                  0                 \n",
       "1                                                  0                 \n",
       "2                                                  0                 \n",
       "\n",
       "   Sarcoïdose  TSVP  Possible NSTEMI / STEMI  Tuberculose  Laryngospasme  \n",
       "0           0     0                        0            1              0  \n",
       "1           1     0                        0            0              0  \n",
       "2           1     0                        1            0              0  \n",
       "\n",
       "[3 rows x 49 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "train_y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c62412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function for spliting dataset and drop columns\n",
    "def data_pre(df, target_columns):\n",
    "    targets = {}\n",
    "    for column in target_columns:\n",
    "        targets[column] = df[column].copy()\n",
    "        df = df.drop(column, axis=1)\n",
    "    \n",
    "    data_X = df\n",
    "    return data_X, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f077a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target columns we want to move from the train dataset\n",
    "target_columns = ['PATHOLOGY', 'DIFFERENTIAL_DIAGNOSIS', 'INITIAL_EVIDENCE']\n",
    "# apply the function to train dataset\n",
    "train_X, train_targets = data_pre(train, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f5e1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target columns we want to move from the train dataset\n",
    "target_columns = ['PATHOLOGY', 'DIFFERENTIAL_DIAGNOSIS', 'INITIAL_EVIDENCE']\n",
    "# apply the function to train dataset\n",
    "test_X, test_targets = data_pre(test, target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6acbcb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>I30</th>\n",
       "      <th>diarrhee</th>\n",
       "      <th>bode</th>\n",
       "      <th>lesions_peau_endroitducorps_@_face_dorsale_main_D_</th>\n",
       "      <th>douleurxx_irrad_@_sous_la_machoire</th>\n",
       "      <th>douleurxx_irrad_@_cartilage_thyroidien</th>\n",
       "      <th>douleurxx_irrad_@_arrière_de_tête</th>\n",
       "      <th>douleurxx_endroitducorps_@_hypochondre_G_</th>\n",
       "      <th>...</th>\n",
       "      <th>etourdissement</th>\n",
       "      <th>hernie_hiatale</th>\n",
       "      <th>douleurxx_irrad_@_trachée</th>\n",
       "      <th>douleurxx_endroitducorps_@_orteil__1__G_</th>\n",
       "      <th>ww_dd</th>\n",
       "      <th>lesions_peau_endroitducorps_@_petite_lèvre_G_</th>\n",
       "      <th>lesions_peau_elevee_@_2</th>\n",
       "      <th>j17_j18</th>\n",
       "      <th>lesions_peau_intens_@_0</th>\n",
       "      <th>lesions_peau_endroitducorps_@_vagin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.165138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.192661</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.174312</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 518 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AGE  SEX  I30  diarrhee  bode  \\\n",
       "0  0.165138    0    0         0     0   \n",
       "1  0.192661    0    0         1     0   \n",
       "2  0.174312    1    0         0     0   \n",
       "\n",
       "   lesions_peau_endroitducorps_@_face_dorsale_main_D_  \\\n",
       "0                                                  0    \n",
       "1                                                  0    \n",
       "2                                                  0    \n",
       "\n",
       "   douleurxx_irrad_@_sous_la_machoire  douleurxx_irrad_@_cartilage_thyroidien  \\\n",
       "0                                   0                                       0   \n",
       "1                                   0                                       0   \n",
       "2                                   0                                       0   \n",
       "\n",
       "   douleurxx_irrad_@_arrière_de_tête  \\\n",
       "0                                  0   \n",
       "1                                  0   \n",
       "2                                  0   \n",
       "\n",
       "   douleurxx_endroitducorps_@_hypochondre_G_  ...  etourdissement  \\\n",
       "0                                          0  ...               0   \n",
       "1                                          0  ...               0   \n",
       "2                                          0  ...               0   \n",
       "\n",
       "   hernie_hiatale  douleurxx_irrad_@_trachée  \\\n",
       "0               0                          0   \n",
       "1               0                          0   \n",
       "2               0                          0   \n",
       "\n",
       "   douleurxx_endroitducorps_@_orteil__1__G_  ww_dd  \\\n",
       "0                                         0      0   \n",
       "1                                         0      0   \n",
       "2                                         0      0   \n",
       "\n",
       "   lesions_peau_endroitducorps_@_petite_lèvre_G_  lesions_peau_elevee_@_2  \\\n",
       "0                                              0                        0   \n",
       "1                                              0                        0   \n",
       "2                                              0                        0   \n",
       "\n",
       "   j17_j18  lesions_peau_intens_@_0  lesions_peau_endroitducorps_@_vagin  \n",
       "0        0                        0                                    0  \n",
       "1        0                        0                                    0  \n",
       "2        1                        1                                    0  \n",
       "\n",
       "[3 rows x 518 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "train_X.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ede854e",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c985eba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the working environment\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c54c4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a three layers RNN model\n",
    "# class RNNModel(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(RNNModel, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "        \n",
    "#         # first RNN layer\n",
    "#         self.rnn1 = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "#         # second RNN layer - Takes input from the first RNN layer\n",
    "#         self.rnn2 = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
    "        \n",
    "#         # linear layers\n",
    "#         self.fc1 = nn.Linear(hidden_size, hidden_size // 2)  # Intermediate linear layer\n",
    "#         self.fc2 = nn.Linear(hidden_size // 2, output_size)  # Final output layer\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "#         # pass through the first RNN layer\n",
    "#         out, _ = self.rnn1(x, h0)\n",
    "#         # pass the output of the first RNN layer to the second RNN layer\n",
    "#         out, _ = self.rnn2(out, h0)\n",
    "        \n",
    "#         # passing the output of the last time step through linear layers\n",
    "#         out = self.fc1(out[:, -1, :])\n",
    "#         out = self.fc2(out)\n",
    "#         return out\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # First LSTM layer\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        # Second LSTM layer - Takes input from the first LSTM layer\n",
    "        self.lstm2 = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        \n",
    "        # Linear layers\n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)  # Intermediate linear layer\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, output_size)  # Final output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states with zeros\n",
    "        h0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Pass through the first LSTM layer\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        # Pass the output of the first LSTM layer to the second LSTM layer\n",
    "        out, _ = self.lstm2(out, (h0, c0))\n",
    "        \n",
    "        # Passing the output of the last time step through linear layers\n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "input_size = train_X.shape[1]  # number of features\n",
    "hidden_size = 64\n",
    "output_size = len(set(train_y))  # number of unique diagnoses\n",
    "\n",
    "model = LSTMModel(input_size, hidden_size, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d49167d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert arrays to PyTorch tensors and move them to the specified device\n",
    "X_train_tensor = torch.tensor(train_X.values, dtype=torch.float).to(device)\n",
    "y_train_tensor = torch.tensor(train_y.values, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12eacc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TensorDataset and DataLoader for batch processing\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0834a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40e50b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of eposhes\n",
    "num_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f7f80280",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/40], Step [100/16026], Loss: 0.3915\n",
      "Epoch [1/40], Step [200/16026], Loss: 0.3230\n",
      "Epoch [1/40], Step [300/16026], Loss: 0.2710\n",
      "Epoch [1/40], Step [400/16026], Loss: 0.2250\n",
      "Epoch [1/40], Step [500/16026], Loss: 0.2066\n",
      "Epoch [1/40], Step [600/16026], Loss: 0.2033\n",
      "Epoch [1/40], Step [700/16026], Loss: 0.1720\n",
      "Epoch [1/40], Step [800/16026], Loss: 0.1781\n",
      "Epoch [1/40], Step [900/16026], Loss: 0.1717\n",
      "Epoch [1/40], Step [1000/16026], Loss: 0.1617\n",
      "Epoch [1/40], Step [1100/16026], Loss: 0.1649\n",
      "Epoch [1/40], Step [1200/16026], Loss: 0.1453\n",
      "Epoch [1/40], Step [1300/16026], Loss: 0.1633\n",
      "Epoch [1/40], Step [1400/16026], Loss: 0.1204\n",
      "Epoch [1/40], Step [1500/16026], Loss: 0.1305\n",
      "Epoch [1/40], Step [1600/16026], Loss: 0.1183\n",
      "Epoch [1/40], Step [1700/16026], Loss: 0.1063\n",
      "Epoch [1/40], Step [1800/16026], Loss: 0.1053\n",
      "Epoch [1/40], Step [1900/16026], Loss: 0.1038\n",
      "Epoch [1/40], Step [2000/16026], Loss: 0.1146\n",
      "Epoch [1/40], Step [2100/16026], Loss: 0.1186\n",
      "Epoch [1/40], Step [2200/16026], Loss: 0.1115\n",
      "Epoch [1/40], Step [2300/16026], Loss: 0.0893\n",
      "Epoch [1/40], Step [2400/16026], Loss: 0.1260\n",
      "Epoch [1/40], Step [2500/16026], Loss: 0.0962\n",
      "Epoch [1/40], Step [2600/16026], Loss: 0.1054\n",
      "Epoch [1/40], Step [2700/16026], Loss: 0.0987\n",
      "Epoch [1/40], Step [2800/16026], Loss: 0.1017\n",
      "Epoch [1/40], Step [2900/16026], Loss: 0.0839\n",
      "Epoch [1/40], Step [3000/16026], Loss: 0.0807\n",
      "Epoch [1/40], Step [3100/16026], Loss: 0.0889\n",
      "Epoch [1/40], Step [3200/16026], Loss: 0.1035\n",
      "Epoch [1/40], Step [3300/16026], Loss: 0.0845\n",
      "Epoch [1/40], Step [3400/16026], Loss: 0.0876\n",
      "Epoch [1/40], Step [3500/16026], Loss: 0.0984\n",
      "Epoch [1/40], Step [3600/16026], Loss: 0.0737\n",
      "Epoch [1/40], Step [3700/16026], Loss: 0.0969\n",
      "Epoch [1/40], Step [3800/16026], Loss: 0.0813\n",
      "Epoch [1/40], Step [3900/16026], Loss: 0.0761\n",
      "Epoch [1/40], Step [4000/16026], Loss: 0.0672\n",
      "Epoch [1/40], Step [4100/16026], Loss: 0.0955\n",
      "Epoch [1/40], Step [4200/16026], Loss: 0.0674\n",
      "Epoch [1/40], Step [4300/16026], Loss: 0.0761\n",
      "Epoch [1/40], Step [4400/16026], Loss: 0.0800\n",
      "Epoch [1/40], Step [4500/16026], Loss: 0.0838\n",
      "Epoch [1/40], Step [4600/16026], Loss: 0.0831\n",
      "Epoch [1/40], Step [4700/16026], Loss: 0.0727\n",
      "Epoch [1/40], Step [4800/16026], Loss: 0.0840\n",
      "Epoch [1/40], Step [4900/16026], Loss: 0.0544\n",
      "Epoch [1/40], Step [5000/16026], Loss: 0.0819\n",
      "Epoch [1/40], Step [5100/16026], Loss: 0.0723\n",
      "Epoch [1/40], Step [5200/16026], Loss: 0.0700\n",
      "Epoch [1/40], Step [5300/16026], Loss: 0.0679\n",
      "Epoch [1/40], Step [5400/16026], Loss: 0.0711\n",
      "Epoch [1/40], Step [5500/16026], Loss: 0.0703\n",
      "Epoch [1/40], Step [5600/16026], Loss: 0.0681\n",
      "Epoch [1/40], Step [5700/16026], Loss: 0.0561\n",
      "Epoch [1/40], Step [5800/16026], Loss: 0.0747\n",
      "Epoch [1/40], Step [5900/16026], Loss: 0.0636\n",
      "Epoch [1/40], Step [6000/16026], Loss: 0.0559\n",
      "Epoch [1/40], Step [6100/16026], Loss: 0.0646\n",
      "Epoch [1/40], Step [6200/16026], Loss: 0.0644\n",
      "Epoch [1/40], Step [6300/16026], Loss: 0.0943\n",
      "Epoch [1/40], Step [6400/16026], Loss: 0.0767\n",
      "Epoch [1/40], Step [6500/16026], Loss: 0.0665\n",
      "Epoch [1/40], Step [6600/16026], Loss: 0.0779\n",
      "Epoch [1/40], Step [6700/16026], Loss: 0.0595\n",
      "Epoch [1/40], Step [6800/16026], Loss: 0.0686\n",
      "Epoch [1/40], Step [6900/16026], Loss: 0.0626\n",
      "Epoch [1/40], Step [7000/16026], Loss: 0.0599\n",
      "Epoch [1/40], Step [7100/16026], Loss: 0.0536\n",
      "Epoch [1/40], Step [7200/16026], Loss: 0.0569\n",
      "Epoch [1/40], Step [7300/16026], Loss: 0.0718\n",
      "Epoch [1/40], Step [7400/16026], Loss: 0.0643\n",
      "Epoch [1/40], Step [7500/16026], Loss: 0.0491\n",
      "Epoch [1/40], Step [7600/16026], Loss: 0.0595\n",
      "Epoch [1/40], Step [7700/16026], Loss: 0.0705\n",
      "Epoch [1/40], Step [7800/16026], Loss: 0.0552\n",
      "Epoch [1/40], Step [7900/16026], Loss: 0.0687\n",
      "Epoch [1/40], Step [8000/16026], Loss: 0.0570\n",
      "Epoch [1/40], Step [8100/16026], Loss: 0.0532\n",
      "Epoch [1/40], Step [8200/16026], Loss: 0.0650\n",
      "Epoch [1/40], Step [8300/16026], Loss: 0.0530\n",
      "Epoch [1/40], Step [8400/16026], Loss: 0.0696\n",
      "Epoch [1/40], Step [8500/16026], Loss: 0.0427\n",
      "Epoch [1/40], Step [8600/16026], Loss: 0.0527\n",
      "Epoch [1/40], Step [8700/16026], Loss: 0.0604\n",
      "Epoch [1/40], Step [8800/16026], Loss: 0.0490\n",
      "Epoch [1/40], Step [8900/16026], Loss: 0.0518\n",
      "Epoch [1/40], Step [9000/16026], Loss: 0.0622\n",
      "Epoch [1/40], Step [9100/16026], Loss: 0.0681\n",
      "Epoch [1/40], Step [9200/16026], Loss: 0.0673\n",
      "Epoch [1/40], Step [9300/16026], Loss: 0.0564\n",
      "Epoch [1/40], Step [9400/16026], Loss: 0.0558\n",
      "Epoch [1/40], Step [9500/16026], Loss: 0.0541\n",
      "Epoch [1/40], Step [9600/16026], Loss: 0.0471\n",
      "Epoch [1/40], Step [9700/16026], Loss: 0.0397\n",
      "Epoch [1/40], Step [9800/16026], Loss: 0.0586\n",
      "Epoch [1/40], Step [9900/16026], Loss: 0.0438\n",
      "Epoch [1/40], Step [10000/16026], Loss: 0.0521\n",
      "Epoch [1/40], Step [10100/16026], Loss: 0.0504\n",
      "Epoch [1/40], Step [10200/16026], Loss: 0.0486\n",
      "Epoch [1/40], Step [10300/16026], Loss: 0.0537\n",
      "Epoch [1/40], Step [10400/16026], Loss: 0.0496\n",
      "Epoch [1/40], Step [10500/16026], Loss: 0.0504\n",
      "Epoch [1/40], Step [10600/16026], Loss: 0.0550\n",
      "Epoch [1/40], Step [10700/16026], Loss: 0.0460\n",
      "Epoch [1/40], Step [10800/16026], Loss: 0.0517\n",
      "Epoch [1/40], Step [10900/16026], Loss: 0.0491\n",
      "Epoch [1/40], Step [11000/16026], Loss: 0.0471\n",
      "Epoch [1/40], Step [11100/16026], Loss: 0.0666\n",
      "Epoch [1/40], Step [11200/16026], Loss: 0.0464\n",
      "Epoch [1/40], Step [11300/16026], Loss: 0.0620\n",
      "Epoch [1/40], Step [11400/16026], Loss: 0.0627\n",
      "Epoch [1/40], Step [11500/16026], Loss: 0.0361\n",
      "Epoch [1/40], Step [11600/16026], Loss: 0.0412\n",
      "Epoch [1/40], Step [11700/16026], Loss: 0.0560\n",
      "Epoch [1/40], Step [11800/16026], Loss: 0.0373\n",
      "Epoch [1/40], Step [11900/16026], Loss: 0.0403\n",
      "Epoch [1/40], Step [12000/16026], Loss: 0.0491\n",
      "Epoch [1/40], Step [12100/16026], Loss: 0.0482\n",
      "Epoch [1/40], Step [12200/16026], Loss: 0.0493\n",
      "Epoch [1/40], Step [12300/16026], Loss: 0.0505\n",
      "Epoch [1/40], Step [12400/16026], Loss: 0.0573\n",
      "Epoch [1/40], Step [12500/16026], Loss: 0.0336\n",
      "Epoch [1/40], Step [12600/16026], Loss: 0.0421\n",
      "Epoch [1/40], Step [12700/16026], Loss: 0.0384\n",
      "Epoch [1/40], Step [12800/16026], Loss: 0.0482\n",
      "Epoch [1/40], Step [12900/16026], Loss: 0.0369\n",
      "Epoch [1/40], Step [13000/16026], Loss: 0.0650\n",
      "Epoch [1/40], Step [13100/16026], Loss: 0.0327\n",
      "Epoch [1/40], Step [13200/16026], Loss: 0.0392\n",
      "Epoch [1/40], Step [13300/16026], Loss: 0.0376\n",
      "Epoch [1/40], Step [13400/16026], Loss: 0.0364\n",
      "Epoch [1/40], Step [13500/16026], Loss: 0.0460\n",
      "Epoch [1/40], Step [13600/16026], Loss: 0.0580\n",
      "Epoch [1/40], Step [13700/16026], Loss: 0.0472\n",
      "Epoch [1/40], Step [13800/16026], Loss: 0.0562\n",
      "Epoch [1/40], Step [13900/16026], Loss: 0.0485\n",
      "Epoch [1/40], Step [14000/16026], Loss: 0.0492\n",
      "Epoch [1/40], Step [14100/16026], Loss: 0.0366\n",
      "Epoch [1/40], Step [14200/16026], Loss: 0.0468\n",
      "Epoch [1/40], Step [14300/16026], Loss: 0.0539\n",
      "Epoch [1/40], Step [14400/16026], Loss: 0.0383\n",
      "Epoch [1/40], Step [14500/16026], Loss: 0.0429\n",
      "Epoch [1/40], Step [14600/16026], Loss: 0.0394\n",
      "Epoch [1/40], Step [14700/16026], Loss: 0.0570\n",
      "Epoch [1/40], Step [14800/16026], Loss: 0.0500\n",
      "Epoch [1/40], Step [14900/16026], Loss: 0.0578\n",
      "Epoch [1/40], Step [15000/16026], Loss: 0.0478\n",
      "Epoch [1/40], Step [15100/16026], Loss: 0.0517\n",
      "Epoch [1/40], Step [15200/16026], Loss: 0.0481\n",
      "Epoch [1/40], Step [15300/16026], Loss: 0.0475\n",
      "Epoch [1/40], Step [15400/16026], Loss: 0.0316\n",
      "Epoch [1/40], Step [15500/16026], Loss: 0.0438\n",
      "Epoch [1/40], Step [15600/16026], Loss: 0.0462\n",
      "Epoch [1/40], Step [15700/16026], Loss: 0.0484\n",
      "Epoch [1/40], Step [15800/16026], Loss: 0.0463\n",
      "Epoch [1/40], Step [15900/16026], Loss: 0.0325\n",
      "Epoch [1/40], Step [16000/16026], Loss: 0.0433\n",
      "Epoch [2/40], Step [100/16026], Loss: 0.0305\n",
      "Epoch [2/40], Step [200/16026], Loss: 0.0442\n",
      "Epoch [2/40], Step [300/16026], Loss: 0.0636\n",
      "Epoch [2/40], Step [400/16026], Loss: 0.0780\n",
      "Epoch [2/40], Step [500/16026], Loss: 0.0391\n",
      "Epoch [2/40], Step [600/16026], Loss: 0.0401\n",
      "Epoch [2/40], Step [700/16026], Loss: 0.0436\n",
      "Epoch [2/40], Step [800/16026], Loss: 0.0353\n",
      "Epoch [2/40], Step [900/16026], Loss: 0.0411\n",
      "Epoch [2/40], Step [1000/16026], Loss: 0.0367\n",
      "Epoch [2/40], Step [1100/16026], Loss: 0.0425\n",
      "Epoch [2/40], Step [1200/16026], Loss: 0.0415\n",
      "Epoch [2/40], Step [1300/16026], Loss: 0.0359\n",
      "Epoch [2/40], Step [1400/16026], Loss: 0.0394\n",
      "Epoch [2/40], Step [1500/16026], Loss: 0.0487\n",
      "Epoch [2/40], Step [1600/16026], Loss: 0.0493\n",
      "Epoch [2/40], Step [1700/16026], Loss: 0.0495\n",
      "Epoch [2/40], Step [1800/16026], Loss: 0.0490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40], Step [1900/16026], Loss: 0.0376\n",
      "Epoch [2/40], Step [2000/16026], Loss: 0.0453\n",
      "Epoch [2/40], Step [2100/16026], Loss: 0.0341\n",
      "Epoch [2/40], Step [2200/16026], Loss: 0.0641\n",
      "Epoch [2/40], Step [2300/16026], Loss: 0.0354\n",
      "Epoch [2/40], Step [2400/16026], Loss: 0.0414\n",
      "Epoch [2/40], Step [2500/16026], Loss: 0.0542\n",
      "Epoch [2/40], Step [2600/16026], Loss: 0.0544\n",
      "Epoch [2/40], Step [2700/16026], Loss: 0.0564\n",
      "Epoch [2/40], Step [2800/16026], Loss: 0.0369\n",
      "Epoch [2/40], Step [2900/16026], Loss: 0.0458\n",
      "Epoch [2/40], Step [3000/16026], Loss: 0.0425\n",
      "Epoch [2/40], Step [3100/16026], Loss: 0.0397\n",
      "Epoch [2/40], Step [3200/16026], Loss: 0.0386\n",
      "Epoch [2/40], Step [3300/16026], Loss: 0.0341\n",
      "Epoch [2/40], Step [3400/16026], Loss: 0.0371\n",
      "Epoch [2/40], Step [3500/16026], Loss: 0.0373\n",
      "Epoch [2/40], Step [3600/16026], Loss: 0.0401\n",
      "Epoch [2/40], Step [3700/16026], Loss: 0.0395\n",
      "Epoch [2/40], Step [3800/16026], Loss: 0.0336\n",
      "Epoch [2/40], Step [3900/16026], Loss: 0.0514\n",
      "Epoch [2/40], Step [4000/16026], Loss: 0.0441\n",
      "Epoch [2/40], Step [4100/16026], Loss: 0.0403\n",
      "Epoch [2/40], Step [4200/16026], Loss: 0.0507\n",
      "Epoch [2/40], Step [4300/16026], Loss: 0.0374\n",
      "Epoch [2/40], Step [4400/16026], Loss: 0.0415\n",
      "Epoch [2/40], Step [4500/16026], Loss: 0.0436\n",
      "Epoch [2/40], Step [4600/16026], Loss: 0.0363\n",
      "Epoch [2/40], Step [4700/16026], Loss: 0.0378\n",
      "Epoch [2/40], Step [4800/16026], Loss: 0.0481\n",
      "Epoch [2/40], Step [4900/16026], Loss: 0.0322\n",
      "Epoch [2/40], Step [5000/16026], Loss: 0.0303\n",
      "Epoch [2/40], Step [5100/16026], Loss: 0.0432\n",
      "Epoch [2/40], Step [5200/16026], Loss: 0.0499\n",
      "Epoch [2/40], Step [5300/16026], Loss: 0.0362\n",
      "Epoch [2/40], Step [5400/16026], Loss: 0.0450\n",
      "Epoch [2/40], Step [5500/16026], Loss: 0.0342\n",
      "Epoch [2/40], Step [5600/16026], Loss: 0.0381\n",
      "Epoch [2/40], Step [5700/16026], Loss: 0.0299\n",
      "Epoch [2/40], Step [5800/16026], Loss: 0.0389\n",
      "Epoch [2/40], Step [5900/16026], Loss: 0.0353\n",
      "Epoch [2/40], Step [6000/16026], Loss: 0.0368\n",
      "Epoch [2/40], Step [6100/16026], Loss: 0.0439\n",
      "Epoch [2/40], Step [6200/16026], Loss: 0.0400\n",
      "Epoch [2/40], Step [6300/16026], Loss: 0.0399\n",
      "Epoch [2/40], Step [6400/16026], Loss: 0.0448\n",
      "Epoch [2/40], Step [6500/16026], Loss: 0.0467\n",
      "Epoch [2/40], Step [6600/16026], Loss: 0.0359\n",
      "Epoch [2/40], Step [6700/16026], Loss: 0.0568\n",
      "Epoch [2/40], Step [6800/16026], Loss: 0.0287\n",
      "Epoch [2/40], Step [6900/16026], Loss: 0.0408\n",
      "Epoch [2/40], Step [7000/16026], Loss: 0.0410\n",
      "Epoch [2/40], Step [7100/16026], Loss: 0.0471\n",
      "Epoch [2/40], Step [7200/16026], Loss: 0.0364\n",
      "Epoch [2/40], Step [7300/16026], Loss: 0.0300\n",
      "Epoch [2/40], Step [7400/16026], Loss: 0.0367\n",
      "Epoch [2/40], Step [7500/16026], Loss: 0.0311\n",
      "Epoch [2/40], Step [7600/16026], Loss: 0.0296\n",
      "Epoch [2/40], Step [7700/16026], Loss: 0.0750\n",
      "Epoch [2/40], Step [7800/16026], Loss: 0.0376\n",
      "Epoch [2/40], Step [7900/16026], Loss: 0.0356\n",
      "Epoch [2/40], Step [8000/16026], Loss: 0.0487\n",
      "Epoch [2/40], Step [8100/16026], Loss: 0.0365\n",
      "Epoch [2/40], Step [8200/16026], Loss: 0.0397\n",
      "Epoch [2/40], Step [8300/16026], Loss: 0.0489\n",
      "Epoch [2/40], Step [8400/16026], Loss: 0.0355\n",
      "Epoch [2/40], Step [8500/16026], Loss: 0.0412\n",
      "Epoch [2/40], Step [8600/16026], Loss: 0.0316\n",
      "Epoch [2/40], Step [8700/16026], Loss: 0.0390\n",
      "Epoch [2/40], Step [8800/16026], Loss: 0.0323\n",
      "Epoch [2/40], Step [8900/16026], Loss: 0.0410\n",
      "Epoch [2/40], Step [9000/16026], Loss: 0.0361\n",
      "Epoch [2/40], Step [9100/16026], Loss: 0.0374\n",
      "Epoch [2/40], Step [9200/16026], Loss: 0.0249\n",
      "Epoch [2/40], Step [9300/16026], Loss: 0.0397\n",
      "Epoch [2/40], Step [9400/16026], Loss: 0.0232\n",
      "Epoch [2/40], Step [9500/16026], Loss: 0.0334\n",
      "Epoch [2/40], Step [9600/16026], Loss: 0.0455\n",
      "Epoch [2/40], Step [9700/16026], Loss: 0.0316\n",
      "Epoch [2/40], Step [9800/16026], Loss: 0.0268\n",
      "Epoch [2/40], Step [9900/16026], Loss: 0.0296\n",
      "Epoch [2/40], Step [10000/16026], Loss: 0.0349\n",
      "Epoch [2/40], Step [10100/16026], Loss: 0.0347\n",
      "Epoch [2/40], Step [10200/16026], Loss: 0.0183\n",
      "Epoch [2/40], Step [10300/16026], Loss: 0.0343\n",
      "Epoch [2/40], Step [10400/16026], Loss: 0.0243\n",
      "Epoch [2/40], Step [10500/16026], Loss: 0.0515\n",
      "Epoch [2/40], Step [10600/16026], Loss: 0.0394\n",
      "Epoch [2/40], Step [10700/16026], Loss: 0.0245\n",
      "Epoch [2/40], Step [10800/16026], Loss: 0.0438\n",
      "Epoch [2/40], Step [10900/16026], Loss: 0.0323\n",
      "Epoch [2/40], Step [11000/16026], Loss: 0.0272\n",
      "Epoch [2/40], Step [11100/16026], Loss: 0.0455\n",
      "Epoch [2/40], Step [11200/16026], Loss: 0.0349\n",
      "Epoch [2/40], Step [11300/16026], Loss: 0.0408\n",
      "Epoch [2/40], Step [11400/16026], Loss: 0.0443\n",
      "Epoch [2/40], Step [11500/16026], Loss: 0.0236\n",
      "Epoch [2/40], Step [11600/16026], Loss: 0.0383\n",
      "Epoch [2/40], Step [11700/16026], Loss: 0.0519\n",
      "Epoch [2/40], Step [11800/16026], Loss: 0.0409\n",
      "Epoch [2/40], Step [11900/16026], Loss: 0.0313\n",
      "Epoch [2/40], Step [12000/16026], Loss: 0.0495\n",
      "Epoch [2/40], Step [12100/16026], Loss: 0.0304\n",
      "Epoch [2/40], Step [12200/16026], Loss: 0.0324\n",
      "Epoch [2/40], Step [12300/16026], Loss: 0.0331\n",
      "Epoch [2/40], Step [12400/16026], Loss: 0.0358\n",
      "Epoch [2/40], Step [12500/16026], Loss: 0.0424\n",
      "Epoch [2/40], Step [12600/16026], Loss: 0.0325\n",
      "Epoch [2/40], Step [12700/16026], Loss: 0.0333\n",
      "Epoch [2/40], Step [12800/16026], Loss: 0.0456\n",
      "Epoch [2/40], Step [12900/16026], Loss: 0.0279\n",
      "Epoch [2/40], Step [13000/16026], Loss: 0.0382\n",
      "Epoch [2/40], Step [13100/16026], Loss: 0.0422\n",
      "Epoch [2/40], Step [13200/16026], Loss: 0.0273\n",
      "Epoch [2/40], Step [13300/16026], Loss: 0.0383\n",
      "Epoch [2/40], Step [13400/16026], Loss: 0.0363\n",
      "Epoch [2/40], Step [13500/16026], Loss: 0.0411\n",
      "Epoch [2/40], Step [13600/16026], Loss: 0.0415\n",
      "Epoch [2/40], Step [13700/16026], Loss: 0.0293\n",
      "Epoch [2/40], Step [13800/16026], Loss: 0.0312\n",
      "Epoch [2/40], Step [13900/16026], Loss: 0.0267\n",
      "Epoch [2/40], Step [14000/16026], Loss: 0.0500\n",
      "Epoch [2/40], Step [14100/16026], Loss: 0.0415\n",
      "Epoch [2/40], Step [14200/16026], Loss: 0.0249\n",
      "Epoch [2/40], Step [14300/16026], Loss: 0.0302\n",
      "Epoch [2/40], Step [14400/16026], Loss: 0.0406\n",
      "Epoch [2/40], Step [14500/16026], Loss: 0.0429\n",
      "Epoch [2/40], Step [14600/16026], Loss: 0.0364\n",
      "Epoch [2/40], Step [14700/16026], Loss: 0.0329\n",
      "Epoch [2/40], Step [14800/16026], Loss: 0.0365\n",
      "Epoch [2/40], Step [14900/16026], Loss: 0.0230\n",
      "Epoch [2/40], Step [15000/16026], Loss: 0.0359\n",
      "Epoch [2/40], Step [15100/16026], Loss: 0.0362\n",
      "Epoch [2/40], Step [15200/16026], Loss: 0.0327\n",
      "Epoch [2/40], Step [15300/16026], Loss: 0.0348\n",
      "Epoch [2/40], Step [15400/16026], Loss: 0.0405\n",
      "Epoch [2/40], Step [15500/16026], Loss: 0.0385\n",
      "Epoch [2/40], Step [15600/16026], Loss: 0.0249\n",
      "Epoch [2/40], Step [15700/16026], Loss: 0.0227\n",
      "Epoch [2/40], Step [15800/16026], Loss: 0.0435\n",
      "Epoch [2/40], Step [15900/16026], Loss: 0.0246\n",
      "Epoch [2/40], Step [16000/16026], Loss: 0.0299\n",
      "Epoch [3/40], Step [100/16026], Loss: 0.0388\n",
      "Epoch [3/40], Step [200/16026], Loss: 0.0328\n",
      "Epoch [3/40], Step [300/16026], Loss: 0.0351\n",
      "Epoch [3/40], Step [400/16026], Loss: 0.0464\n",
      "Epoch [3/40], Step [500/16026], Loss: 0.0242\n",
      "Epoch [3/40], Step [600/16026], Loss: 0.0311\n",
      "Epoch [3/40], Step [700/16026], Loss: 0.0378\n",
      "Epoch [3/40], Step [800/16026], Loss: 0.0243\n",
      "Epoch [3/40], Step [900/16026], Loss: 0.0307\n",
      "Epoch [3/40], Step [1000/16026], Loss: 0.0399\n",
      "Epoch [3/40], Step [1100/16026], Loss: 0.0612\n",
      "Epoch [3/40], Step [1200/16026], Loss: 0.0243\n",
      "Epoch [3/40], Step [1300/16026], Loss: 0.0343\n",
      "Epoch [3/40], Step [1400/16026], Loss: 0.0300\n",
      "Epoch [3/40], Step [1500/16026], Loss: 0.0370\n",
      "Epoch [3/40], Step [1600/16026], Loss: 0.0558\n",
      "Epoch [3/40], Step [1700/16026], Loss: 0.0303\n",
      "Epoch [3/40], Step [1800/16026], Loss: 0.0314\n",
      "Epoch [3/40], Step [1900/16026], Loss: 0.0285\n",
      "Epoch [3/40], Step [2000/16026], Loss: 0.0309\n",
      "Epoch [3/40], Step [2100/16026], Loss: 0.0295\n",
      "Epoch [3/40], Step [2200/16026], Loss: 0.0291\n",
      "Epoch [3/40], Step [2300/16026], Loss: 0.0300\n",
      "Epoch [3/40], Step [2400/16026], Loss: 0.0349\n",
      "Epoch [3/40], Step [2500/16026], Loss: 0.0346\n",
      "Epoch [3/40], Step [2600/16026], Loss: 0.0423\n",
      "Epoch [3/40], Step [2700/16026], Loss: 0.0461\n",
      "Epoch [3/40], Step [2800/16026], Loss: 0.0316\n",
      "Epoch [3/40], Step [2900/16026], Loss: 0.0208\n",
      "Epoch [3/40], Step [3000/16026], Loss: 0.0346\n",
      "Epoch [3/40], Step [3100/16026], Loss: 0.0373\n",
      "Epoch [3/40], Step [3200/16026], Loss: 0.0286\n",
      "Epoch [3/40], Step [3300/16026], Loss: 0.0246\n",
      "Epoch [3/40], Step [3400/16026], Loss: 0.0322\n",
      "Epoch [3/40], Step [3500/16026], Loss: 0.0256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/40], Step [3600/16026], Loss: 0.0471\n",
      "Epoch [3/40], Step [3700/16026], Loss: 0.0419\n",
      "Epoch [3/40], Step [3800/16026], Loss: 0.0380\n",
      "Epoch [3/40], Step [3900/16026], Loss: 0.0419\n",
      "Epoch [3/40], Step [4000/16026], Loss: 0.0359\n",
      "Epoch [3/40], Step [4100/16026], Loss: 0.0332\n",
      "Epoch [3/40], Step [4200/16026], Loss: 0.0434\n",
      "Epoch [3/40], Step [4300/16026], Loss: 0.0337\n",
      "Epoch [3/40], Step [4400/16026], Loss: 0.0431\n",
      "Epoch [3/40], Step [4500/16026], Loss: 0.0324\n",
      "Epoch [3/40], Step [4600/16026], Loss: 0.0253\n",
      "Epoch [3/40], Step [4700/16026], Loss: 0.0443\n",
      "Epoch [3/40], Step [4800/16026], Loss: 0.0304\n",
      "Epoch [3/40], Step [4900/16026], Loss: 0.0313\n",
      "Epoch [3/40], Step [5000/16026], Loss: 0.0232\n",
      "Epoch [3/40], Step [5100/16026], Loss: 0.0354\n",
      "Epoch [3/40], Step [5200/16026], Loss: 0.0213\n",
      "Epoch [3/40], Step [5300/16026], Loss: 0.0372\n",
      "Epoch [3/40], Step [5400/16026], Loss: 0.0383\n",
      "Epoch [3/40], Step [5500/16026], Loss: 0.0392\n",
      "Epoch [3/40], Step [5600/16026], Loss: 0.0444\n",
      "Epoch [3/40], Step [5700/16026], Loss: 0.0408\n",
      "Epoch [3/40], Step [5800/16026], Loss: 0.0693\n",
      "Epoch [3/40], Step [5900/16026], Loss: 0.0360\n",
      "Epoch [3/40], Step [6000/16026], Loss: 0.0214\n",
      "Epoch [3/40], Step [6100/16026], Loss: 0.0266\n",
      "Epoch [3/40], Step [6200/16026], Loss: 0.0245\n",
      "Epoch [3/40], Step [6300/16026], Loss: 0.0371\n",
      "Epoch [3/40], Step [6400/16026], Loss: 0.0373\n",
      "Epoch [3/40], Step [6500/16026], Loss: 0.0381\n",
      "Epoch [3/40], Step [6600/16026], Loss: 0.0275\n",
      "Epoch [3/40], Step [6700/16026], Loss: 0.0288\n",
      "Epoch [3/40], Step [6800/16026], Loss: 0.0323\n",
      "Epoch [3/40], Step [6900/16026], Loss: 0.0382\n",
      "Epoch [3/40], Step [7000/16026], Loss: 0.0320\n",
      "Epoch [3/40], Step [7100/16026], Loss: 0.0243\n",
      "Epoch [3/40], Step [7200/16026], Loss: 0.0355\n",
      "Epoch [3/40], Step [7300/16026], Loss: 0.0315\n",
      "Epoch [3/40], Step [7400/16026], Loss: 0.0367\n",
      "Epoch [3/40], Step [7500/16026], Loss: 0.0156\n",
      "Epoch [3/40], Step [7600/16026], Loss: 0.0328\n",
      "Epoch [3/40], Step [7700/16026], Loss: 0.0298\n",
      "Epoch [3/40], Step [7800/16026], Loss: 0.0274\n",
      "Epoch [3/40], Step [7900/16026], Loss: 0.0361\n",
      "Epoch [3/40], Step [8000/16026], Loss: 0.0294\n",
      "Epoch [3/40], Step [8100/16026], Loss: 0.0230\n",
      "Epoch [3/40], Step [8200/16026], Loss: 0.0233\n",
      "Epoch [3/40], Step [8300/16026], Loss: 0.0358\n",
      "Epoch [3/40], Step [8400/16026], Loss: 0.0360\n",
      "Epoch [3/40], Step [8500/16026], Loss: 0.0299\n",
      "Epoch [3/40], Step [8600/16026], Loss: 0.0382\n",
      "Epoch [3/40], Step [8700/16026], Loss: 0.0314\n",
      "Epoch [3/40], Step [8800/16026], Loss: 0.0235\n",
      "Epoch [3/40], Step [8900/16026], Loss: 0.0473\n",
      "Epoch [3/40], Step [9000/16026], Loss: 0.0330\n",
      "Epoch [3/40], Step [9100/16026], Loss: 0.0490\n",
      "Epoch [3/40], Step [9200/16026], Loss: 0.0307\n",
      "Epoch [3/40], Step [9300/16026], Loss: 0.0253\n",
      "Epoch [3/40], Step [9400/16026], Loss: 0.0310\n",
      "Epoch [3/40], Step [9500/16026], Loss: 0.0338\n",
      "Epoch [3/40], Step [9600/16026], Loss: 0.0256\n",
      "Epoch [3/40], Step [9700/16026], Loss: 0.0392\n",
      "Epoch [3/40], Step [9800/16026], Loss: 0.0330\n",
      "Epoch [3/40], Step [9900/16026], Loss: 0.0269\n",
      "Epoch [3/40], Step [10000/16026], Loss: 0.0301\n",
      "Epoch [3/40], Step [10100/16026], Loss: 0.0178\n",
      "Epoch [3/40], Step [10200/16026], Loss: 0.0285\n",
      "Epoch [3/40], Step [10300/16026], Loss: 0.0241\n",
      "Epoch [3/40], Step [10400/16026], Loss: 0.0308\n",
      "Epoch [3/40], Step [10500/16026], Loss: 0.0313\n",
      "Epoch [3/40], Step [10600/16026], Loss: 0.0270\n",
      "Epoch [3/40], Step [10700/16026], Loss: 0.0313\n",
      "Epoch [3/40], Step [10800/16026], Loss: 0.0620\n",
      "Epoch [3/40], Step [10900/16026], Loss: 0.0312\n",
      "Epoch [3/40], Step [11000/16026], Loss: 0.0220\n",
      "Epoch [3/40], Step [11100/16026], Loss: 0.0287\n",
      "Epoch [3/40], Step [11200/16026], Loss: 0.0352\n",
      "Epoch [3/40], Step [11300/16026], Loss: 0.0238\n",
      "Epoch [3/40], Step [11400/16026], Loss: 0.0314\n",
      "Epoch [3/40], Step [11500/16026], Loss: 0.0451\n",
      "Epoch [3/40], Step [11600/16026], Loss: 0.0399\n",
      "Epoch [3/40], Step [11700/16026], Loss: 0.0346\n",
      "Epoch [3/40], Step [11800/16026], Loss: 0.0337\n",
      "Epoch [3/40], Step [11900/16026], Loss: 0.0398\n",
      "Epoch [3/40], Step [12000/16026], Loss: 0.0305\n",
      "Epoch [3/40], Step [12100/16026], Loss: 0.0397\n",
      "Epoch [3/40], Step [12200/16026], Loss: 0.0202\n",
      "Epoch [3/40], Step [12300/16026], Loss: 0.0337\n",
      "Epoch [3/40], Step [12400/16026], Loss: 0.0263\n",
      "Epoch [3/40], Step [12500/16026], Loss: 0.0311\n",
      "Epoch [3/40], Step [12600/16026], Loss: 0.0262\n",
      "Epoch [3/40], Step [12700/16026], Loss: 0.0284\n",
      "Epoch [3/40], Step [12800/16026], Loss: 0.0282\n",
      "Epoch [3/40], Step [12900/16026], Loss: 0.0318\n",
      "Epoch [3/40], Step [13000/16026], Loss: 0.0415\n",
      "Epoch [3/40], Step [13100/16026], Loss: 0.0226\n",
      "Epoch [3/40], Step [13200/16026], Loss: 0.0360\n",
      "Epoch [3/40], Step [13300/16026], Loss: 0.0226\n",
      "Epoch [3/40], Step [13400/16026], Loss: 0.0275\n",
      "Epoch [3/40], Step [13500/16026], Loss: 0.0280\n",
      "Epoch [3/40], Step [13600/16026], Loss: 0.0373\n",
      "Epoch [3/40], Step [13700/16026], Loss: 0.0349\n",
      "Epoch [3/40], Step [13800/16026], Loss: 0.0420\n",
      "Epoch [3/40], Step [13900/16026], Loss: 0.0718\n",
      "Epoch [3/40], Step [14000/16026], Loss: 0.0301\n",
      "Epoch [3/40], Step [14100/16026], Loss: 0.0269\n",
      "Epoch [3/40], Step [14200/16026], Loss: 0.0308\n",
      "Epoch [3/40], Step [14300/16026], Loss: 0.0302\n",
      "Epoch [3/40], Step [14400/16026], Loss: 0.0367\n",
      "Epoch [3/40], Step [14500/16026], Loss: 0.0419\n",
      "Epoch [3/40], Step [14600/16026], Loss: 0.0151\n",
      "Epoch [3/40], Step [14700/16026], Loss: 0.0282\n",
      "Epoch [3/40], Step [14800/16026], Loss: 0.0244\n",
      "Epoch [3/40], Step [14900/16026], Loss: 0.0223\n",
      "Epoch [3/40], Step [15000/16026], Loss: 0.0240\n",
      "Epoch [3/40], Step [15100/16026], Loss: 0.0295\n",
      "Epoch [3/40], Step [15200/16026], Loss: 0.0398\n",
      "Epoch [3/40], Step [15300/16026], Loss: 0.0438\n",
      "Epoch [3/40], Step [15400/16026], Loss: 0.0213\n",
      "Epoch [3/40], Step [15500/16026], Loss: 0.0363\n",
      "Epoch [3/40], Step [15600/16026], Loss: 0.0203\n",
      "Epoch [3/40], Step [15700/16026], Loss: 0.0272\n",
      "Epoch [3/40], Step [15800/16026], Loss: 0.0298\n",
      "Epoch [3/40], Step [15900/16026], Loss: 0.0347\n",
      "Epoch [3/40], Step [16000/16026], Loss: 0.0321\n",
      "Epoch [4/40], Step [100/16026], Loss: 0.0335\n",
      "Epoch [4/40], Step [200/16026], Loss: 0.0328\n",
      "Epoch [4/40], Step [300/16026], Loss: 0.0270\n",
      "Epoch [4/40], Step [400/16026], Loss: 0.0480\n",
      "Epoch [4/40], Step [500/16026], Loss: 0.0281\n",
      "Epoch [4/40], Step [600/16026], Loss: 0.0564\n",
      "Epoch [4/40], Step [700/16026], Loss: 0.0352\n",
      "Epoch [4/40], Step [800/16026], Loss: 0.0391\n",
      "Epoch [4/40], Step [900/16026], Loss: 0.0300\n",
      "Epoch [4/40], Step [1000/16026], Loss: 0.0227\n",
      "Epoch [4/40], Step [1100/16026], Loss: 0.0266\n",
      "Epoch [4/40], Step [1200/16026], Loss: 0.0352\n",
      "Epoch [4/40], Step [1300/16026], Loss: 0.0335\n",
      "Epoch [4/40], Step [1400/16026], Loss: 0.0315\n",
      "Epoch [4/40], Step [1500/16026], Loss: 0.0270\n",
      "Epoch [4/40], Step [1600/16026], Loss: 0.0253\n",
      "Epoch [4/40], Step [1700/16026], Loss: 0.0310\n",
      "Epoch [4/40], Step [1800/16026], Loss: 0.0276\n",
      "Epoch [4/40], Step [1900/16026], Loss: 0.0288\n",
      "Epoch [4/40], Step [2000/16026], Loss: 0.0254\n",
      "Epoch [4/40], Step [2100/16026], Loss: 0.0295\n",
      "Epoch [4/40], Step [2200/16026], Loss: 0.0391\n",
      "Epoch [4/40], Step [2300/16026], Loss: 0.0182\n",
      "Epoch [4/40], Step [2400/16026], Loss: 0.0342\n",
      "Epoch [4/40], Step [2500/16026], Loss: 0.0259\n",
      "Epoch [4/40], Step [2600/16026], Loss: 0.0271\n",
      "Epoch [4/40], Step [2700/16026], Loss: 0.0276\n",
      "Epoch [4/40], Step [2800/16026], Loss: 0.0367\n",
      "Epoch [4/40], Step [2900/16026], Loss: 0.0414\n",
      "Epoch [4/40], Step [3000/16026], Loss: 0.0292\n",
      "Epoch [4/40], Step [3100/16026], Loss: 0.0446\n",
      "Epoch [4/40], Step [3200/16026], Loss: 0.0349\n",
      "Epoch [4/40], Step [3300/16026], Loss: 0.0213\n",
      "Epoch [4/40], Step [3400/16026], Loss: 0.0324\n",
      "Epoch [4/40], Step [3500/16026], Loss: 0.0366\n",
      "Epoch [4/40], Step [3600/16026], Loss: 0.0398\n",
      "Epoch [4/40], Step [3700/16026], Loss: 0.0251\n",
      "Epoch [4/40], Step [3800/16026], Loss: 0.0364\n",
      "Epoch [4/40], Step [3900/16026], Loss: 0.0220\n",
      "Epoch [4/40], Step [4000/16026], Loss: 0.0358\n",
      "Epoch [4/40], Step [4100/16026], Loss: 0.0218\n",
      "Epoch [4/40], Step [4200/16026], Loss: 0.0311\n",
      "Epoch [4/40], Step [4300/16026], Loss: 0.0290\n",
      "Epoch [4/40], Step [4400/16026], Loss: 0.0388\n",
      "Epoch [4/40], Step [4500/16026], Loss: 0.0305\n",
      "Epoch [4/40], Step [4600/16026], Loss: 0.0351\n",
      "Epoch [4/40], Step [4700/16026], Loss: 0.0342\n",
      "Epoch [4/40], Step [4800/16026], Loss: 0.0364\n",
      "Epoch [4/40], Step [4900/16026], Loss: 0.0218\n",
      "Epoch [4/40], Step [5000/16026], Loss: 0.0338\n",
      "Epoch [4/40], Step [5100/16026], Loss: 0.0467\n",
      "Epoch [4/40], Step [5200/16026], Loss: 0.0297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40], Step [5300/16026], Loss: 0.0289\n",
      "Epoch [4/40], Step [5400/16026], Loss: 0.0298\n",
      "Epoch [4/40], Step [5500/16026], Loss: 0.0326\n",
      "Epoch [4/40], Step [5600/16026], Loss: 0.0396\n",
      "Epoch [4/40], Step [5700/16026], Loss: 0.0274\n",
      "Epoch [4/40], Step [5800/16026], Loss: 0.0217\n",
      "Epoch [4/40], Step [5900/16026], Loss: 0.0413\n",
      "Epoch [4/40], Step [6000/16026], Loss: 0.0352\n",
      "Epoch [4/40], Step [6100/16026], Loss: 0.0272\n",
      "Epoch [4/40], Step [6200/16026], Loss: 0.0340\n",
      "Epoch [4/40], Step [6300/16026], Loss: 0.0299\n",
      "Epoch [4/40], Step [6400/16026], Loss: 0.0336\n",
      "Epoch [4/40], Step [6500/16026], Loss: 0.0340\n",
      "Epoch [4/40], Step [6600/16026], Loss: 0.0367\n",
      "Epoch [4/40], Step [6700/16026], Loss: 0.0226\n",
      "Epoch [4/40], Step [6800/16026], Loss: 0.0251\n",
      "Epoch [4/40], Step [6900/16026], Loss: 0.0264\n",
      "Epoch [4/40], Step [7000/16026], Loss: 0.0268\n",
      "Epoch [4/40], Step [7100/16026], Loss: 0.0553\n",
      "Epoch [4/40], Step [7200/16026], Loss: 0.0321\n",
      "Epoch [4/40], Step [7300/16026], Loss: 0.0291\n",
      "Epoch [4/40], Step [7400/16026], Loss: 0.0285\n",
      "Epoch [4/40], Step [7500/16026], Loss: 0.0354\n",
      "Epoch [4/40], Step [7600/16026], Loss: 0.0257\n",
      "Epoch [4/40], Step [7700/16026], Loss: 0.0251\n",
      "Epoch [4/40], Step [7800/16026], Loss: 0.0331\n",
      "Epoch [4/40], Step [7900/16026], Loss: 0.0359\n",
      "Epoch [4/40], Step [8000/16026], Loss: 0.0264\n",
      "Epoch [4/40], Step [8100/16026], Loss: 0.0375\n",
      "Epoch [4/40], Step [8200/16026], Loss: 0.0232\n",
      "Epoch [4/40], Step [8300/16026], Loss: 0.0187\n",
      "Epoch [4/40], Step [8400/16026], Loss: 0.0227\n",
      "Epoch [4/40], Step [8500/16026], Loss: 0.0285\n",
      "Epoch [4/40], Step [8600/16026], Loss: 0.0275\n",
      "Epoch [4/40], Step [8700/16026], Loss: 0.0139\n",
      "Epoch [4/40], Step [8800/16026], Loss: 0.0240\n",
      "Epoch [4/40], Step [8900/16026], Loss: 0.0269\n",
      "Epoch [4/40], Step [9000/16026], Loss: 0.0275\n",
      "Epoch [4/40], Step [9100/16026], Loss: 0.0208\n",
      "Epoch [4/40], Step [9200/16026], Loss: 0.0303\n",
      "Epoch [4/40], Step [9300/16026], Loss: 0.0236\n",
      "Epoch [4/40], Step [9400/16026], Loss: 0.0280\n",
      "Epoch [4/40], Step [9500/16026], Loss: 0.0284\n",
      "Epoch [4/40], Step [9600/16026], Loss: 0.0344\n",
      "Epoch [4/40], Step [9700/16026], Loss: 0.0272\n",
      "Epoch [4/40], Step [9800/16026], Loss: 0.0282\n",
      "Epoch [4/40], Step [9900/16026], Loss: 0.0296\n",
      "Epoch [4/40], Step [10000/16026], Loss: 0.0344\n",
      "Epoch [4/40], Step [10100/16026], Loss: 0.0239\n",
      "Epoch [4/40], Step [10200/16026], Loss: 0.0320\n",
      "Epoch [4/40], Step [10300/16026], Loss: 0.0320\n",
      "Epoch [4/40], Step [10400/16026], Loss: 0.0349\n",
      "Epoch [4/40], Step [10500/16026], Loss: 0.0266\n",
      "Epoch [4/40], Step [10600/16026], Loss: 0.0292\n",
      "Epoch [4/40], Step [10700/16026], Loss: 0.0191\n",
      "Epoch [4/40], Step [10800/16026], Loss: 0.0387\n",
      "Epoch [4/40], Step [10900/16026], Loss: 0.0306\n",
      "Epoch [4/40], Step [11000/16026], Loss: 0.0330\n",
      "Epoch [4/40], Step [11100/16026], Loss: 0.0381\n",
      "Epoch [4/40], Step [11200/16026], Loss: 0.0326\n",
      "Epoch [4/40], Step [11300/16026], Loss: 0.0266\n",
      "Epoch [4/40], Step [11400/16026], Loss: 0.0255\n",
      "Epoch [4/40], Step [11500/16026], Loss: 0.0252\n",
      "Epoch [4/40], Step [11600/16026], Loss: 0.0296\n",
      "Epoch [4/40], Step [11700/16026], Loss: 0.0278\n",
      "Epoch [4/40], Step [11800/16026], Loss: 0.0273\n",
      "Epoch [4/40], Step [11900/16026], Loss: 0.0270\n",
      "Epoch [4/40], Step [12000/16026], Loss: 0.0281\n",
      "Epoch [4/40], Step [12100/16026], Loss: 0.0310\n",
      "Epoch [4/40], Step [12200/16026], Loss: 0.0280\n",
      "Epoch [4/40], Step [12300/16026], Loss: 0.0182\n",
      "Epoch [4/40], Step [12400/16026], Loss: 0.0262\n",
      "Epoch [4/40], Step [12500/16026], Loss: 0.0174\n",
      "Epoch [4/40], Step [12600/16026], Loss: 0.0266\n",
      "Epoch [4/40], Step [12700/16026], Loss: 0.0265\n",
      "Epoch [4/40], Step [12800/16026], Loss: 0.0300\n",
      "Epoch [4/40], Step [12900/16026], Loss: 0.0309\n",
      "Epoch [4/40], Step [13000/16026], Loss: 0.0243\n",
      "Epoch [4/40], Step [13100/16026], Loss: 0.0286\n",
      "Epoch [4/40], Step [13200/16026], Loss: 0.0273\n",
      "Epoch [4/40], Step [13300/16026], Loss: 0.0226\n",
      "Epoch [4/40], Step [13400/16026], Loss: 0.0273\n",
      "Epoch [4/40], Step [13500/16026], Loss: 0.0290\n",
      "Epoch [4/40], Step [13600/16026], Loss: 0.0568\n",
      "Epoch [4/40], Step [13700/16026], Loss: 0.0194\n",
      "Epoch [4/40], Step [13800/16026], Loss: 0.0248\n",
      "Epoch [4/40], Step [13900/16026], Loss: 0.0340\n",
      "Epoch [4/40], Step [14000/16026], Loss: 0.0316\n",
      "Epoch [4/40], Step [14100/16026], Loss: 0.0240\n",
      "Epoch [4/40], Step [14200/16026], Loss: 0.0237\n",
      "Epoch [4/40], Step [14300/16026], Loss: 0.0404\n",
      "Epoch [4/40], Step [14400/16026], Loss: 0.0500\n",
      "Epoch [4/40], Step [14500/16026], Loss: 0.0280\n",
      "Epoch [4/40], Step [14600/16026], Loss: 0.0225\n",
      "Epoch [4/40], Step [14700/16026], Loss: 0.0231\n",
      "Epoch [4/40], Step [14800/16026], Loss: 0.0317\n",
      "Epoch [4/40], Step [14900/16026], Loss: 0.0298\n",
      "Epoch [4/40], Step [15000/16026], Loss: 0.0290\n",
      "Epoch [4/40], Step [15100/16026], Loss: 0.0180\n",
      "Epoch [4/40], Step [15200/16026], Loss: 0.0245\n",
      "Epoch [4/40], Step [15300/16026], Loss: 0.0278\n",
      "Epoch [4/40], Step [15400/16026], Loss: 0.0292\n",
      "Epoch [4/40], Step [15500/16026], Loss: 0.0248\n",
      "Epoch [4/40], Step [15600/16026], Loss: 0.0248\n",
      "Epoch [4/40], Step [15700/16026], Loss: 0.0286\n",
      "Epoch [4/40], Step [15800/16026], Loss: 0.0239\n",
      "Epoch [4/40], Step [15900/16026], Loss: 0.0422\n",
      "Epoch [4/40], Step [16000/16026], Loss: 0.0258\n",
      "Epoch [5/40], Step [100/16026], Loss: 0.0239\n",
      "Epoch [5/40], Step [200/16026], Loss: 0.0305\n",
      "Epoch [5/40], Step [300/16026], Loss: 0.0206\n",
      "Epoch [5/40], Step [400/16026], Loss: 0.0312\n",
      "Epoch [5/40], Step [500/16026], Loss: 0.0331\n",
      "Epoch [5/40], Step [600/16026], Loss: 0.0989\n",
      "Epoch [5/40], Step [700/16026], Loss: 0.0289\n",
      "Epoch [5/40], Step [800/16026], Loss: 0.0280\n",
      "Epoch [5/40], Step [900/16026], Loss: 0.0263\n",
      "Epoch [5/40], Step [1000/16026], Loss: 0.0198\n",
      "Epoch [5/40], Step [1100/16026], Loss: 0.0316\n",
      "Epoch [5/40], Step [1200/16026], Loss: 0.0171\n",
      "Epoch [5/40], Step [1300/16026], Loss: 0.0355\n",
      "Epoch [5/40], Step [1400/16026], Loss: 0.0350\n",
      "Epoch [5/40], Step [1500/16026], Loss: 0.0827\n",
      "Epoch [5/40], Step [1600/16026], Loss: 0.0225\n",
      "Epoch [5/40], Step [1700/16026], Loss: 0.0305\n",
      "Epoch [5/40], Step [1800/16026], Loss: 0.0246\n",
      "Epoch [5/40], Step [1900/16026], Loss: 0.0208\n",
      "Epoch [5/40], Step [2000/16026], Loss: 0.0227\n",
      "Epoch [5/40], Step [2100/16026], Loss: 0.0318\n",
      "Epoch [5/40], Step [2200/16026], Loss: 0.0285\n",
      "Epoch [5/40], Step [2300/16026], Loss: 0.0228\n",
      "Epoch [5/40], Step [2400/16026], Loss: 0.0233\n",
      "Epoch [5/40], Step [2500/16026], Loss: 0.0380\n",
      "Epoch [5/40], Step [2600/16026], Loss: 0.0224\n",
      "Epoch [5/40], Step [2700/16026], Loss: 0.0271\n",
      "Epoch [5/40], Step [2800/16026], Loss: 0.0273\n",
      "Epoch [5/40], Step [2900/16026], Loss: 0.0219\n",
      "Epoch [5/40], Step [3000/16026], Loss: 0.0334\n",
      "Epoch [5/40], Step [3100/16026], Loss: 0.0364\n",
      "Epoch [5/40], Step [3200/16026], Loss: 0.0314\n",
      "Epoch [5/40], Step [3300/16026], Loss: 0.0179\n",
      "Epoch [5/40], Step [3400/16026], Loss: 0.0225\n",
      "Epoch [5/40], Step [3500/16026], Loss: 0.0356\n",
      "Epoch [5/40], Step [3600/16026], Loss: 0.0429\n",
      "Epoch [5/40], Step [3700/16026], Loss: 0.0184\n",
      "Epoch [5/40], Step [3800/16026], Loss: 0.0258\n",
      "Epoch [5/40], Step [3900/16026], Loss: 0.0209\n",
      "Epoch [5/40], Step [4000/16026], Loss: 0.0306\n",
      "Epoch [5/40], Step [4100/16026], Loss: 0.0460\n",
      "Epoch [5/40], Step [4200/16026], Loss: 0.0213\n",
      "Epoch [5/40], Step [4300/16026], Loss: 0.0308\n",
      "Epoch [5/40], Step [4400/16026], Loss: 0.0282\n",
      "Epoch [5/40], Step [4500/16026], Loss: 0.0311\n",
      "Epoch [5/40], Step [4600/16026], Loss: 0.0530\n",
      "Epoch [5/40], Step [4700/16026], Loss: 0.0293\n",
      "Epoch [5/40], Step [4800/16026], Loss: 0.0272\n",
      "Epoch [5/40], Step [4900/16026], Loss: 0.0331\n",
      "Epoch [5/40], Step [5000/16026], Loss: 0.0373\n",
      "Epoch [5/40], Step [5100/16026], Loss: 0.0291\n",
      "Epoch [5/40], Step [5200/16026], Loss: 0.0254\n",
      "Epoch [5/40], Step [5300/16026], Loss: 0.0218\n",
      "Epoch [5/40], Step [5400/16026], Loss: 0.0185\n",
      "Epoch [5/40], Step [5500/16026], Loss: 0.0278\n",
      "Epoch [5/40], Step [5600/16026], Loss: 0.0165\n",
      "Epoch [5/40], Step [5700/16026], Loss: 0.0287\n",
      "Epoch [5/40], Step [5800/16026], Loss: 0.0244\n",
      "Epoch [5/40], Step [5900/16026], Loss: 0.0313\n",
      "Epoch [5/40], Step [6000/16026], Loss: 0.0269\n",
      "Epoch [5/40], Step [6100/16026], Loss: 0.0361\n",
      "Epoch [5/40], Step [6200/16026], Loss: 0.0192\n",
      "Epoch [5/40], Step [6300/16026], Loss: 0.0346\n",
      "Epoch [5/40], Step [6400/16026], Loss: 0.0174\n",
      "Epoch [5/40], Step [6500/16026], Loss: 0.0510\n",
      "Epoch [5/40], Step [6600/16026], Loss: 0.0279\n",
      "Epoch [5/40], Step [6700/16026], Loss: 0.0224\n",
      "Epoch [5/40], Step [6800/16026], Loss: 0.0354\n",
      "Epoch [5/40], Step [6900/16026], Loss: 0.0305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/40], Step [7000/16026], Loss: 0.0280\n",
      "Epoch [5/40], Step [7100/16026], Loss: 0.0264\n",
      "Epoch [5/40], Step [7200/16026], Loss: 0.0352\n",
      "Epoch [5/40], Step [7300/16026], Loss: 0.0359\n",
      "Epoch [5/40], Step [7400/16026], Loss: 0.0317\n",
      "Epoch [5/40], Step [7500/16026], Loss: 0.0328\n",
      "Epoch [5/40], Step [7600/16026], Loss: 0.0263\n",
      "Epoch [5/40], Step [7700/16026], Loss: 0.0281\n",
      "Epoch [5/40], Step [7800/16026], Loss: 0.0245\n",
      "Epoch [5/40], Step [7900/16026], Loss: 0.0356\n",
      "Epoch [5/40], Step [8000/16026], Loss: 0.0318\n",
      "Epoch [5/40], Step [8100/16026], Loss: 0.0269\n",
      "Epoch [5/40], Step [8200/16026], Loss: 0.0209\n",
      "Epoch [5/40], Step [8300/16026], Loss: 0.0220\n",
      "Epoch [5/40], Step [8400/16026], Loss: 0.0327\n",
      "Epoch [5/40], Step [8500/16026], Loss: 0.0306\n",
      "Epoch [5/40], Step [8600/16026], Loss: 0.0288\n",
      "Epoch [5/40], Step [8700/16026], Loss: 0.0286\n",
      "Epoch [5/40], Step [8800/16026], Loss: 0.0298\n",
      "Epoch [5/40], Step [8900/16026], Loss: 0.0270\n",
      "Epoch [5/40], Step [9000/16026], Loss: 0.0266\n",
      "Epoch [5/40], Step [9100/16026], Loss: 0.0187\n",
      "Epoch [5/40], Step [9200/16026], Loss: 0.0157\n",
      "Epoch [5/40], Step [9300/16026], Loss: 0.0452\n",
      "Epoch [5/40], Step [9400/16026], Loss: 0.0338\n",
      "Epoch [5/40], Step [9500/16026], Loss: 0.0298\n",
      "Epoch [5/40], Step [9600/16026], Loss: 0.0244\n",
      "Epoch [5/40], Step [9700/16026], Loss: 0.0246\n",
      "Epoch [5/40], Step [9800/16026], Loss: 0.0305\n",
      "Epoch [5/40], Step [9900/16026], Loss: 0.0281\n",
      "Epoch [5/40], Step [10000/16026], Loss: 0.0407\n",
      "Epoch [5/40], Step [10100/16026], Loss: 0.0164\n",
      "Epoch [5/40], Step [10200/16026], Loss: 0.0296\n",
      "Epoch [5/40], Step [10300/16026], Loss: 0.0300\n",
      "Epoch [5/40], Step [10400/16026], Loss: 0.0304\n",
      "Epoch [5/40], Step [10500/16026], Loss: 0.0276\n",
      "Epoch [5/40], Step [10600/16026], Loss: 0.0228\n",
      "Epoch [5/40], Step [10700/16026], Loss: 0.0216\n",
      "Epoch [5/40], Step [10800/16026], Loss: 0.0311\n",
      "Epoch [5/40], Step [10900/16026], Loss: 0.0362\n",
      "Epoch [5/40], Step [11000/16026], Loss: 0.0318\n",
      "Epoch [5/40], Step [11100/16026], Loss: 0.0320\n",
      "Epoch [5/40], Step [11200/16026], Loss: 0.0287\n",
      "Epoch [5/40], Step [11300/16026], Loss: 0.0331\n",
      "Epoch [5/40], Step [11400/16026], Loss: 0.0209\n",
      "Epoch [5/40], Step [11500/16026], Loss: 0.0233\n",
      "Epoch [5/40], Step [11600/16026], Loss: 0.0202\n",
      "Epoch [5/40], Step [11700/16026], Loss: 0.0887\n",
      "Epoch [5/40], Step [11800/16026], Loss: 0.0298\n",
      "Epoch [5/40], Step [11900/16026], Loss: 0.0250\n",
      "Epoch [5/40], Step [12000/16026], Loss: 0.0313\n",
      "Epoch [5/40], Step [12100/16026], Loss: 0.0273\n",
      "Epoch [5/40], Step [12200/16026], Loss: 0.0771\n",
      "Epoch [5/40], Step [12300/16026], Loss: 0.0275\n",
      "Epoch [5/40], Step [12400/16026], Loss: 0.0268\n",
      "Epoch [5/40], Step [12500/16026], Loss: 0.0321\n",
      "Epoch [5/40], Step [12600/16026], Loss: 0.0290\n",
      "Epoch [5/40], Step [12700/16026], Loss: 0.0263\n",
      "Epoch [5/40], Step [12800/16026], Loss: 0.0227\n",
      "Epoch [5/40], Step [12900/16026], Loss: 0.0258\n",
      "Epoch [5/40], Step [13000/16026], Loss: 0.0293\n",
      "Epoch [5/40], Step [13100/16026], Loss: 0.0372\n",
      "Epoch [5/40], Step [13200/16026], Loss: 0.0332\n",
      "Epoch [5/40], Step [13300/16026], Loss: 0.0362\n",
      "Epoch [5/40], Step [13400/16026], Loss: 0.0390\n",
      "Epoch [5/40], Step [13500/16026], Loss: 0.0244\n",
      "Epoch [5/40], Step [13600/16026], Loss: 0.0424\n",
      "Epoch [5/40], Step [13700/16026], Loss: 0.0292\n",
      "Epoch [5/40], Step [13800/16026], Loss: 0.0294\n",
      "Epoch [5/40], Step [13900/16026], Loss: 0.0758\n",
      "Epoch [5/40], Step [14000/16026], Loss: 0.0190\n",
      "Epoch [5/40], Step [14100/16026], Loss: 0.0270\n",
      "Epoch [5/40], Step [14200/16026], Loss: 0.0254\n",
      "Epoch [5/40], Step [14300/16026], Loss: 0.0335\n",
      "Epoch [5/40], Step [14400/16026], Loss: 0.0253\n",
      "Epoch [5/40], Step [14500/16026], Loss: 0.0269\n",
      "Epoch [5/40], Step [14600/16026], Loss: 0.0294\n",
      "Epoch [5/40], Step [14700/16026], Loss: 0.0400\n",
      "Epoch [5/40], Step [14800/16026], Loss: 0.0369\n",
      "Epoch [5/40], Step [14900/16026], Loss: 0.0241\n",
      "Epoch [5/40], Step [15000/16026], Loss: 0.0235\n",
      "Epoch [5/40], Step [15100/16026], Loss: 0.0526\n",
      "Epoch [5/40], Step [15200/16026], Loss: 0.0214\n",
      "Epoch [5/40], Step [15300/16026], Loss: 0.0238\n",
      "Epoch [5/40], Step [15400/16026], Loss: 0.0318\n",
      "Epoch [5/40], Step [15500/16026], Loss: 0.0196\n",
      "Epoch [5/40], Step [15600/16026], Loss: 0.0393\n",
      "Epoch [5/40], Step [15700/16026], Loss: 0.0387\n",
      "Epoch [5/40], Step [15800/16026], Loss: 0.0218\n",
      "Epoch [5/40], Step [15900/16026], Loss: 0.0230\n",
      "Epoch [5/40], Step [16000/16026], Loss: 0.0243\n",
      "Epoch [6/40], Step [100/16026], Loss: 0.0254\n",
      "Epoch [6/40], Step [200/16026], Loss: 0.0179\n",
      "Epoch [6/40], Step [300/16026], Loss: 0.0249\n",
      "Epoch [6/40], Step [400/16026], Loss: 0.0250\n",
      "Epoch [6/40], Step [500/16026], Loss: 0.0224\n",
      "Epoch [6/40], Step [600/16026], Loss: 0.0251\n",
      "Epoch [6/40], Step [700/16026], Loss: 0.0429\n",
      "Epoch [6/40], Step [800/16026], Loss: 0.0276\n",
      "Epoch [6/40], Step [900/16026], Loss: 0.0292\n",
      "Epoch [6/40], Step [1000/16026], Loss: 0.0287\n",
      "Epoch [6/40], Step [1100/16026], Loss: 0.0253\n",
      "Epoch [6/40], Step [1200/16026], Loss: 0.0376\n",
      "Epoch [6/40], Step [1300/16026], Loss: 0.0253\n",
      "Epoch [6/40], Step [1400/16026], Loss: 0.0523\n",
      "Epoch [6/40], Step [1500/16026], Loss: 0.0333\n",
      "Epoch [6/40], Step [1600/16026], Loss: 0.0229\n",
      "Epoch [6/40], Step [1700/16026], Loss: 0.0368\n",
      "Epoch [6/40], Step [1800/16026], Loss: 0.0162\n",
      "Epoch [6/40], Step [1900/16026], Loss: 0.0407\n",
      "Epoch [6/40], Step [2000/16026], Loss: 0.0322\n",
      "Epoch [6/40], Step [2100/16026], Loss: 0.0244\n",
      "Epoch [6/40], Step [2200/16026], Loss: 0.0362\n",
      "Epoch [6/40], Step [2300/16026], Loss: 0.0341\n",
      "Epoch [6/40], Step [2400/16026], Loss: 0.0170\n",
      "Epoch [6/40], Step [2500/16026], Loss: 0.0261\n",
      "Epoch [6/40], Step [2600/16026], Loss: 0.0274\n",
      "Epoch [6/40], Step [2700/16026], Loss: 0.0437\n",
      "Epoch [6/40], Step [2800/16026], Loss: 0.0183\n",
      "Epoch [6/40], Step [2900/16026], Loss: 0.0243\n",
      "Epoch [6/40], Step [3000/16026], Loss: 0.0206\n",
      "Epoch [6/40], Step [3100/16026], Loss: 0.0266\n",
      "Epoch [6/40], Step [3200/16026], Loss: 0.0340\n",
      "Epoch [6/40], Step [3300/16026], Loss: 0.0275\n",
      "Epoch [6/40], Step [3400/16026], Loss: 0.0134\n",
      "Epoch [6/40], Step [3500/16026], Loss: 0.0172\n",
      "Epoch [6/40], Step [3600/16026], Loss: 0.0107\n",
      "Epoch [6/40], Step [3700/16026], Loss: 0.0329\n",
      "Epoch [6/40], Step [3800/16026], Loss: 0.0279\n",
      "Epoch [6/40], Step [3900/16026], Loss: 0.0336\n",
      "Epoch [6/40], Step [4000/16026], Loss: 0.0302\n",
      "Epoch [6/40], Step [4100/16026], Loss: 0.0416\n",
      "Epoch [6/40], Step [4200/16026], Loss: 0.0305\n",
      "Epoch [6/40], Step [4300/16026], Loss: 0.0357\n",
      "Epoch [6/40], Step [4400/16026], Loss: 0.0267\n",
      "Epoch [6/40], Step [4500/16026], Loss: 0.0509\n",
      "Epoch [6/40], Step [4600/16026], Loss: 0.0294\n",
      "Epoch [6/40], Step [4700/16026], Loss: 0.0314\n",
      "Epoch [6/40], Step [4800/16026], Loss: 0.0256\n",
      "Epoch [6/40], Step [4900/16026], Loss: 0.0259\n",
      "Epoch [6/40], Step [5000/16026], Loss: 0.0181\n",
      "Epoch [6/40], Step [5100/16026], Loss: 0.0338\n",
      "Epoch [6/40], Step [5200/16026], Loss: 0.0384\n",
      "Epoch [6/40], Step [5300/16026], Loss: 0.0262\n",
      "Epoch [6/40], Step [5400/16026], Loss: 0.0293\n",
      "Epoch [6/40], Step [5500/16026], Loss: 0.0211\n",
      "Epoch [6/40], Step [5600/16026], Loss: 0.0366\n",
      "Epoch [6/40], Step [5700/16026], Loss: 0.0139\n",
      "Epoch [6/40], Step [5800/16026], Loss: 0.0293\n",
      "Epoch [6/40], Step [5900/16026], Loss: 0.0154\n",
      "Epoch [6/40], Step [6000/16026], Loss: 0.0388\n",
      "Epoch [6/40], Step [6100/16026], Loss: 0.0277\n",
      "Epoch [6/40], Step [6200/16026], Loss: 0.0378\n",
      "Epoch [6/40], Step [6300/16026], Loss: 0.0232\n",
      "Epoch [6/40], Step [6400/16026], Loss: 0.0210\n",
      "Epoch [6/40], Step [6500/16026], Loss: 0.0284\n",
      "Epoch [6/40], Step [6600/16026], Loss: 0.0160\n",
      "Epoch [6/40], Step [6700/16026], Loss: 0.0242\n",
      "Epoch [6/40], Step [6800/16026], Loss: 0.0188\n",
      "Epoch [6/40], Step [6900/16026], Loss: 0.0246\n",
      "Epoch [6/40], Step [7000/16026], Loss: 0.0278\n",
      "Epoch [6/40], Step [7100/16026], Loss: 0.0252\n",
      "Epoch [6/40], Step [7200/16026], Loss: 0.0345\n",
      "Epoch [6/40], Step [7300/16026], Loss: 0.0306\n",
      "Epoch [6/40], Step [7400/16026], Loss: 0.0271\n",
      "Epoch [6/40], Step [7500/16026], Loss: 0.0224\n",
      "Epoch [6/40], Step [7600/16026], Loss: 0.0224\n",
      "Epoch [6/40], Step [7700/16026], Loss: 0.0138\n",
      "Epoch [6/40], Step [7800/16026], Loss: 0.0209\n",
      "Epoch [6/40], Step [7900/16026], Loss: 0.0249\n",
      "Epoch [6/40], Step [8000/16026], Loss: 0.0274\n",
      "Epoch [6/40], Step [8100/16026], Loss: 0.0259\n",
      "Epoch [6/40], Step [8200/16026], Loss: 0.0272\n",
      "Epoch [6/40], Step [8300/16026], Loss: 0.0296\n",
      "Epoch [6/40], Step [8400/16026], Loss: 0.0234\n",
      "Epoch [6/40], Step [8500/16026], Loss: 0.0268\n",
      "Epoch [6/40], Step [8600/16026], Loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40], Step [8700/16026], Loss: 0.0188\n",
      "Epoch [6/40], Step [8800/16026], Loss: 0.0236\n",
      "Epoch [6/40], Step [8900/16026], Loss: 0.0345\n",
      "Epoch [6/40], Step [9000/16026], Loss: 0.0194\n",
      "Epoch [6/40], Step [9100/16026], Loss: 0.0168\n",
      "Epoch [6/40], Step [9200/16026], Loss: 0.0194\n",
      "Epoch [6/40], Step [9300/16026], Loss: 0.0261\n",
      "Epoch [6/40], Step [9400/16026], Loss: 0.0175\n",
      "Epoch [6/40], Step [9500/16026], Loss: 0.0283\n",
      "Epoch [6/40], Step [9600/16026], Loss: 0.0208\n",
      "Epoch [6/40], Step [9700/16026], Loss: 0.0264\n",
      "Epoch [6/40], Step [9800/16026], Loss: 0.0294\n",
      "Epoch [6/40], Step [9900/16026], Loss: 0.0196\n",
      "Epoch [6/40], Step [10000/16026], Loss: 0.0378\n",
      "Epoch [6/40], Step [10100/16026], Loss: 0.0256\n",
      "Epoch [6/40], Step [10200/16026], Loss: 0.0245\n",
      "Epoch [6/40], Step [10300/16026], Loss: 0.0238\n",
      "Epoch [6/40], Step [10400/16026], Loss: 0.0295\n",
      "Epoch [6/40], Step [10500/16026], Loss: 0.0312\n",
      "Epoch [6/40], Step [10600/16026], Loss: 0.0342\n",
      "Epoch [6/40], Step [10700/16026], Loss: 0.0353\n",
      "Epoch [6/40], Step [10800/16026], Loss: 0.0229\n",
      "Epoch [6/40], Step [10900/16026], Loss: 0.0276\n",
      "Epoch [6/40], Step [11000/16026], Loss: 0.0320\n",
      "Epoch [6/40], Step [11100/16026], Loss: 0.0373\n",
      "Epoch [6/40], Step [11200/16026], Loss: 0.0254\n",
      "Epoch [6/40], Step [11300/16026], Loss: 0.0231\n",
      "Epoch [6/40], Step [11400/16026], Loss: 0.0156\n",
      "Epoch [6/40], Step [11500/16026], Loss: 0.0268\n",
      "Epoch [6/40], Step [11600/16026], Loss: 0.0314\n",
      "Epoch [6/40], Step [11700/16026], Loss: 0.0243\n",
      "Epoch [6/40], Step [11800/16026], Loss: 0.0321\n",
      "Epoch [6/40], Step [11900/16026], Loss: 0.0137\n",
      "Epoch [6/40], Step [12000/16026], Loss: 0.0357\n",
      "Epoch [6/40], Step [12100/16026], Loss: 0.0284\n",
      "Epoch [6/40], Step [12200/16026], Loss: 0.0303\n",
      "Epoch [6/40], Step [12300/16026], Loss: 0.0370\n",
      "Epoch [6/40], Step [12400/16026], Loss: 0.0349\n",
      "Epoch [6/40], Step [12500/16026], Loss: 0.0284\n",
      "Epoch [6/40], Step [12600/16026], Loss: 0.0224\n",
      "Epoch [6/40], Step [12700/16026], Loss: 0.0308\n",
      "Epoch [6/40], Step [12800/16026], Loss: 0.0254\n",
      "Epoch [6/40], Step [12900/16026], Loss: 0.0300\n",
      "Epoch [6/40], Step [13000/16026], Loss: 0.0193\n",
      "Epoch [6/40], Step [13100/16026], Loss: 0.0291\n",
      "Epoch [6/40], Step [13200/16026], Loss: 0.0149\n",
      "Epoch [6/40], Step [13300/16026], Loss: 0.0172\n",
      "Epoch [6/40], Step [13400/16026], Loss: 0.0238\n",
      "Epoch [6/40], Step [13500/16026], Loss: 0.0323\n",
      "Epoch [6/40], Step [13600/16026], Loss: 0.0272\n",
      "Epoch [6/40], Step [13700/16026], Loss: 0.0271\n",
      "Epoch [6/40], Step [13800/16026], Loss: 0.0286\n",
      "Epoch [6/40], Step [13900/16026], Loss: 0.0336\n",
      "Epoch [6/40], Step [14000/16026], Loss: 0.0291\n",
      "Epoch [6/40], Step [14100/16026], Loss: 0.0223\n",
      "Epoch [6/40], Step [14200/16026], Loss: 0.0295\n",
      "Epoch [6/40], Step [14300/16026], Loss: 0.0309\n",
      "Epoch [6/40], Step [14400/16026], Loss: 0.0395\n",
      "Epoch [6/40], Step [14500/16026], Loss: 0.0219\n",
      "Epoch [6/40], Step [14600/16026], Loss: 0.0303\n",
      "Epoch [6/40], Step [14700/16026], Loss: 0.0337\n",
      "Epoch [6/40], Step [14800/16026], Loss: 0.0191\n",
      "Epoch [6/40], Step [14900/16026], Loss: 0.0297\n",
      "Epoch [6/40], Step [15000/16026], Loss: 0.0314\n",
      "Epoch [6/40], Step [15100/16026], Loss: 0.0257\n",
      "Epoch [6/40], Step [15200/16026], Loss: 0.0252\n",
      "Epoch [6/40], Step [15300/16026], Loss: 0.0168\n",
      "Epoch [6/40], Step [15400/16026], Loss: 0.0281\n",
      "Epoch [6/40], Step [15500/16026], Loss: 0.0459\n",
      "Epoch [6/40], Step [15600/16026], Loss: 0.0263\n",
      "Epoch [6/40], Step [15700/16026], Loss: 0.0250\n",
      "Epoch [6/40], Step [15800/16026], Loss: 0.0333\n",
      "Epoch [6/40], Step [15900/16026], Loss: 0.0223\n",
      "Epoch [6/40], Step [16000/16026], Loss: 0.0261\n",
      "Epoch [7/40], Step [100/16026], Loss: 0.0197\n",
      "Epoch [7/40], Step [200/16026], Loss: 0.0287\n",
      "Epoch [7/40], Step [300/16026], Loss: 0.0210\n",
      "Epoch [7/40], Step [400/16026], Loss: 0.0253\n",
      "Epoch [7/40], Step [500/16026], Loss: 0.0165\n",
      "Epoch [7/40], Step [600/16026], Loss: 0.0218\n",
      "Epoch [7/40], Step [700/16026], Loss: 0.0176\n",
      "Epoch [7/40], Step [800/16026], Loss: 0.0224\n",
      "Epoch [7/40], Step [900/16026], Loss: 0.0264\n",
      "Epoch [7/40], Step [1000/16026], Loss: 0.0200\n",
      "Epoch [7/40], Step [1100/16026], Loss: 0.0211\n",
      "Epoch [7/40], Step [1200/16026], Loss: 0.0215\n",
      "Epoch [7/40], Step [1300/16026], Loss: 0.0153\n",
      "Epoch [7/40], Step [1400/16026], Loss: 0.0150\n",
      "Epoch [7/40], Step [1500/16026], Loss: 0.0314\n",
      "Epoch [7/40], Step [1600/16026], Loss: 0.0312\n",
      "Epoch [7/40], Step [1700/16026], Loss: 0.0565\n",
      "Epoch [7/40], Step [1800/16026], Loss: 0.0307\n",
      "Epoch [7/40], Step [1900/16026], Loss: 0.0164\n",
      "Epoch [7/40], Step [2000/16026], Loss: 0.0354\n",
      "Epoch [7/40], Step [2100/16026], Loss: 0.0135\n",
      "Epoch [7/40], Step [2200/16026], Loss: 0.0224\n",
      "Epoch [7/40], Step [2300/16026], Loss: 0.0210\n",
      "Epoch [7/40], Step [2400/16026], Loss: 0.0234\n",
      "Epoch [7/40], Step [2500/16026], Loss: 0.0293\n",
      "Epoch [7/40], Step [2600/16026], Loss: 0.0350\n",
      "Epoch [7/40], Step [2700/16026], Loss: 0.0438\n",
      "Epoch [7/40], Step [2800/16026], Loss: 0.0301\n",
      "Epoch [7/40], Step [2900/16026], Loss: 0.0335\n",
      "Epoch [7/40], Step [3000/16026], Loss: 0.0274\n",
      "Epoch [7/40], Step [3100/16026], Loss: 0.0335\n",
      "Epoch [7/40], Step [3200/16026], Loss: 0.0301\n",
      "Epoch [7/40], Step [3300/16026], Loss: 0.0207\n",
      "Epoch [7/40], Step [3400/16026], Loss: 0.0225\n",
      "Epoch [7/40], Step [3500/16026], Loss: 0.0285\n",
      "Epoch [7/40], Step [3600/16026], Loss: 0.0250\n",
      "Epoch [7/40], Step [3700/16026], Loss: 0.0246\n",
      "Epoch [7/40], Step [3800/16026], Loss: 0.0194\n",
      "Epoch [7/40], Step [3900/16026], Loss: 0.0241\n",
      "Epoch [7/40], Step [4000/16026], Loss: 0.0290\n",
      "Epoch [7/40], Step [4100/16026], Loss: 0.0200\n",
      "Epoch [7/40], Step [4200/16026], Loss: 0.0186\n",
      "Epoch [7/40], Step [4300/16026], Loss: 0.0189\n",
      "Epoch [7/40], Step [4400/16026], Loss: 0.0300\n",
      "Epoch [7/40], Step [4500/16026], Loss: 0.0238\n",
      "Epoch [7/40], Step [4600/16026], Loss: 0.0127\n",
      "Epoch [7/40], Step [4700/16026], Loss: 0.0157\n",
      "Epoch [7/40], Step [4800/16026], Loss: 0.0332\n",
      "Epoch [7/40], Step [4900/16026], Loss: 0.0359\n",
      "Epoch [7/40], Step [5000/16026], Loss: 0.0237\n",
      "Epoch [7/40], Step [5100/16026], Loss: 0.0269\n",
      "Epoch [7/40], Step [5200/16026], Loss: 0.0358\n",
      "Epoch [7/40], Step [5300/16026], Loss: 0.0238\n",
      "Epoch [7/40], Step [5400/16026], Loss: 0.0289\n",
      "Epoch [7/40], Step [5500/16026], Loss: 0.0212\n",
      "Epoch [7/40], Step [5600/16026], Loss: 0.0265\n",
      "Epoch [7/40], Step [5700/16026], Loss: 0.0212\n",
      "Epoch [7/40], Step [5800/16026], Loss: 0.0229\n",
      "Epoch [7/40], Step [5900/16026], Loss: 0.0231\n",
      "Epoch [7/40], Step [6000/16026], Loss: 0.0256\n",
      "Epoch [7/40], Step [6100/16026], Loss: 0.0194\n",
      "Epoch [7/40], Step [6200/16026], Loss: 0.0214\n",
      "Epoch [7/40], Step [6300/16026], Loss: 0.0360\n",
      "Epoch [7/40], Step [6400/16026], Loss: 0.0262\n",
      "Epoch [7/40], Step [6500/16026], Loss: 0.0271\n",
      "Epoch [7/40], Step [6600/16026], Loss: 0.0353\n",
      "Epoch [7/40], Step [6700/16026], Loss: 0.0273\n",
      "Epoch [7/40], Step [6800/16026], Loss: 0.0268\n",
      "Epoch [7/40], Step [6900/16026], Loss: 0.0281\n",
      "Epoch [7/40], Step [7000/16026], Loss: 0.0204\n",
      "Epoch [7/40], Step [7100/16026], Loss: 0.0302\n",
      "Epoch [7/40], Step [7200/16026], Loss: 0.0375\n",
      "Epoch [7/40], Step [7300/16026], Loss: 0.0253\n",
      "Epoch [7/40], Step [7400/16026], Loss: 0.0218\n",
      "Epoch [7/40], Step [7500/16026], Loss: 0.0186\n",
      "Epoch [7/40], Step [7600/16026], Loss: 0.0135\n",
      "Epoch [7/40], Step [7700/16026], Loss: 0.0180\n",
      "Epoch [7/40], Step [7800/16026], Loss: 0.0233\n",
      "Epoch [7/40], Step [7900/16026], Loss: 0.0172\n",
      "Epoch [7/40], Step [8000/16026], Loss: 0.0201\n",
      "Epoch [7/40], Step [8100/16026], Loss: 0.0286\n",
      "Epoch [7/40], Step [8200/16026], Loss: 0.0264\n",
      "Epoch [7/40], Step [8300/16026], Loss: 0.0295\n",
      "Epoch [7/40], Step [8400/16026], Loss: 0.0249\n",
      "Epoch [7/40], Step [8500/16026], Loss: 0.0269\n",
      "Epoch [7/40], Step [8600/16026], Loss: 0.0298\n",
      "Epoch [7/40], Step [8700/16026], Loss: 0.0258\n",
      "Epoch [7/40], Step [8800/16026], Loss: 0.0266\n",
      "Epoch [7/40], Step [8900/16026], Loss: 0.0228\n",
      "Epoch [7/40], Step [9000/16026], Loss: 0.0216\n",
      "Epoch [7/40], Step [9100/16026], Loss: 0.0364\n",
      "Epoch [7/40], Step [9200/16026], Loss: 0.0257\n",
      "Epoch [7/40], Step [9300/16026], Loss: 0.0164\n",
      "Epoch [7/40], Step [9400/16026], Loss: 0.0206\n",
      "Epoch [7/40], Step [9500/16026], Loss: 0.0152\n",
      "Epoch [7/40], Step [9600/16026], Loss: 0.0241\n",
      "Epoch [7/40], Step [9700/16026], Loss: 0.0266\n",
      "Epoch [7/40], Step [9800/16026], Loss: 0.0372\n",
      "Epoch [7/40], Step [9900/16026], Loss: 0.0302\n",
      "Epoch [7/40], Step [10000/16026], Loss: 0.0345\n",
      "Epoch [7/40], Step [10100/16026], Loss: 0.0330\n",
      "Epoch [7/40], Step [10200/16026], Loss: 0.0194\n",
      "Epoch [7/40], Step [10300/16026], Loss: 0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/40], Step [10400/16026], Loss: 0.0199\n",
      "Epoch [7/40], Step [10500/16026], Loss: 0.0158\n",
      "Epoch [7/40], Step [10600/16026], Loss: 0.0206\n",
      "Epoch [7/40], Step [10700/16026], Loss: 0.0305\n",
      "Epoch [7/40], Step [10800/16026], Loss: 0.0269\n",
      "Epoch [7/40], Step [10900/16026], Loss: 0.0266\n",
      "Epoch [7/40], Step [11000/16026], Loss: 0.0231\n",
      "Epoch [7/40], Step [11100/16026], Loss: 0.0207\n",
      "Epoch [7/40], Step [11200/16026], Loss: 0.0293\n",
      "Epoch [7/40], Step [11300/16026], Loss: 0.0287\n",
      "Epoch [7/40], Step [11400/16026], Loss: 0.0194\n",
      "Epoch [7/40], Step [11500/16026], Loss: 0.0244\n",
      "Epoch [7/40], Step [11600/16026], Loss: 0.0174\n",
      "Epoch [7/40], Step [11700/16026], Loss: 0.0262\n",
      "Epoch [7/40], Step [11800/16026], Loss: 0.0326\n",
      "Epoch [7/40], Step [11900/16026], Loss: 0.0319\n",
      "Epoch [7/40], Step [12000/16026], Loss: 0.0273\n",
      "Epoch [7/40], Step [12100/16026], Loss: 0.0191\n",
      "Epoch [7/40], Step [12200/16026], Loss: 0.0276\n",
      "Epoch [7/40], Step [12300/16026], Loss: 0.0180\n",
      "Epoch [7/40], Step [12400/16026], Loss: 0.0340\n",
      "Epoch [7/40], Step [12500/16026], Loss: 0.0178\n",
      "Epoch [7/40], Step [12600/16026], Loss: 0.0287\n",
      "Epoch [7/40], Step [12700/16026], Loss: 0.0223\n",
      "Epoch [7/40], Step [12800/16026], Loss: 0.0197\n",
      "Epoch [7/40], Step [12900/16026], Loss: 0.0218\n",
      "Epoch [7/40], Step [13000/16026], Loss: 0.0326\n",
      "Epoch [7/40], Step [13100/16026], Loss: 0.0281\n",
      "Epoch [7/40], Step [13200/16026], Loss: 0.0175\n",
      "Epoch [7/40], Step [13300/16026], Loss: 0.0297\n",
      "Epoch [7/40], Step [13400/16026], Loss: 0.0349\n",
      "Epoch [7/40], Step [13500/16026], Loss: 0.0201\n",
      "Epoch [7/40], Step [13600/16026], Loss: 0.0225\n",
      "Epoch [7/40], Step [13700/16026], Loss: 0.0217\n",
      "Epoch [7/40], Step [13800/16026], Loss: 0.0163\n",
      "Epoch [7/40], Step [13900/16026], Loss: 0.0238\n",
      "Epoch [7/40], Step [14000/16026], Loss: 0.0165\n",
      "Epoch [7/40], Step [14100/16026], Loss: 0.0264\n",
      "Epoch [7/40], Step [14200/16026], Loss: 0.0243\n",
      "Epoch [7/40], Step [14300/16026], Loss: 0.0177\n",
      "Epoch [7/40], Step [14400/16026], Loss: 0.0214\n",
      "Epoch [7/40], Step [14500/16026], Loss: 0.0140\n",
      "Epoch [7/40], Step [14600/16026], Loss: 0.0284\n",
      "Epoch [7/40], Step [14700/16026], Loss: 0.0249\n",
      "Epoch [7/40], Step [14800/16026], Loss: 0.0273\n",
      "Epoch [7/40], Step [14900/16026], Loss: 0.0325\n",
      "Epoch [7/40], Step [15000/16026], Loss: 0.0596\n",
      "Epoch [7/40], Step [15100/16026], Loss: 0.0224\n",
      "Epoch [7/40], Step [15200/16026], Loss: 0.0381\n",
      "Epoch [7/40], Step [15300/16026], Loss: 0.0415\n",
      "Epoch [7/40], Step [15400/16026], Loss: 0.0242\n",
      "Epoch [7/40], Step [15500/16026], Loss: 0.0220\n",
      "Epoch [7/40], Step [15600/16026], Loss: 0.0304\n",
      "Epoch [7/40], Step [15700/16026], Loss: 0.0206\n",
      "Epoch [7/40], Step [15800/16026], Loss: 0.0300\n",
      "Epoch [7/40], Step [15900/16026], Loss: 0.0298\n",
      "Epoch [7/40], Step [16000/16026], Loss: 0.0223\n",
      "Epoch [8/40], Step [100/16026], Loss: 0.0310\n",
      "Epoch [8/40], Step [200/16026], Loss: 0.0230\n",
      "Epoch [8/40], Step [300/16026], Loss: 0.0172\n",
      "Epoch [8/40], Step [400/16026], Loss: 0.0190\n",
      "Epoch [8/40], Step [500/16026], Loss: 0.0226\n",
      "Epoch [8/40], Step [600/16026], Loss: 0.0315\n",
      "Epoch [8/40], Step [700/16026], Loss: 0.0251\n",
      "Epoch [8/40], Step [800/16026], Loss: 0.0264\n",
      "Epoch [8/40], Step [900/16026], Loss: 0.0191\n",
      "Epoch [8/40], Step [1000/16026], Loss: 0.0213\n",
      "Epoch [8/40], Step [1100/16026], Loss: 0.0222\n",
      "Epoch [8/40], Step [1200/16026], Loss: 0.0295\n",
      "Epoch [8/40], Step [1300/16026], Loss: 0.0240\n",
      "Epoch [8/40], Step [1400/16026], Loss: 0.0239\n",
      "Epoch [8/40], Step [1500/16026], Loss: 0.0266\n",
      "Epoch [8/40], Step [1600/16026], Loss: 0.0213\n",
      "Epoch [8/40], Step [1700/16026], Loss: 0.0215\n",
      "Epoch [8/40], Step [1800/16026], Loss: 0.0236\n",
      "Epoch [8/40], Step [1900/16026], Loss: 0.0536\n",
      "Epoch [8/40], Step [2000/16026], Loss: 0.0233\n",
      "Epoch [8/40], Step [2100/16026], Loss: 0.0344\n",
      "Epoch [8/40], Step [2200/16026], Loss: 0.0283\n",
      "Epoch [8/40], Step [2300/16026], Loss: 0.0289\n",
      "Epoch [8/40], Step [2400/16026], Loss: 0.0160\n",
      "Epoch [8/40], Step [2500/16026], Loss: 0.0222\n",
      "Epoch [8/40], Step [2600/16026], Loss: 0.0221\n",
      "Epoch [8/40], Step [2700/16026], Loss: 0.0221\n",
      "Epoch [8/40], Step [2800/16026], Loss: 0.0235\n",
      "Epoch [8/40], Step [2900/16026], Loss: 0.0226\n",
      "Epoch [8/40], Step [3000/16026], Loss: 0.0390\n",
      "Epoch [8/40], Step [3100/16026], Loss: 0.0196\n",
      "Epoch [8/40], Step [3200/16026], Loss: 0.0193\n",
      "Epoch [8/40], Step [3300/16026], Loss: 0.0251\n",
      "Epoch [8/40], Step [3400/16026], Loss: 0.0206\n",
      "Epoch [8/40], Step [3500/16026], Loss: 0.0206\n",
      "Epoch [8/40], Step [3600/16026], Loss: 0.0203\n",
      "Epoch [8/40], Step [3700/16026], Loss: 0.0351\n",
      "Epoch [8/40], Step [3800/16026], Loss: 0.0229\n",
      "Epoch [8/40], Step [3900/16026], Loss: 0.0243\n",
      "Epoch [8/40], Step [4000/16026], Loss: 0.0220\n",
      "Epoch [8/40], Step [4100/16026], Loss: 0.0194\n",
      "Epoch [8/40], Step [4200/16026], Loss: 0.0288\n",
      "Epoch [8/40], Step [4300/16026], Loss: 0.0151\n",
      "Epoch [8/40], Step [4400/16026], Loss: 0.0304\n",
      "Epoch [8/40], Step [4500/16026], Loss: 0.0203\n",
      "Epoch [8/40], Step [4600/16026], Loss: 0.0353\n",
      "Epoch [8/40], Step [4700/16026], Loss: 0.0216\n",
      "Epoch [8/40], Step [4800/16026], Loss: 0.0266\n",
      "Epoch [8/40], Step [4900/16026], Loss: 0.0239\n",
      "Epoch [8/40], Step [5000/16026], Loss: 0.0190\n",
      "Epoch [8/40], Step [5100/16026], Loss: 0.0313\n",
      "Epoch [8/40], Step [5200/16026], Loss: 0.0233\n",
      "Epoch [8/40], Step [5300/16026], Loss: 0.0239\n",
      "Epoch [8/40], Step [5400/16026], Loss: 0.0311\n",
      "Epoch [8/40], Step [5500/16026], Loss: 0.0173\n",
      "Epoch [8/40], Step [5600/16026], Loss: 0.0379\n",
      "Epoch [8/40], Step [5700/16026], Loss: 0.0522\n",
      "Epoch [8/40], Step [5800/16026], Loss: 0.0263\n",
      "Epoch [8/40], Step [5900/16026], Loss: 0.0303\n",
      "Epoch [8/40], Step [6000/16026], Loss: 0.0195\n",
      "Epoch [8/40], Step [6100/16026], Loss: 0.0296\n",
      "Epoch [8/40], Step [6200/16026], Loss: 0.0176\n",
      "Epoch [8/40], Step [6300/16026], Loss: 0.0179\n",
      "Epoch [8/40], Step [6400/16026], Loss: 0.0211\n",
      "Epoch [8/40], Step [6500/16026], Loss: 0.0212\n",
      "Epoch [8/40], Step [6600/16026], Loss: 0.0271\n",
      "Epoch [8/40], Step [6700/16026], Loss: 0.0263\n",
      "Epoch [8/40], Step [6800/16026], Loss: 0.0407\n",
      "Epoch [8/40], Step [6900/16026], Loss: 0.0320\n",
      "Epoch [8/40], Step [7000/16026], Loss: 0.0230\n",
      "Epoch [8/40], Step [7100/16026], Loss: 0.0306\n",
      "Epoch [8/40], Step [7200/16026], Loss: 0.0373\n",
      "Epoch [8/40], Step [7300/16026], Loss: 0.0239\n",
      "Epoch [8/40], Step [7400/16026], Loss: 0.0347\n",
      "Epoch [8/40], Step [7500/16026], Loss: 0.0495\n",
      "Epoch [8/40], Step [7600/16026], Loss: 0.0463\n",
      "Epoch [8/40], Step [7700/16026], Loss: 0.0170\n",
      "Epoch [8/40], Step [7800/16026], Loss: 0.0214\n",
      "Epoch [8/40], Step [7900/16026], Loss: 0.0354\n",
      "Epoch [8/40], Step [8000/16026], Loss: 0.0233\n",
      "Epoch [8/40], Step [8100/16026], Loss: 0.0294\n",
      "Epoch [8/40], Step [8200/16026], Loss: 0.0178\n",
      "Epoch [8/40], Step [8300/16026], Loss: 0.0360\n",
      "Epoch [8/40], Step [8400/16026], Loss: 0.0314\n",
      "Epoch [8/40], Step [8500/16026], Loss: 0.0231\n",
      "Epoch [8/40], Step [8600/16026], Loss: 0.0199\n",
      "Epoch [8/40], Step [8700/16026], Loss: 0.0151\n",
      "Epoch [8/40], Step [8800/16026], Loss: 0.0285\n",
      "Epoch [8/40], Step [8900/16026], Loss: 0.0261\n",
      "Epoch [8/40], Step [9000/16026], Loss: 0.0225\n",
      "Epoch [8/40], Step [9100/16026], Loss: 0.0216\n",
      "Epoch [8/40], Step [9200/16026], Loss: 0.0397\n",
      "Epoch [8/40], Step [9300/16026], Loss: 0.0309\n",
      "Epoch [8/40], Step [9400/16026], Loss: 0.0212\n",
      "Epoch [8/40], Step [9500/16026], Loss: 0.0324\n",
      "Epoch [8/40], Step [9600/16026], Loss: 0.0248\n",
      "Epoch [8/40], Step [9700/16026], Loss: 0.0189\n",
      "Epoch [8/40], Step [9800/16026], Loss: 0.0150\n",
      "Epoch [8/40], Step [9900/16026], Loss: 0.0157\n",
      "Epoch [8/40], Step [10000/16026], Loss: 0.0209\n",
      "Epoch [8/40], Step [10100/16026], Loss: 0.0246\n",
      "Epoch [8/40], Step [10200/16026], Loss: 0.0221\n",
      "Epoch [8/40], Step [10300/16026], Loss: 0.0267\n",
      "Epoch [8/40], Step [10400/16026], Loss: 0.0133\n",
      "Epoch [8/40], Step [10500/16026], Loss: 0.0238\n",
      "Epoch [8/40], Step [10600/16026], Loss: 0.0211\n",
      "Epoch [8/40], Step [10700/16026], Loss: 0.0226\n",
      "Epoch [8/40], Step [10800/16026], Loss: 0.0241\n",
      "Epoch [8/40], Step [10900/16026], Loss: 0.0239\n",
      "Epoch [8/40], Step [11000/16026], Loss: 0.0153\n",
      "Epoch [8/40], Step [11100/16026], Loss: 0.0285\n",
      "Epoch [8/40], Step [11200/16026], Loss: 0.0155\n",
      "Epoch [8/40], Step [11300/16026], Loss: 0.0241\n",
      "Epoch [8/40], Step [11400/16026], Loss: 0.0244\n",
      "Epoch [8/40], Step [11500/16026], Loss: 0.0267\n",
      "Epoch [8/40], Step [11600/16026], Loss: 0.0317\n",
      "Epoch [8/40], Step [11700/16026], Loss: 0.0293\n",
      "Epoch [8/40], Step [11800/16026], Loss: 0.0237\n",
      "Epoch [8/40], Step [11900/16026], Loss: 0.0214\n",
      "Epoch [8/40], Step [12000/16026], Loss: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/40], Step [12100/16026], Loss: 0.0250\n",
      "Epoch [8/40], Step [12200/16026], Loss: 0.0308\n",
      "Epoch [8/40], Step [12300/16026], Loss: 0.0228\n",
      "Epoch [8/40], Step [12400/16026], Loss: 0.0260\n",
      "Epoch [8/40], Step [12500/16026], Loss: 0.0259\n",
      "Epoch [8/40], Step [12600/16026], Loss: 0.0205\n",
      "Epoch [8/40], Step [12700/16026], Loss: 0.0257\n",
      "Epoch [8/40], Step [12800/16026], Loss: 0.0207\n",
      "Epoch [8/40], Step [12900/16026], Loss: 0.0216\n",
      "Epoch [8/40], Step [13000/16026], Loss: 0.0293\n",
      "Epoch [8/40], Step [13100/16026], Loss: 0.0277\n",
      "Epoch [8/40], Step [13200/16026], Loss: 0.0227\n",
      "Epoch [8/40], Step [13300/16026], Loss: 0.0341\n",
      "Epoch [8/40], Step [13400/16026], Loss: 0.0228\n",
      "Epoch [8/40], Step [13500/16026], Loss: 0.0244\n",
      "Epoch [8/40], Step [13600/16026], Loss: 0.0259\n",
      "Epoch [8/40], Step [13700/16026], Loss: 0.0282\n",
      "Epoch [8/40], Step [13800/16026], Loss: 0.0203\n",
      "Epoch [8/40], Step [13900/16026], Loss: 0.0266\n",
      "Epoch [8/40], Step [14000/16026], Loss: 0.0257\n",
      "Epoch [8/40], Step [14100/16026], Loss: 0.0281\n",
      "Epoch [8/40], Step [14200/16026], Loss: 0.0217\n",
      "Epoch [8/40], Step [14300/16026], Loss: 0.0216\n",
      "Epoch [8/40], Step [14400/16026], Loss: 0.0229\n",
      "Epoch [8/40], Step [14500/16026], Loss: 0.0386\n",
      "Epoch [8/40], Step [14600/16026], Loss: 0.0359\n",
      "Epoch [8/40], Step [14700/16026], Loss: 0.0166\n",
      "Epoch [8/40], Step [14800/16026], Loss: 0.0307\n",
      "Epoch [8/40], Step [14900/16026], Loss: 0.0202\n",
      "Epoch [8/40], Step [15000/16026], Loss: 0.0277\n",
      "Epoch [8/40], Step [15100/16026], Loss: 0.0195\n",
      "Epoch [8/40], Step [15200/16026], Loss: 0.0248\n",
      "Epoch [8/40], Step [15300/16026], Loss: 0.0274\n",
      "Epoch [8/40], Step [15400/16026], Loss: 0.0228\n",
      "Epoch [8/40], Step [15500/16026], Loss: 0.0273\n",
      "Epoch [8/40], Step [15600/16026], Loss: 0.0254\n",
      "Epoch [8/40], Step [15700/16026], Loss: 0.0154\n",
      "Epoch [8/40], Step [15800/16026], Loss: 0.0260\n",
      "Epoch [8/40], Step [15900/16026], Loss: 0.0131\n",
      "Epoch [8/40], Step [16000/16026], Loss: 0.0259\n",
      "Epoch [9/40], Step [100/16026], Loss: 0.0156\n",
      "Epoch [9/40], Step [200/16026], Loss: 0.0216\n",
      "Epoch [9/40], Step [300/16026], Loss: 0.0204\n",
      "Epoch [9/40], Step [400/16026], Loss: 0.0219\n",
      "Epoch [9/40], Step [500/16026], Loss: 0.0184\n",
      "Epoch [9/40], Step [600/16026], Loss: 0.0252\n",
      "Epoch [9/40], Step [700/16026], Loss: 0.0167\n",
      "Epoch [9/40], Step [800/16026], Loss: 0.0283\n",
      "Epoch [9/40], Step [900/16026], Loss: 0.0260\n",
      "Epoch [9/40], Step [1000/16026], Loss: 0.0130\n",
      "Epoch [9/40], Step [1100/16026], Loss: 0.0263\n",
      "Epoch [9/40], Step [1200/16026], Loss: 0.0281\n",
      "Epoch [9/40], Step [1300/16026], Loss: 0.0244\n",
      "Epoch [9/40], Step [1400/16026], Loss: 0.0176\n",
      "Epoch [9/40], Step [1500/16026], Loss: 0.0219\n",
      "Epoch [9/40], Step [1600/16026], Loss: 0.0288\n",
      "Epoch [9/40], Step [1700/16026], Loss: 0.0328\n",
      "Epoch [9/40], Step [1800/16026], Loss: 0.0199\n",
      "Epoch [9/40], Step [1900/16026], Loss: 0.0387\n",
      "Epoch [9/40], Step [2000/16026], Loss: 0.0316\n",
      "Epoch [9/40], Step [2100/16026], Loss: 0.0143\n",
      "Epoch [9/40], Step [2200/16026], Loss: 0.0359\n",
      "Epoch [9/40], Step [2300/16026], Loss: 0.0224\n",
      "Epoch [9/40], Step [2400/16026], Loss: 0.0202\n",
      "Epoch [9/40], Step [2500/16026], Loss: 0.0385\n",
      "Epoch [9/40], Step [2600/16026], Loss: 0.0200\n",
      "Epoch [9/40], Step [2700/16026], Loss: 0.0315\n",
      "Epoch [9/40], Step [2800/16026], Loss: 0.0148\n",
      "Epoch [9/40], Step [2900/16026], Loss: 0.0174\n",
      "Epoch [9/40], Step [3000/16026], Loss: 0.0229\n",
      "Epoch [9/40], Step [3100/16026], Loss: 0.0207\n",
      "Epoch [9/40], Step [3200/16026], Loss: 0.0219\n",
      "Epoch [9/40], Step [3300/16026], Loss: 0.0409\n",
      "Epoch [9/40], Step [3400/16026], Loss: 0.0315\n",
      "Epoch [9/40], Step [3500/16026], Loss: 0.0375\n",
      "Epoch [9/40], Step [3600/16026], Loss: 0.0226\n",
      "Epoch [9/40], Step [3700/16026], Loss: 0.0345\n",
      "Epoch [9/40], Step [3800/16026], Loss: 0.0310\n",
      "Epoch [9/40], Step [3900/16026], Loss: 0.0236\n",
      "Epoch [9/40], Step [4000/16026], Loss: 0.0240\n",
      "Epoch [9/40], Step [4100/16026], Loss: 0.0325\n",
      "Epoch [9/40], Step [4200/16026], Loss: 0.0291\n",
      "Epoch [9/40], Step [4300/16026], Loss: 0.0264\n",
      "Epoch [9/40], Step [4400/16026], Loss: 0.0281\n",
      "Epoch [9/40], Step [4500/16026], Loss: 0.0154\n",
      "Epoch [9/40], Step [4600/16026], Loss: 0.0173\n",
      "Epoch [9/40], Step [4700/16026], Loss: 0.0183\n",
      "Epoch [9/40], Step [4800/16026], Loss: 0.0175\n",
      "Epoch [9/40], Step [4900/16026], Loss: 0.0260\n",
      "Epoch [9/40], Step [5000/16026], Loss: 0.0321\n",
      "Epoch [9/40], Step [5100/16026], Loss: 0.0218\n",
      "Epoch [9/40], Step [5200/16026], Loss: 0.0277\n",
      "Epoch [9/40], Step [5300/16026], Loss: 0.0213\n",
      "Epoch [9/40], Step [5400/16026], Loss: 0.0153\n",
      "Epoch [9/40], Step [5500/16026], Loss: 0.0156\n",
      "Epoch [9/40], Step [5600/16026], Loss: 0.0302\n",
      "Epoch [9/40], Step [5700/16026], Loss: 0.0211\n",
      "Epoch [9/40], Step [5800/16026], Loss: 0.0251\n",
      "Epoch [9/40], Step [5900/16026], Loss: 0.0266\n",
      "Epoch [9/40], Step [6000/16026], Loss: 0.0184\n",
      "Epoch [9/40], Step [6100/16026], Loss: 0.0185\n",
      "Epoch [9/40], Step [6200/16026], Loss: 0.0299\n",
      "Epoch [9/40], Step [6300/16026], Loss: 0.0190\n",
      "Epoch [9/40], Step [6400/16026], Loss: 0.0289\n",
      "Epoch [9/40], Step [6500/16026], Loss: 0.0320\n",
      "Epoch [9/40], Step [6600/16026], Loss: 0.0198\n",
      "Epoch [9/40], Step [6700/16026], Loss: 0.0284\n",
      "Epoch [9/40], Step [6800/16026], Loss: 0.0364\n",
      "Epoch [9/40], Step [6900/16026], Loss: 0.0175\n",
      "Epoch [9/40], Step [7000/16026], Loss: 0.0235\n",
      "Epoch [9/40], Step [7100/16026], Loss: 0.0226\n",
      "Epoch [9/40], Step [7200/16026], Loss: 0.0180\n",
      "Epoch [9/40], Step [7300/16026], Loss: 0.0232\n",
      "Epoch [9/40], Step [7400/16026], Loss: 0.0206\n",
      "Epoch [9/40], Step [7500/16026], Loss: 0.0351\n",
      "Epoch [9/40], Step [7600/16026], Loss: 0.0238\n",
      "Epoch [9/40], Step [7700/16026], Loss: 0.0239\n",
      "Epoch [9/40], Step [7800/16026], Loss: 0.0161\n",
      "Epoch [9/40], Step [7900/16026], Loss: 0.0279\n",
      "Epoch [9/40], Step [8000/16026], Loss: 0.0183\n",
      "Epoch [9/40], Step [8100/16026], Loss: 0.0338\n",
      "Epoch [9/40], Step [8200/16026], Loss: 0.0261\n",
      "Epoch [9/40], Step [8300/16026], Loss: 0.0214\n",
      "Epoch [9/40], Step [8400/16026], Loss: 0.0158\n",
      "Epoch [9/40], Step [8500/16026], Loss: 0.0200\n",
      "Epoch [9/40], Step [8600/16026], Loss: 0.0300\n",
      "Epoch [9/40], Step [8700/16026], Loss: 0.0212\n",
      "Epoch [9/40], Step [8800/16026], Loss: 0.0146\n",
      "Epoch [9/40], Step [8900/16026], Loss: 0.0444\n",
      "Epoch [9/40], Step [9000/16026], Loss: 0.0221\n",
      "Epoch [9/40], Step [9100/16026], Loss: 0.0256\n",
      "Epoch [9/40], Step [9200/16026], Loss: 0.0222\n",
      "Epoch [9/40], Step [9300/16026], Loss: 0.0258\n",
      "Epoch [9/40], Step [9400/16026], Loss: 0.0491\n",
      "Epoch [9/40], Step [9500/16026], Loss: 0.0764\n",
      "Epoch [9/40], Step [9600/16026], Loss: 0.0269\n",
      "Epoch [9/40], Step [9700/16026], Loss: 0.0336\n",
      "Epoch [9/40], Step [9800/16026], Loss: 0.0276\n",
      "Epoch [9/40], Step [9900/16026], Loss: 0.0203\n",
      "Epoch [9/40], Step [10000/16026], Loss: 0.0601\n",
      "Epoch [9/40], Step [10100/16026], Loss: 0.0219\n",
      "Epoch [9/40], Step [10200/16026], Loss: 0.0246\n",
      "Epoch [9/40], Step [10300/16026], Loss: 0.0202\n",
      "Epoch [9/40], Step [10400/16026], Loss: 0.0193\n",
      "Epoch [9/40], Step [10500/16026], Loss: 0.0262\n",
      "Epoch [9/40], Step [10600/16026], Loss: 0.0356\n",
      "Epoch [9/40], Step [10700/16026], Loss: 0.0286\n",
      "Epoch [9/40], Step [10800/16026], Loss: 0.0294\n",
      "Epoch [9/40], Step [10900/16026], Loss: 0.0170\n",
      "Epoch [9/40], Step [11000/16026], Loss: 0.0321\n",
      "Epoch [9/40], Step [11100/16026], Loss: 0.0177\n",
      "Epoch [9/40], Step [11200/16026], Loss: 0.0210\n",
      "Epoch [9/40], Step [11300/16026], Loss: 0.0252\n",
      "Epoch [9/40], Step [11400/16026], Loss: 0.0223\n",
      "Epoch [9/40], Step [11500/16026], Loss: 0.0227\n",
      "Epoch [9/40], Step [11600/16026], Loss: 0.0259\n",
      "Epoch [9/40], Step [11700/16026], Loss: 0.0254\n",
      "Epoch [9/40], Step [11800/16026], Loss: 0.0236\n",
      "Epoch [9/40], Step [11900/16026], Loss: 0.0249\n",
      "Epoch [9/40], Step [12000/16026], Loss: 0.0323\n",
      "Epoch [9/40], Step [12100/16026], Loss: 0.0302\n",
      "Epoch [9/40], Step [12200/16026], Loss: 0.0195\n",
      "Epoch [9/40], Step [12300/16026], Loss: 0.0229\n",
      "Epoch [9/40], Step [12400/16026], Loss: 0.0265\n",
      "Epoch [9/40], Step [12500/16026], Loss: 0.0229\n",
      "Epoch [9/40], Step [12600/16026], Loss: 0.0190\n",
      "Epoch [9/40], Step [12700/16026], Loss: 0.0327\n",
      "Epoch [9/40], Step [12800/16026], Loss: 0.0508\n",
      "Epoch [9/40], Step [12900/16026], Loss: 0.0225\n",
      "Epoch [9/40], Step [13000/16026], Loss: 0.0257\n",
      "Epoch [9/40], Step [13100/16026], Loss: 0.0304\n",
      "Epoch [9/40], Step [13200/16026], Loss: 0.0327\n",
      "Epoch [9/40], Step [13300/16026], Loss: 0.0178\n",
      "Epoch [9/40], Step [13400/16026], Loss: 0.0327\n",
      "Epoch [9/40], Step [13500/16026], Loss: 0.0345\n",
      "Epoch [9/40], Step [13600/16026], Loss: 0.0381\n",
      "Epoch [9/40], Step [13700/16026], Loss: 0.0259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/40], Step [13800/16026], Loss: 0.0210\n",
      "Epoch [9/40], Step [13900/16026], Loss: 0.0198\n",
      "Epoch [9/40], Step [14000/16026], Loss: 0.0225\n",
      "Epoch [9/40], Step [14100/16026], Loss: 0.0194\n",
      "Epoch [9/40], Step [14200/16026], Loss: 0.0256\n",
      "Epoch [9/40], Step [14300/16026], Loss: 0.0195\n",
      "Epoch [9/40], Step [14400/16026], Loss: 0.0246\n",
      "Epoch [9/40], Step [14500/16026], Loss: 0.0243\n",
      "Epoch [9/40], Step [14600/16026], Loss: 0.0371\n",
      "Epoch [9/40], Step [14700/16026], Loss: 0.0473\n",
      "Epoch [9/40], Step [14800/16026], Loss: 0.0334\n",
      "Epoch [9/40], Step [14900/16026], Loss: 0.0274\n",
      "Epoch [9/40], Step [15000/16026], Loss: 0.0229\n",
      "Epoch [9/40], Step [15100/16026], Loss: 0.0157\n",
      "Epoch [9/40], Step [15200/16026], Loss: 0.0295\n",
      "Epoch [9/40], Step [15300/16026], Loss: 0.0158\n",
      "Epoch [9/40], Step [15400/16026], Loss: 0.0275\n",
      "Epoch [9/40], Step [15500/16026], Loss: 0.0230\n",
      "Epoch [9/40], Step [15600/16026], Loss: 0.0224\n",
      "Epoch [9/40], Step [15700/16026], Loss: 0.0221\n",
      "Epoch [9/40], Step [15800/16026], Loss: 0.0199\n",
      "Epoch [9/40], Step [15900/16026], Loss: 0.0193\n",
      "Epoch [9/40], Step [16000/16026], Loss: 0.0165\n",
      "Epoch [10/40], Step [100/16026], Loss: 0.0233\n",
      "Epoch [10/40], Step [200/16026], Loss: 0.0262\n",
      "Epoch [10/40], Step [300/16026], Loss: 0.0285\n",
      "Epoch [10/40], Step [400/16026], Loss: 0.0206\n",
      "Epoch [10/40], Step [500/16026], Loss: 0.0213\n",
      "Epoch [10/40], Step [600/16026], Loss: 0.0214\n",
      "Epoch [10/40], Step [700/16026], Loss: 0.0226\n",
      "Epoch [10/40], Step [800/16026], Loss: 0.0325\n",
      "Epoch [10/40], Step [900/16026], Loss: 0.0227\n",
      "Epoch [10/40], Step [1000/16026], Loss: 0.0259\n",
      "Epoch [10/40], Step [1100/16026], Loss: 0.0222\n",
      "Epoch [10/40], Step [1200/16026], Loss: 0.0178\n",
      "Epoch [10/40], Step [1300/16026], Loss: 0.0140\n",
      "Epoch [10/40], Step [1400/16026], Loss: 0.0230\n",
      "Epoch [10/40], Step [1500/16026], Loss: 0.0244\n",
      "Epoch [10/40], Step [1600/16026], Loss: 0.0312\n",
      "Epoch [10/40], Step [1700/16026], Loss: 0.0217\n",
      "Epoch [10/40], Step [1800/16026], Loss: 0.0243\n",
      "Epoch [10/40], Step [1900/16026], Loss: 0.0120\n",
      "Epoch [10/40], Step [2000/16026], Loss: 0.0252\n",
      "Epoch [10/40], Step [2100/16026], Loss: 0.0302\n",
      "Epoch [10/40], Step [2200/16026], Loss: 0.0209\n",
      "Epoch [10/40], Step [2300/16026], Loss: 0.0195\n",
      "Epoch [10/40], Step [2400/16026], Loss: 0.0150\n",
      "Epoch [10/40], Step [2500/16026], Loss: 0.0243\n",
      "Epoch [10/40], Step [2600/16026], Loss: 0.0222\n",
      "Epoch [10/40], Step [2700/16026], Loss: 0.0291\n",
      "Epoch [10/40], Step [2800/16026], Loss: 0.0298\n",
      "Epoch [10/40], Step [2900/16026], Loss: 0.0235\n",
      "Epoch [10/40], Step [3000/16026], Loss: 0.0211\n",
      "Epoch [10/40], Step [3100/16026], Loss: 0.0276\n",
      "Epoch [10/40], Step [3200/16026], Loss: 0.0347\n",
      "Epoch [10/40], Step [3300/16026], Loss: 0.0158\n",
      "Epoch [10/40], Step [3400/16026], Loss: 0.0187\n",
      "Epoch [10/40], Step [3500/16026], Loss: 0.0276\n",
      "Epoch [10/40], Step [3600/16026], Loss: 0.0298\n",
      "Epoch [10/40], Step [3700/16026], Loss: 0.0193\n",
      "Epoch [10/40], Step [3800/16026], Loss: 0.0291\n",
      "Epoch [10/40], Step [3900/16026], Loss: 0.0374\n",
      "Epoch [10/40], Step [4000/16026], Loss: 0.0408\n",
      "Epoch [10/40], Step [4100/16026], Loss: 0.0193\n",
      "Epoch [10/40], Step [4200/16026], Loss: 0.0280\n",
      "Epoch [10/40], Step [4300/16026], Loss: 0.0234\n",
      "Epoch [10/40], Step [4400/16026], Loss: 0.0345\n",
      "Epoch [10/40], Step [4500/16026], Loss: 0.0300\n",
      "Epoch [10/40], Step [4600/16026], Loss: 0.0245\n",
      "Epoch [10/40], Step [4700/16026], Loss: 0.0319\n",
      "Epoch [10/40], Step [4800/16026], Loss: 0.0221\n",
      "Epoch [10/40], Step [4900/16026], Loss: 0.0224\n",
      "Epoch [10/40], Step [5000/16026], Loss: 0.0294\n",
      "Epoch [10/40], Step [5100/16026], Loss: 0.0218\n",
      "Epoch [10/40], Step [5200/16026], Loss: 0.0248\n",
      "Epoch [10/40], Step [5300/16026], Loss: 0.0168\n",
      "Epoch [10/40], Step [5400/16026], Loss: 0.0290\n",
      "Epoch [10/40], Step [5500/16026], Loss: 0.0145\n",
      "Epoch [10/40], Step [5600/16026], Loss: 0.0168\n",
      "Epoch [10/40], Step [5700/16026], Loss: 0.0287\n",
      "Epoch [10/40], Step [5800/16026], Loss: 0.0211\n",
      "Epoch [10/40], Step [5900/16026], Loss: 0.0239\n",
      "Epoch [10/40], Step [6000/16026], Loss: 0.0243\n",
      "Epoch [10/40], Step [6100/16026], Loss: 0.0323\n",
      "Epoch [10/40], Step [6200/16026], Loss: 0.0259\n",
      "Epoch [10/40], Step [6300/16026], Loss: 0.0232\n",
      "Epoch [10/40], Step [6400/16026], Loss: 0.0239\n",
      "Epoch [10/40], Step [6500/16026], Loss: 0.0213\n",
      "Epoch [10/40], Step [6600/16026], Loss: 0.0162\n",
      "Epoch [10/40], Step [6700/16026], Loss: 0.0243\n",
      "Epoch [10/40], Step [6800/16026], Loss: 0.0228\n",
      "Epoch [10/40], Step [6900/16026], Loss: 0.0241\n",
      "Epoch [10/40], Step [7000/16026], Loss: 0.0322\n",
      "Epoch [10/40], Step [7100/16026], Loss: 0.0147\n",
      "Epoch [10/40], Step [7200/16026], Loss: 0.0207\n",
      "Epoch [10/40], Step [7300/16026], Loss: 0.0309\n",
      "Epoch [10/40], Step [7400/16026], Loss: 0.0268\n",
      "Epoch [10/40], Step [7500/16026], Loss: 0.0267\n",
      "Epoch [10/40], Step [7600/16026], Loss: 0.0262\n",
      "Epoch [10/40], Step [7700/16026], Loss: 0.0271\n",
      "Epoch [10/40], Step [7800/16026], Loss: 0.0274\n",
      "Epoch [10/40], Step [7900/16026], Loss: 0.0192\n",
      "Epoch [10/40], Step [8000/16026], Loss: 0.0239\n",
      "Epoch [10/40], Step [8100/16026], Loss: 0.0209\n",
      "Epoch [10/40], Step [8200/16026], Loss: 0.0182\n",
      "Epoch [10/40], Step [8300/16026], Loss: 0.0189\n",
      "Epoch [10/40], Step [8400/16026], Loss: 0.0195\n",
      "Epoch [10/40], Step [8500/16026], Loss: 0.0173\n",
      "Epoch [10/40], Step [8600/16026], Loss: 0.0240\n",
      "Epoch [10/40], Step [8700/16026], Loss: 0.0254\n",
      "Epoch [10/40], Step [8800/16026], Loss: 0.0479\n",
      "Epoch [10/40], Step [8900/16026], Loss: 0.0204\n",
      "Epoch [10/40], Step [9000/16026], Loss: 0.0161\n",
      "Epoch [10/40], Step [9100/16026], Loss: 0.0190\n",
      "Epoch [10/40], Step [9200/16026], Loss: 0.0234\n",
      "Epoch [10/40], Step [9300/16026], Loss: 0.0223\n",
      "Epoch [10/40], Step [9400/16026], Loss: 0.0342\n",
      "Epoch [10/40], Step [9500/16026], Loss: 0.0273\n",
      "Epoch [10/40], Step [9600/16026], Loss: 0.0257\n",
      "Epoch [10/40], Step [9700/16026], Loss: 0.0203\n",
      "Epoch [10/40], Step [9800/16026], Loss: 0.0333\n",
      "Epoch [10/40], Step [9900/16026], Loss: 0.0204\n",
      "Epoch [10/40], Step [10000/16026], Loss: 0.0236\n",
      "Epoch [10/40], Step [10100/16026], Loss: 0.0237\n",
      "Epoch [10/40], Step [10200/16026], Loss: 0.0176\n",
      "Epoch [10/40], Step [10300/16026], Loss: 0.0257\n",
      "Epoch [10/40], Step [10400/16026], Loss: 0.0285\n",
      "Epoch [10/40], Step [10500/16026], Loss: 0.0144\n",
      "Epoch [10/40], Step [10600/16026], Loss: 0.0230\n",
      "Epoch [10/40], Step [10700/16026], Loss: 0.0212\n",
      "Epoch [10/40], Step [10800/16026], Loss: 0.0215\n",
      "Epoch [10/40], Step [10900/16026], Loss: 0.0256\n",
      "Epoch [10/40], Step [11000/16026], Loss: 0.0210\n",
      "Epoch [10/40], Step [11100/16026], Loss: 0.0193\n",
      "Epoch [10/40], Step [11200/16026], Loss: 0.0242\n",
      "Epoch [10/40], Step [11300/16026], Loss: 0.0142\n",
      "Epoch [10/40], Step [11400/16026], Loss: 0.0272\n",
      "Epoch [10/40], Step [11500/16026], Loss: 0.0281\n",
      "Epoch [10/40], Step [11600/16026], Loss: 0.0305\n",
      "Epoch [10/40], Step [11700/16026], Loss: 0.0243\n",
      "Epoch [10/40], Step [11800/16026], Loss: 0.0198\n",
      "Epoch [10/40], Step [11900/16026], Loss: 0.0151\n",
      "Epoch [10/40], Step [12000/16026], Loss: 0.0172\n",
      "Epoch [10/40], Step [12100/16026], Loss: 0.0207\n",
      "Epoch [10/40], Step [12200/16026], Loss: 0.0424\n",
      "Epoch [10/40], Step [12300/16026], Loss: 0.0190\n",
      "Epoch [10/40], Step [12400/16026], Loss: 0.0509\n",
      "Epoch [10/40], Step [12500/16026], Loss: 0.0278\n",
      "Epoch [10/40], Step [12600/16026], Loss: 0.0264\n",
      "Epoch [10/40], Step [12700/16026], Loss: 0.0239\n",
      "Epoch [10/40], Step [12800/16026], Loss: 0.0256\n",
      "Epoch [10/40], Step [12900/16026], Loss: 0.0174\n",
      "Epoch [10/40], Step [13000/16026], Loss: 0.0193\n",
      "Epoch [10/40], Step [13100/16026], Loss: 0.0147\n",
      "Epoch [10/40], Step [13200/16026], Loss: 0.0301\n",
      "Epoch [10/40], Step [13300/16026], Loss: 0.0307\n",
      "Epoch [10/40], Step [13400/16026], Loss: 0.0185\n",
      "Epoch [10/40], Step [13500/16026], Loss: 0.0186\n",
      "Epoch [10/40], Step [13600/16026], Loss: 0.0324\n",
      "Epoch [10/40], Step [13700/16026], Loss: 0.0225\n",
      "Epoch [10/40], Step [13800/16026], Loss: 0.0231\n",
      "Epoch [10/40], Step [13900/16026], Loss: 0.0177\n",
      "Epoch [10/40], Step [14000/16026], Loss: 0.0240\n",
      "Epoch [10/40], Step [14100/16026], Loss: 0.0262\n",
      "Epoch [10/40], Step [14200/16026], Loss: 0.0208\n",
      "Epoch [10/40], Step [14300/16026], Loss: 0.0328\n",
      "Epoch [10/40], Step [14400/16026], Loss: 0.0246\n",
      "Epoch [10/40], Step [14500/16026], Loss: 0.0158\n",
      "Epoch [10/40], Step [14600/16026], Loss: 0.0239\n",
      "Epoch [10/40], Step [14700/16026], Loss: 0.0222\n",
      "Epoch [10/40], Step [14800/16026], Loss: 0.0229\n",
      "Epoch [10/40], Step [14900/16026], Loss: 0.0211\n",
      "Epoch [10/40], Step [15000/16026], Loss: 0.0231\n",
      "Epoch [10/40], Step [15100/16026], Loss: 0.0275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40], Step [15200/16026], Loss: 0.0270\n",
      "Epoch [10/40], Step [15300/16026], Loss: 0.0189\n",
      "Epoch [10/40], Step [15400/16026], Loss: 0.0244\n",
      "Epoch [10/40], Step [15500/16026], Loss: 0.0292\n",
      "Epoch [10/40], Step [15600/16026], Loss: 0.0222\n",
      "Epoch [10/40], Step [15700/16026], Loss: 0.0236\n",
      "Epoch [10/40], Step [15800/16026], Loss: 0.0358\n",
      "Epoch [10/40], Step [15900/16026], Loss: 0.0209\n",
      "Epoch [10/40], Step [16000/16026], Loss: 0.0269\n",
      "Epoch [11/40], Step [100/16026], Loss: 0.0204\n",
      "Epoch [11/40], Step [200/16026], Loss: 0.0368\n",
      "Epoch [11/40], Step [300/16026], Loss: 0.0215\n",
      "Epoch [11/40], Step [400/16026], Loss: 0.0194\n",
      "Epoch [11/40], Step [500/16026], Loss: 0.0211\n",
      "Epoch [11/40], Step [600/16026], Loss: 0.0183\n",
      "Epoch [11/40], Step [700/16026], Loss: 0.0248\n",
      "Epoch [11/40], Step [800/16026], Loss: 0.0218\n",
      "Epoch [11/40], Step [900/16026], Loss: 0.0208\n",
      "Epoch [11/40], Step [1000/16026], Loss: 0.0216\n",
      "Epoch [11/40], Step [1100/16026], Loss: 0.0218\n",
      "Epoch [11/40], Step [1200/16026], Loss: 0.0247\n",
      "Epoch [11/40], Step [1300/16026], Loss: 0.0308\n",
      "Epoch [11/40], Step [1400/16026], Loss: 0.0273\n",
      "Epoch [11/40], Step [1500/16026], Loss: 0.0363\n",
      "Epoch [11/40], Step [1600/16026], Loss: 0.0298\n",
      "Epoch [11/40], Step [1700/16026], Loss: 0.0244\n",
      "Epoch [11/40], Step [1800/16026], Loss: 0.0286\n",
      "Epoch [11/40], Step [1900/16026], Loss: 0.0272\n",
      "Epoch [11/40], Step [2000/16026], Loss: 0.0324\n",
      "Epoch [11/40], Step [2100/16026], Loss: 0.0248\n",
      "Epoch [11/40], Step [2200/16026], Loss: 0.0339\n",
      "Epoch [11/40], Step [2300/16026], Loss: 0.0693\n",
      "Epoch [11/40], Step [2400/16026], Loss: 0.0292\n",
      "Epoch [11/40], Step [2500/16026], Loss: 0.0299\n",
      "Epoch [11/40], Step [2600/16026], Loss: 0.0202\n",
      "Epoch [11/40], Step [2700/16026], Loss: 0.0298\n",
      "Epoch [11/40], Step [2800/16026], Loss: 0.0366\n",
      "Epoch [11/40], Step [2900/16026], Loss: 0.0259\n",
      "Epoch [11/40], Step [3000/16026], Loss: 0.0189\n",
      "Epoch [11/40], Step [3100/16026], Loss: 0.0126\n",
      "Epoch [11/40], Step [3200/16026], Loss: 0.0298\n",
      "Epoch [11/40], Step [3300/16026], Loss: 0.0200\n",
      "Epoch [11/40], Step [3400/16026], Loss: 0.0205\n",
      "Epoch [11/40], Step [3500/16026], Loss: 0.0253\n",
      "Epoch [11/40], Step [3600/16026], Loss: 0.0258\n",
      "Epoch [11/40], Step [3700/16026], Loss: 0.0348\n",
      "Epoch [11/40], Step [3800/16026], Loss: 0.0238\n",
      "Epoch [11/40], Step [3900/16026], Loss: 0.0275\n",
      "Epoch [11/40], Step [4000/16026], Loss: 0.0323\n",
      "Epoch [11/40], Step [4100/16026], Loss: 0.0170\n",
      "Epoch [11/40], Step [4200/16026], Loss: 0.0128\n",
      "Epoch [11/40], Step [4300/16026], Loss: 0.0260\n",
      "Epoch [11/40], Step [4400/16026], Loss: 0.0270\n",
      "Epoch [11/40], Step [4500/16026], Loss: 0.0228\n",
      "Epoch [11/40], Step [4600/16026], Loss: 0.0317\n",
      "Epoch [11/40], Step [4700/16026], Loss: 0.0207\n",
      "Epoch [11/40], Step [4800/16026], Loss: 0.0238\n",
      "Epoch [11/40], Step [4900/16026], Loss: 0.0210\n",
      "Epoch [11/40], Step [5000/16026], Loss: 0.0227\n",
      "Epoch [11/40], Step [5100/16026], Loss: 0.0265\n",
      "Epoch [11/40], Step [5200/16026], Loss: 0.0234\n",
      "Epoch [11/40], Step [5300/16026], Loss: 0.0212\n",
      "Epoch [11/40], Step [5400/16026], Loss: 0.0130\n",
      "Epoch [11/40], Step [5500/16026], Loss: 0.0203\n",
      "Epoch [11/40], Step [5600/16026], Loss: 0.0221\n",
      "Epoch [11/40], Step [5700/16026], Loss: 0.0294\n",
      "Epoch [11/40], Step [5800/16026], Loss: 0.0158\n",
      "Epoch [11/40], Step [5900/16026], Loss: 0.0389\n",
      "Epoch [11/40], Step [6000/16026], Loss: 0.0265\n",
      "Epoch [11/40], Step [6100/16026], Loss: 0.0165\n",
      "Epoch [11/40], Step [6200/16026], Loss: 0.0180\n",
      "Epoch [11/40], Step [6300/16026], Loss: 0.0282\n",
      "Epoch [11/40], Step [6400/16026], Loss: 0.0187\n",
      "Epoch [11/40], Step [6500/16026], Loss: 0.0325\n",
      "Epoch [11/40], Step [6600/16026], Loss: 0.0344\n",
      "Epoch [11/40], Step [6700/16026], Loss: 0.0187\n",
      "Epoch [11/40], Step [6800/16026], Loss: 0.0198\n",
      "Epoch [11/40], Step [6900/16026], Loss: 0.0184\n",
      "Epoch [11/40], Step [7000/16026], Loss: 0.0384\n",
      "Epoch [11/40], Step [7100/16026], Loss: 0.0229\n",
      "Epoch [11/40], Step [7200/16026], Loss: 0.0227\n",
      "Epoch [11/40], Step [7300/16026], Loss: 0.0248\n",
      "Epoch [11/40], Step [7400/16026], Loss: 0.0148\n",
      "Epoch [11/40], Step [7500/16026], Loss: 0.0383\n",
      "Epoch [11/40], Step [7600/16026], Loss: 0.0223\n",
      "Epoch [11/40], Step [7700/16026], Loss: 0.0212\n",
      "Epoch [11/40], Step [7800/16026], Loss: 0.0247\n",
      "Epoch [11/40], Step [7900/16026], Loss: 0.0258\n",
      "Epoch [11/40], Step [8000/16026], Loss: 0.0167\n",
      "Epoch [11/40], Step [8100/16026], Loss: 0.0168\n",
      "Epoch [11/40], Step [8200/16026], Loss: 0.0195\n",
      "Epoch [11/40], Step [8300/16026], Loss: 0.0154\n",
      "Epoch [11/40], Step [8400/16026], Loss: 0.0318\n",
      "Epoch [11/40], Step [8500/16026], Loss: 0.0226\n",
      "Epoch [11/40], Step [8600/16026], Loss: 0.0191\n",
      "Epoch [11/40], Step [8700/16026], Loss: 0.0135\n",
      "Epoch [11/40], Step [8800/16026], Loss: 0.0192\n",
      "Epoch [11/40], Step [8900/16026], Loss: 0.0206\n",
      "Epoch [11/40], Step [9000/16026], Loss: 0.0291\n",
      "Epoch [11/40], Step [9100/16026], Loss: 0.0221\n",
      "Epoch [11/40], Step [9200/16026], Loss: 0.0199\n",
      "Epoch [11/40], Step [9300/16026], Loss: 0.0148\n",
      "Epoch [11/40], Step [9400/16026], Loss: 0.0272\n",
      "Epoch [11/40], Step [9500/16026], Loss: 0.0114\n",
      "Epoch [11/40], Step [9600/16026], Loss: 0.0554\n",
      "Epoch [11/40], Step [9700/16026], Loss: 0.0169\n",
      "Epoch [11/40], Step [9800/16026], Loss: 0.0271\n",
      "Epoch [11/40], Step [9900/16026], Loss: 0.0264\n",
      "Epoch [11/40], Step [10000/16026], Loss: 0.0246\n",
      "Epoch [11/40], Step [10100/16026], Loss: 0.0233\n",
      "Epoch [11/40], Step [10200/16026], Loss: 0.0193\n",
      "Epoch [11/40], Step [10300/16026], Loss: 0.0196\n",
      "Epoch [11/40], Step [10400/16026], Loss: 0.0220\n",
      "Epoch [11/40], Step [10500/16026], Loss: 0.0180\n",
      "Epoch [11/40], Step [10600/16026], Loss: 0.0261\n",
      "Epoch [11/40], Step [10700/16026], Loss: 0.0311\n",
      "Epoch [11/40], Step [10800/16026], Loss: 0.0279\n",
      "Epoch [11/40], Step [10900/16026], Loss: 0.0212\n",
      "Epoch [11/40], Step [11000/16026], Loss: 0.0250\n",
      "Epoch [11/40], Step [11100/16026], Loss: 0.0171\n",
      "Epoch [11/40], Step [11200/16026], Loss: 0.0347\n",
      "Epoch [11/40], Step [11300/16026], Loss: 0.0237\n",
      "Epoch [11/40], Step [11400/16026], Loss: 0.0250\n",
      "Epoch [11/40], Step [11500/16026], Loss: 0.0200\n",
      "Epoch [11/40], Step [11600/16026], Loss: 0.0808\n",
      "Epoch [11/40], Step [11700/16026], Loss: 0.0200\n",
      "Epoch [11/40], Step [11800/16026], Loss: 0.0134\n",
      "Epoch [11/40], Step [11900/16026], Loss: 0.0207\n",
      "Epoch [11/40], Step [12000/16026], Loss: 0.0253\n",
      "Epoch [11/40], Step [12100/16026], Loss: 0.0255\n",
      "Epoch [11/40], Step [12200/16026], Loss: 0.0180\n",
      "Epoch [11/40], Step [12300/16026], Loss: 0.0198\n",
      "Epoch [11/40], Step [12400/16026], Loss: 0.0183\n",
      "Epoch [11/40], Step [12500/16026], Loss: 0.0147\n",
      "Epoch [11/40], Step [12600/16026], Loss: 0.0174\n",
      "Epoch [11/40], Step [12700/16026], Loss: 0.0272\n",
      "Epoch [11/40], Step [12800/16026], Loss: 0.0238\n",
      "Epoch [11/40], Step [12900/16026], Loss: 0.0231\n",
      "Epoch [11/40], Step [13000/16026], Loss: 0.0207\n",
      "Epoch [11/40], Step [13100/16026], Loss: 0.0382\n",
      "Epoch [11/40], Step [13200/16026], Loss: 0.0180\n",
      "Epoch [11/40], Step [13300/16026], Loss: 0.0304\n",
      "Epoch [11/40], Step [13400/16026], Loss: 0.0274\n",
      "Epoch [11/40], Step [13500/16026], Loss: 0.0241\n",
      "Epoch [11/40], Step [13600/16026], Loss: 0.0202\n",
      "Epoch [11/40], Step [13700/16026], Loss: 0.0198\n",
      "Epoch [11/40], Step [13800/16026], Loss: 0.0187\n",
      "Epoch [11/40], Step [13900/16026], Loss: 0.0220\n",
      "Epoch [11/40], Step [14000/16026], Loss: 0.0197\n",
      "Epoch [11/40], Step [14100/16026], Loss: 0.0266\n",
      "Epoch [11/40], Step [14200/16026], Loss: 0.0217\n",
      "Epoch [11/40], Step [14300/16026], Loss: 0.0201\n",
      "Epoch [11/40], Step [14400/16026], Loss: 0.0313\n",
      "Epoch [11/40], Step [14500/16026], Loss: 0.0170\n",
      "Epoch [11/40], Step [14600/16026], Loss: 0.0209\n",
      "Epoch [11/40], Step [14700/16026], Loss: 0.0233\n",
      "Epoch [11/40], Step [14800/16026], Loss: 0.0147\n",
      "Epoch [11/40], Step [14900/16026], Loss: 0.0265\n",
      "Epoch [11/40], Step [15000/16026], Loss: 0.0200\n",
      "Epoch [11/40], Step [15100/16026], Loss: 0.0358\n",
      "Epoch [11/40], Step [15200/16026], Loss: 0.0310\n",
      "Epoch [11/40], Step [15300/16026], Loss: 0.0277\n",
      "Epoch [11/40], Step [15400/16026], Loss: 0.0211\n",
      "Epoch [11/40], Step [15500/16026], Loss: 0.0241\n",
      "Epoch [11/40], Step [15600/16026], Loss: 0.0176\n",
      "Epoch [11/40], Step [15700/16026], Loss: 0.0231\n",
      "Epoch [11/40], Step [15800/16026], Loss: 0.0464\n",
      "Epoch [11/40], Step [15900/16026], Loss: 0.0280\n",
      "Epoch [11/40], Step [16000/16026], Loss: 0.0379\n",
      "Epoch [12/40], Step [100/16026], Loss: 0.0404\n",
      "Epoch [12/40], Step [200/16026], Loss: 0.0236\n",
      "Epoch [12/40], Step [300/16026], Loss: 0.0179\n",
      "Epoch [12/40], Step [400/16026], Loss: 0.0227\n",
      "Epoch [12/40], Step [500/16026], Loss: 0.0552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/40], Step [600/16026], Loss: 0.0158\n",
      "Epoch [12/40], Step [700/16026], Loss: 0.0208\n",
      "Epoch [12/40], Step [800/16026], Loss: 0.0180\n",
      "Epoch [12/40], Step [900/16026], Loss: 0.0213\n",
      "Epoch [12/40], Step [1000/16026], Loss: 0.0197\n",
      "Epoch [12/40], Step [1100/16026], Loss: 0.0146\n",
      "Epoch [12/40], Step [1200/16026], Loss: 0.0206\n",
      "Epoch [12/40], Step [1300/16026], Loss: 0.0226\n",
      "Epoch [12/40], Step [1400/16026], Loss: 0.0142\n",
      "Epoch [12/40], Step [1500/16026], Loss: 0.0251\n",
      "Epoch [12/40], Step [1600/16026], Loss: 0.0269\n",
      "Epoch [12/40], Step [1700/16026], Loss: 0.0158\n",
      "Epoch [12/40], Step [1800/16026], Loss: 0.0149\n",
      "Epoch [12/40], Step [1900/16026], Loss: 0.0272\n",
      "Epoch [12/40], Step [2000/16026], Loss: 0.0281\n",
      "Epoch [12/40], Step [2100/16026], Loss: 0.0259\n",
      "Epoch [12/40], Step [2200/16026], Loss: 0.0149\n",
      "Epoch [12/40], Step [2300/16026], Loss: 0.0150\n",
      "Epoch [12/40], Step [2400/16026], Loss: 0.0210\n",
      "Epoch [12/40], Step [2500/16026], Loss: 0.0232\n",
      "Epoch [12/40], Step [2600/16026], Loss: 0.0312\n",
      "Epoch [12/40], Step [2700/16026], Loss: 0.0165\n",
      "Epoch [12/40], Step [2800/16026], Loss: 0.0217\n",
      "Epoch [12/40], Step [2900/16026], Loss: 0.0390\n",
      "Epoch [12/40], Step [3000/16026], Loss: 0.0222\n",
      "Epoch [12/40], Step [3100/16026], Loss: 0.0174\n",
      "Epoch [12/40], Step [3200/16026], Loss: 0.0202\n",
      "Epoch [12/40], Step [3300/16026], Loss: 0.0288\n",
      "Epoch [12/40], Step [3400/16026], Loss: 0.0283\n",
      "Epoch [12/40], Step [3500/16026], Loss: 0.0479\n",
      "Epoch [12/40], Step [3600/16026], Loss: 0.0285\n",
      "Epoch [12/40], Step [3700/16026], Loss: 0.0265\n",
      "Epoch [12/40], Step [3800/16026], Loss: 0.0239\n",
      "Epoch [12/40], Step [3900/16026], Loss: 0.0356\n",
      "Epoch [12/40], Step [4000/16026], Loss: 0.0270\n",
      "Epoch [12/40], Step [4100/16026], Loss: 0.0163\n",
      "Epoch [12/40], Step [4200/16026], Loss: 0.0295\n",
      "Epoch [12/40], Step [4300/16026], Loss: 0.0210\n",
      "Epoch [12/40], Step [4400/16026], Loss: 0.0252\n",
      "Epoch [12/40], Step [4500/16026], Loss: 0.0303\n",
      "Epoch [12/40], Step [4600/16026], Loss: 0.0171\n",
      "Epoch [12/40], Step [4700/16026], Loss: 0.0119\n",
      "Epoch [12/40], Step [4800/16026], Loss: 0.0219\n",
      "Epoch [12/40], Step [4900/16026], Loss: 0.0285\n",
      "Epoch [12/40], Step [5000/16026], Loss: 0.0220\n",
      "Epoch [12/40], Step [5100/16026], Loss: 0.0197\n",
      "Epoch [12/40], Step [5200/16026], Loss: 0.0261\n",
      "Epoch [12/40], Step [5300/16026], Loss: 0.0256\n",
      "Epoch [12/40], Step [5400/16026], Loss: 0.0271\n",
      "Epoch [12/40], Step [5500/16026], Loss: 0.0141\n",
      "Epoch [12/40], Step [5600/16026], Loss: 0.0197\n",
      "Epoch [12/40], Step [5700/16026], Loss: 0.0194\n",
      "Epoch [12/40], Step [5800/16026], Loss: 0.0396\n",
      "Epoch [12/40], Step [5900/16026], Loss: 0.0176\n",
      "Epoch [12/40], Step [6000/16026], Loss: 0.0277\n",
      "Epoch [12/40], Step [6100/16026], Loss: 0.0232\n",
      "Epoch [12/40], Step [6200/16026], Loss: 0.0250\n",
      "Epoch [12/40], Step [6300/16026], Loss: 0.0291\n",
      "Epoch [12/40], Step [6400/16026], Loss: 0.0131\n",
      "Epoch [12/40], Step [6500/16026], Loss: 0.0134\n",
      "Epoch [12/40], Step [6600/16026], Loss: 0.0214\n",
      "Epoch [12/40], Step [6700/16026], Loss: 0.0305\n",
      "Epoch [12/40], Step [6800/16026], Loss: 0.0217\n",
      "Epoch [12/40], Step [6900/16026], Loss: 0.0219\n",
      "Epoch [12/40], Step [7000/16026], Loss: 0.0186\n",
      "Epoch [12/40], Step [7100/16026], Loss: 0.0184\n",
      "Epoch [12/40], Step [7200/16026], Loss: 0.0161\n",
      "Epoch [12/40], Step [7300/16026], Loss: 0.0290\n",
      "Epoch [12/40], Step [7400/16026], Loss: 0.0202\n",
      "Epoch [12/40], Step [7500/16026], Loss: 0.0332\n",
      "Epoch [12/40], Step [7600/16026], Loss: 0.0193\n",
      "Epoch [12/40], Step [7700/16026], Loss: 0.0200\n",
      "Epoch [12/40], Step [7800/16026], Loss: 0.0189\n",
      "Epoch [12/40], Step [7900/16026], Loss: 0.0220\n",
      "Epoch [12/40], Step [8000/16026], Loss: 0.0205\n",
      "Epoch [12/40], Step [8100/16026], Loss: 0.0188\n",
      "Epoch [12/40], Step [8200/16026], Loss: 0.0269\n",
      "Epoch [12/40], Step [8300/16026], Loss: 0.0231\n",
      "Epoch [12/40], Step [8400/16026], Loss: 0.0196\n",
      "Epoch [12/40], Step [8500/16026], Loss: 0.0192\n",
      "Epoch [12/40], Step [8600/16026], Loss: 0.0320\n",
      "Epoch [12/40], Step [8700/16026], Loss: 0.0222\n",
      "Epoch [12/40], Step [8800/16026], Loss: 0.0257\n",
      "Epoch [12/40], Step [8900/16026], Loss: 0.0249\n",
      "Epoch [12/40], Step [9000/16026], Loss: 0.0263\n",
      "Epoch [12/40], Step [9100/16026], Loss: 0.0194\n",
      "Epoch [12/40], Step [9200/16026], Loss: 0.0288\n",
      "Epoch [12/40], Step [9300/16026], Loss: 0.0754\n",
      "Epoch [12/40], Step [9400/16026], Loss: 0.0339\n",
      "Epoch [12/40], Step [9500/16026], Loss: 0.0406\n",
      "Epoch [12/40], Step [9600/16026], Loss: 0.0180\n",
      "Epoch [12/40], Step [9700/16026], Loss: 0.0226\n",
      "Epoch [12/40], Step [9800/16026], Loss: 0.0195\n",
      "Epoch [12/40], Step [9900/16026], Loss: 0.0140\n",
      "Epoch [12/40], Step [10000/16026], Loss: 0.0263\n",
      "Epoch [12/40], Step [10100/16026], Loss: 0.0292\n",
      "Epoch [12/40], Step [10200/16026], Loss: 0.0139\n",
      "Epoch [12/40], Step [10300/16026], Loss: 0.0191\n",
      "Epoch [12/40], Step [10400/16026], Loss: 0.0218\n",
      "Epoch [12/40], Step [10500/16026], Loss: 0.0230\n",
      "Epoch [12/40], Step [10600/16026], Loss: 0.0221\n",
      "Epoch [12/40], Step [10700/16026], Loss: 0.0148\n",
      "Epoch [12/40], Step [10800/16026], Loss: 0.0216\n",
      "Epoch [12/40], Step [10900/16026], Loss: 0.0159\n",
      "Epoch [12/40], Step [11000/16026], Loss: 0.0121\n",
      "Epoch [12/40], Step [11100/16026], Loss: 0.0326\n",
      "Epoch [12/40], Step [11200/16026], Loss: 0.0276\n",
      "Epoch [12/40], Step [11300/16026], Loss: 0.0176\n",
      "Epoch [12/40], Step [11400/16026], Loss: 0.0230\n",
      "Epoch [12/40], Step [11500/16026], Loss: 0.0154\n",
      "Epoch [12/40], Step [11600/16026], Loss: 0.0249\n",
      "Epoch [12/40], Step [11700/16026], Loss: 0.0716\n",
      "Epoch [12/40], Step [11800/16026], Loss: 0.0151\n",
      "Epoch [12/40], Step [11900/16026], Loss: 0.0221\n",
      "Epoch [12/40], Step [12000/16026], Loss: 0.0251\n",
      "Epoch [12/40], Step [12100/16026], Loss: 0.0272\n",
      "Epoch [12/40], Step [12200/16026], Loss: 0.0116\n",
      "Epoch [12/40], Step [12300/16026], Loss: 0.0336\n",
      "Epoch [12/40], Step [12400/16026], Loss: 0.0171\n",
      "Epoch [12/40], Step [12500/16026], Loss: 0.0133\n",
      "Epoch [12/40], Step [12600/16026], Loss: 0.0195\n",
      "Epoch [12/40], Step [12700/16026], Loss: 0.0329\n",
      "Epoch [12/40], Step [12800/16026], Loss: 0.0361\n",
      "Epoch [12/40], Step [12900/16026], Loss: 0.0166\n",
      "Epoch [12/40], Step [13000/16026], Loss: 0.0183\n",
      "Epoch [12/40], Step [13100/16026], Loss: 0.0215\n",
      "Epoch [12/40], Step [13200/16026], Loss: 0.0262\n",
      "Epoch [12/40], Step [13300/16026], Loss: 0.0284\n",
      "Epoch [12/40], Step [13400/16026], Loss: 0.0341\n",
      "Epoch [12/40], Step [13500/16026], Loss: 0.0216\n",
      "Epoch [12/40], Step [13600/16026], Loss: 0.0208\n",
      "Epoch [12/40], Step [13700/16026], Loss: 0.0168\n",
      "Epoch [12/40], Step [13800/16026], Loss: 0.0252\n",
      "Epoch [12/40], Step [13900/16026], Loss: 0.0265\n",
      "Epoch [12/40], Step [14000/16026], Loss: 0.0290\n",
      "Epoch [12/40], Step [14100/16026], Loss: 0.0256\n",
      "Epoch [12/40], Step [14200/16026], Loss: 0.0213\n",
      "Epoch [12/40], Step [14300/16026], Loss: 0.0279\n",
      "Epoch [12/40], Step [14400/16026], Loss: 0.0347\n",
      "Epoch [12/40], Step [14500/16026], Loss: 0.0196\n",
      "Epoch [12/40], Step [14600/16026], Loss: 0.0196\n",
      "Epoch [12/40], Step [14700/16026], Loss: 0.0213\n",
      "Epoch [12/40], Step [14800/16026], Loss: 0.0260\n",
      "Epoch [12/40], Step [14900/16026], Loss: 0.0167\n",
      "Epoch [12/40], Step [15000/16026], Loss: 0.0201\n",
      "Epoch [12/40], Step [15100/16026], Loss: 0.0099\n",
      "Epoch [12/40], Step [15200/16026], Loss: 0.0158\n",
      "Epoch [12/40], Step [15300/16026], Loss: 0.0216\n",
      "Epoch [12/40], Step [15400/16026], Loss: 0.0337\n",
      "Epoch [12/40], Step [15500/16026], Loss: 0.0178\n",
      "Epoch [12/40], Step [15600/16026], Loss: 0.0147\n",
      "Epoch [12/40], Step [15700/16026], Loss: 0.0301\n",
      "Epoch [12/40], Step [15800/16026], Loss: 0.0390\n",
      "Epoch [12/40], Step [15900/16026], Loss: 0.0170\n",
      "Epoch [12/40], Step [16000/16026], Loss: 0.0207\n",
      "Epoch [13/40], Step [100/16026], Loss: 0.0161\n",
      "Epoch [13/40], Step [200/16026], Loss: 0.0164\n",
      "Epoch [13/40], Step [300/16026], Loss: 0.0211\n",
      "Epoch [13/40], Step [400/16026], Loss: 0.0194\n",
      "Epoch [13/40], Step [500/16026], Loss: 0.0304\n",
      "Epoch [13/40], Step [600/16026], Loss: 0.0300\n",
      "Epoch [13/40], Step [700/16026], Loss: 0.0221\n",
      "Epoch [13/40], Step [800/16026], Loss: 0.0148\n",
      "Epoch [13/40], Step [900/16026], Loss: 0.0427\n",
      "Epoch [13/40], Step [1000/16026], Loss: 0.0201\n",
      "Epoch [13/40], Step [1100/16026], Loss: 0.0292\n",
      "Epoch [13/40], Step [1200/16026], Loss: 0.0162\n",
      "Epoch [13/40], Step [1300/16026], Loss: 0.0246\n",
      "Epoch [13/40], Step [1400/16026], Loss: 0.0199\n",
      "Epoch [13/40], Step [1500/16026], Loss: 0.0247\n",
      "Epoch [13/40], Step [1600/16026], Loss: 0.0215\n",
      "Epoch [13/40], Step [1700/16026], Loss: 0.0191\n",
      "Epoch [13/40], Step [1800/16026], Loss: 0.0199\n",
      "Epoch [13/40], Step [1900/16026], Loss: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/40], Step [2000/16026], Loss: 0.0178\n",
      "Epoch [13/40], Step [2100/16026], Loss: 0.0081\n",
      "Epoch [13/40], Step [2200/16026], Loss: 0.0159\n",
      "Epoch [13/40], Step [2300/16026], Loss: 0.0147\n",
      "Epoch [13/40], Step [2400/16026], Loss: 0.0244\n",
      "Epoch [13/40], Step [2500/16026], Loss: 0.0221\n",
      "Epoch [13/40], Step [2600/16026], Loss: 0.0207\n",
      "Epoch [13/40], Step [2700/16026], Loss: 0.0160\n",
      "Epoch [13/40], Step [2800/16026], Loss: 0.0347\n",
      "Epoch [13/40], Step [2900/16026], Loss: 0.0311\n",
      "Epoch [13/40], Step [3000/16026], Loss: 0.0228\n",
      "Epoch [13/40], Step [3100/16026], Loss: 0.0281\n",
      "Epoch [13/40], Step [3200/16026], Loss: 0.0200\n",
      "Epoch [13/40], Step [3300/16026], Loss: 0.0209\n",
      "Epoch [13/40], Step [3400/16026], Loss: 0.0284\n",
      "Epoch [13/40], Step [3500/16026], Loss: 0.0289\n",
      "Epoch [13/40], Step [3600/16026], Loss: 0.0228\n",
      "Epoch [13/40], Step [3700/16026], Loss: 0.0179\n",
      "Epoch [13/40], Step [3800/16026], Loss: 0.0135\n",
      "Epoch [13/40], Step [3900/16026], Loss: 0.0206\n",
      "Epoch [13/40], Step [4000/16026], Loss: 0.0248\n",
      "Epoch [13/40], Step [4100/16026], Loss: 0.0389\n",
      "Epoch [13/40], Step [4200/16026], Loss: 0.0265\n",
      "Epoch [13/40], Step [4300/16026], Loss: 0.0257\n",
      "Epoch [13/40], Step [4400/16026], Loss: 0.0146\n",
      "Epoch [13/40], Step [4500/16026], Loss: 0.0227\n",
      "Epoch [13/40], Step [4600/16026], Loss: 0.0296\n",
      "Epoch [13/40], Step [4700/16026], Loss: 0.0252\n",
      "Epoch [13/40], Step [4800/16026], Loss: 0.0287\n",
      "Epoch [13/40], Step [4900/16026], Loss: 0.0201\n",
      "Epoch [13/40], Step [5000/16026], Loss: 0.0525\n",
      "Epoch [13/40], Step [5100/16026], Loss: 0.0199\n",
      "Epoch [13/40], Step [5200/16026], Loss: 0.0143\n",
      "Epoch [13/40], Step [5300/16026], Loss: 0.0140\n",
      "Epoch [13/40], Step [5400/16026], Loss: 0.0357\n",
      "Epoch [13/40], Step [5500/16026], Loss: 0.0175\n",
      "Epoch [13/40], Step [5600/16026], Loss: 0.0188\n",
      "Epoch [13/40], Step [5700/16026], Loss: 0.0196\n",
      "Epoch [13/40], Step [5800/16026], Loss: 0.0178\n",
      "Epoch [13/40], Step [5900/16026], Loss: 0.0198\n",
      "Epoch [13/40], Step [6000/16026], Loss: 0.0178\n",
      "Epoch [13/40], Step [6100/16026], Loss: 0.0227\n",
      "Epoch [13/40], Step [6200/16026], Loss: 0.0193\n",
      "Epoch [13/40], Step [6300/16026], Loss: 0.0228\n",
      "Epoch [13/40], Step [6400/16026], Loss: 0.0248\n",
      "Epoch [13/40], Step [6500/16026], Loss: 0.0142\n",
      "Epoch [13/40], Step [6600/16026], Loss: 0.0278\n",
      "Epoch [13/40], Step [6700/16026], Loss: 0.0135\n",
      "Epoch [13/40], Step [6800/16026], Loss: 0.0159\n",
      "Epoch [13/40], Step [6900/16026], Loss: 0.0297\n",
      "Epoch [13/40], Step [7000/16026], Loss: 0.0253\n",
      "Epoch [13/40], Step [7100/16026], Loss: 0.0198\n",
      "Epoch [13/40], Step [7200/16026], Loss: 0.0252\n",
      "Epoch [13/40], Step [7300/16026], Loss: 0.0220\n",
      "Epoch [13/40], Step [7400/16026], Loss: 0.0285\n",
      "Epoch [13/40], Step [7500/16026], Loss: 0.0264\n",
      "Epoch [13/40], Step [7600/16026], Loss: 0.0292\n",
      "Epoch [13/40], Step [7700/16026], Loss: 0.0675\n",
      "Epoch [13/40], Step [7800/16026], Loss: 0.0277\n",
      "Epoch [13/40], Step [7900/16026], Loss: 0.0331\n",
      "Epoch [13/40], Step [8000/16026], Loss: 0.0202\n",
      "Epoch [13/40], Step [8100/16026], Loss: 0.0257\n",
      "Epoch [13/40], Step [8200/16026], Loss: 0.0175\n",
      "Epoch [13/40], Step [8300/16026], Loss: 0.0222\n",
      "Epoch [13/40], Step [8400/16026], Loss: 0.0178\n",
      "Epoch [13/40], Step [8500/16026], Loss: 0.0281\n",
      "Epoch [13/40], Step [8600/16026], Loss: 0.0207\n",
      "Epoch [13/40], Step [8700/16026], Loss: 0.0148\n",
      "Epoch [13/40], Step [8800/16026], Loss: 0.0231\n",
      "Epoch [13/40], Step [8900/16026], Loss: 0.0224\n",
      "Epoch [13/40], Step [9000/16026], Loss: 0.0238\n",
      "Epoch [13/40], Step [9100/16026], Loss: 0.0236\n",
      "Epoch [13/40], Step [9200/16026], Loss: 0.0209\n",
      "Epoch [13/40], Step [9300/16026], Loss: 0.0236\n",
      "Epoch [13/40], Step [9400/16026], Loss: 0.0291\n",
      "Epoch [13/40], Step [9500/16026], Loss: 0.0185\n",
      "Epoch [13/40], Step [9600/16026], Loss: 0.0307\n",
      "Epoch [13/40], Step [9700/16026], Loss: 0.0276\n",
      "Epoch [13/40], Step [9800/16026], Loss: 0.0138\n",
      "Epoch [13/40], Step [9900/16026], Loss: 0.0162\n",
      "Epoch [13/40], Step [10000/16026], Loss: 0.0382\n",
      "Epoch [13/40], Step [10100/16026], Loss: 0.0226\n",
      "Epoch [13/40], Step [10200/16026], Loss: 0.0169\n",
      "Epoch [13/40], Step [10300/16026], Loss: 0.0253\n",
      "Epoch [13/40], Step [10400/16026], Loss: 0.0260\n",
      "Epoch [13/40], Step [10500/16026], Loss: 0.0257\n",
      "Epoch [13/40], Step [10600/16026], Loss: 0.0270\n",
      "Epoch [13/40], Step [10700/16026], Loss: 0.0267\n",
      "Epoch [13/40], Step [10800/16026], Loss: 0.0234\n",
      "Epoch [13/40], Step [10900/16026], Loss: 0.0333\n",
      "Epoch [13/40], Step [11000/16026], Loss: 0.0217\n",
      "Epoch [13/40], Step [11100/16026], Loss: 0.0249\n",
      "Epoch [13/40], Step [11200/16026], Loss: 0.0211\n",
      "Epoch [13/40], Step [11300/16026], Loss: 0.0222\n",
      "Epoch [13/40], Step [11400/16026], Loss: 0.0164\n",
      "Epoch [13/40], Step [11500/16026], Loss: 0.0244\n",
      "Epoch [13/40], Step [11600/16026], Loss: 0.0358\n",
      "Epoch [13/40], Step [11700/16026], Loss: 0.0219\n",
      "Epoch [13/40], Step [11800/16026], Loss: 0.0385\n",
      "Epoch [13/40], Step [11900/16026], Loss: 0.0184\n",
      "Epoch [13/40], Step [12000/16026], Loss: 0.0262\n",
      "Epoch [13/40], Step [12100/16026], Loss: 0.0347\n",
      "Epoch [13/40], Step [12200/16026], Loss: 0.0268\n",
      "Epoch [13/40], Step [12300/16026], Loss: 0.0210\n",
      "Epoch [13/40], Step [12400/16026], Loss: 0.0253\n",
      "Epoch [13/40], Step [12500/16026], Loss: 0.0171\n",
      "Epoch [13/40], Step [12600/16026], Loss: 0.0259\n",
      "Epoch [13/40], Step [12700/16026], Loss: 0.0171\n",
      "Epoch [13/40], Step [12800/16026], Loss: 0.0170\n",
      "Epoch [13/40], Step [12900/16026], Loss: 0.0185\n",
      "Epoch [13/40], Step [13000/16026], Loss: 0.0252\n",
      "Epoch [13/40], Step [13100/16026], Loss: 0.0170\n",
      "Epoch [13/40], Step [13200/16026], Loss: 0.0192\n",
      "Epoch [13/40], Step [13300/16026], Loss: 0.0232\n",
      "Epoch [13/40], Step [13400/16026], Loss: 0.0274\n",
      "Epoch [13/40], Step [13500/16026], Loss: 0.0182\n",
      "Epoch [13/40], Step [13600/16026], Loss: 0.0289\n",
      "Epoch [13/40], Step [13700/16026], Loss: 0.0186\n",
      "Epoch [13/40], Step [13800/16026], Loss: 0.0179\n",
      "Epoch [13/40], Step [13900/16026], Loss: 0.0227\n",
      "Epoch [13/40], Step [14000/16026], Loss: 0.0280\n",
      "Epoch [13/40], Step [14100/16026], Loss: 0.0225\n",
      "Epoch [13/40], Step [14200/16026], Loss: 0.0335\n",
      "Epoch [13/40], Step [14300/16026], Loss: 0.0138\n",
      "Epoch [13/40], Step [14400/16026], Loss: 0.0273\n",
      "Epoch [13/40], Step [14500/16026], Loss: 0.0159\n",
      "Epoch [13/40], Step [14600/16026], Loss: 0.0210\n",
      "Epoch [13/40], Step [14700/16026], Loss: 0.0181\n",
      "Epoch [13/40], Step [14800/16026], Loss: 0.0196\n",
      "Epoch [13/40], Step [14900/16026], Loss: 0.0220\n",
      "Epoch [13/40], Step [15000/16026], Loss: 0.0146\n",
      "Epoch [13/40], Step [15100/16026], Loss: 0.0216\n",
      "Epoch [13/40], Step [15200/16026], Loss: 0.0164\n",
      "Epoch [13/40], Step [15300/16026], Loss: 0.0131\n",
      "Epoch [13/40], Step [15400/16026], Loss: 0.0202\n",
      "Epoch [13/40], Step [15500/16026], Loss: 0.0231\n",
      "Epoch [13/40], Step [15600/16026], Loss: 0.0185\n",
      "Epoch [13/40], Step [15700/16026], Loss: 0.0175\n",
      "Epoch [13/40], Step [15800/16026], Loss: 0.0212\n",
      "Epoch [13/40], Step [15900/16026], Loss: 0.0255\n",
      "Epoch [13/40], Step [16000/16026], Loss: 0.0244\n",
      "Epoch [14/40], Step [100/16026], Loss: 0.0343\n",
      "Epoch [14/40], Step [200/16026], Loss: 0.0234\n",
      "Epoch [14/40], Step [300/16026], Loss: 0.0166\n",
      "Epoch [14/40], Step [400/16026], Loss: 0.0207\n",
      "Epoch [14/40], Step [500/16026], Loss: 0.0212\n",
      "Epoch [14/40], Step [600/16026], Loss: 0.0185\n",
      "Epoch [14/40], Step [700/16026], Loss: 0.0159\n",
      "Epoch [14/40], Step [800/16026], Loss: 0.0175\n",
      "Epoch [14/40], Step [900/16026], Loss: 0.0378\n",
      "Epoch [14/40], Step [1000/16026], Loss: 0.0168\n",
      "Epoch [14/40], Step [1100/16026], Loss: 0.0266\n",
      "Epoch [14/40], Step [1200/16026], Loss: 0.0168\n",
      "Epoch [14/40], Step [1300/16026], Loss: 0.0389\n",
      "Epoch [14/40], Step [1400/16026], Loss: 0.0187\n",
      "Epoch [14/40], Step [1500/16026], Loss: 0.0285\n",
      "Epoch [14/40], Step [1600/16026], Loss: 0.0283\n",
      "Epoch [14/40], Step [1700/16026], Loss: 0.0161\n",
      "Epoch [14/40], Step [1800/16026], Loss: 0.0236\n",
      "Epoch [14/40], Step [1900/16026], Loss: 0.0311\n",
      "Epoch [14/40], Step [2000/16026], Loss: 0.0233\n",
      "Epoch [14/40], Step [2100/16026], Loss: 0.0357\n",
      "Epoch [14/40], Step [2200/16026], Loss: 0.0135\n",
      "Epoch [14/40], Step [2300/16026], Loss: 0.0223\n",
      "Epoch [14/40], Step [2400/16026], Loss: 0.0278\n",
      "Epoch [14/40], Step [2500/16026], Loss: 0.0177\n",
      "Epoch [14/40], Step [2600/16026], Loss: 0.0213\n",
      "Epoch [14/40], Step [2700/16026], Loss: 0.0195\n",
      "Epoch [14/40], Step [2800/16026], Loss: 0.0187\n",
      "Epoch [14/40], Step [2900/16026], Loss: 0.0381\n",
      "Epoch [14/40], Step [3000/16026], Loss: 0.0212\n",
      "Epoch [14/40], Step [3100/16026], Loss: 0.0244\n",
      "Epoch [14/40], Step [3200/16026], Loss: 0.0164\n",
      "Epoch [14/40], Step [3300/16026], Loss: 0.0221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/40], Step [3400/16026], Loss: 0.0269\n",
      "Epoch [14/40], Step [3500/16026], Loss: 0.0241\n",
      "Epoch [14/40], Step [3600/16026], Loss: 0.0257\n",
      "Epoch [14/40], Step [3700/16026], Loss: 0.0266\n",
      "Epoch [14/40], Step [3800/16026], Loss: 0.0235\n",
      "Epoch [14/40], Step [3900/16026], Loss: 0.0202\n",
      "Epoch [14/40], Step [4000/16026], Loss: 0.0173\n",
      "Epoch [14/40], Step [4100/16026], Loss: 0.0227\n",
      "Epoch [14/40], Step [4200/16026], Loss: 0.0209\n",
      "Epoch [14/40], Step [4300/16026], Loss: 0.0255\n",
      "Epoch [14/40], Step [4400/16026], Loss: 0.0259\n",
      "Epoch [14/40], Step [4500/16026], Loss: 0.0155\n",
      "Epoch [14/40], Step [4600/16026], Loss: 0.0133\n",
      "Epoch [14/40], Step [4700/16026], Loss: 0.0137\n",
      "Epoch [14/40], Step [4800/16026], Loss: 0.0236\n",
      "Epoch [14/40], Step [4900/16026], Loss: 0.0275\n",
      "Epoch [14/40], Step [5000/16026], Loss: 0.0261\n",
      "Epoch [14/40], Step [5100/16026], Loss: 0.0199\n",
      "Epoch [14/40], Step [5200/16026], Loss: 0.0166\n",
      "Epoch [14/40], Step [5300/16026], Loss: 0.0216\n",
      "Epoch [14/40], Step [5400/16026], Loss: 0.0163\n",
      "Epoch [14/40], Step [5500/16026], Loss: 0.0236\n",
      "Epoch [14/40], Step [5600/16026], Loss: 0.0140\n",
      "Epoch [14/40], Step [5700/16026], Loss: 0.0192\n",
      "Epoch [14/40], Step [5800/16026], Loss: 0.0305\n",
      "Epoch [14/40], Step [5900/16026], Loss: 0.0207\n",
      "Epoch [14/40], Step [6000/16026], Loss: 0.0276\n",
      "Epoch [14/40], Step [6100/16026], Loss: 0.0106\n",
      "Epoch [14/40], Step [6200/16026], Loss: 0.0190\n",
      "Epoch [14/40], Step [6300/16026], Loss: 0.0162\n",
      "Epoch [14/40], Step [6400/16026], Loss: 0.0186\n",
      "Epoch [14/40], Step [6500/16026], Loss: 0.0242\n",
      "Epoch [14/40], Step [6600/16026], Loss: 0.0326\n",
      "Epoch [14/40], Step [6700/16026], Loss: 0.0187\n",
      "Epoch [14/40], Step [6800/16026], Loss: 0.0235\n",
      "Epoch [14/40], Step [6900/16026], Loss: 0.0261\n",
      "Epoch [14/40], Step [7000/16026], Loss: 0.0245\n",
      "Epoch [14/40], Step [7100/16026], Loss: 0.0168\n",
      "Epoch [14/40], Step [7200/16026], Loss: 0.0174\n",
      "Epoch [14/40], Step [7300/16026], Loss: 0.0175\n",
      "Epoch [14/40], Step [7400/16026], Loss: 0.0251\n",
      "Epoch [14/40], Step [7500/16026], Loss: 0.0149\n",
      "Epoch [14/40], Step [7600/16026], Loss: 0.0438\n",
      "Epoch [14/40], Step [7700/16026], Loss: 0.0397\n",
      "Epoch [14/40], Step [7800/16026], Loss: 0.0176\n",
      "Epoch [14/40], Step [7900/16026], Loss: 0.0250\n",
      "Epoch [14/40], Step [8000/16026], Loss: 0.0231\n",
      "Epoch [14/40], Step [8100/16026], Loss: 0.0224\n",
      "Epoch [14/40], Step [8200/16026], Loss: 0.0196\n",
      "Epoch [14/40], Step [8300/16026], Loss: 0.0585\n",
      "Epoch [14/40], Step [8400/16026], Loss: 0.0180\n",
      "Epoch [14/40], Step [8500/16026], Loss: 0.0214\n",
      "Epoch [14/40], Step [8600/16026], Loss: 0.0243\n",
      "Epoch [14/40], Step [8700/16026], Loss: 0.0228\n",
      "Epoch [14/40], Step [8800/16026], Loss: 0.0220\n",
      "Epoch [14/40], Step [8900/16026], Loss: 0.0212\n",
      "Epoch [14/40], Step [9000/16026], Loss: 0.0220\n",
      "Epoch [14/40], Step [9100/16026], Loss: 0.0264\n",
      "Epoch [14/40], Step [9200/16026], Loss: 0.0177\n",
      "Epoch [14/40], Step [9300/16026], Loss: 0.0174\n",
      "Epoch [14/40], Step [9400/16026], Loss: 0.0147\n",
      "Epoch [14/40], Step [9500/16026], Loss: 0.0177\n",
      "Epoch [14/40], Step [9600/16026], Loss: 0.0261\n",
      "Epoch [14/40], Step [9700/16026], Loss: 0.0249\n",
      "Epoch [14/40], Step [9800/16026], Loss: 0.0181\n",
      "Epoch [14/40], Step [9900/16026], Loss: 0.0164\n",
      "Epoch [14/40], Step [10000/16026], Loss: 0.0300\n",
      "Epoch [14/40], Step [10100/16026], Loss: 0.0194\n",
      "Epoch [14/40], Step [10200/16026], Loss: 0.0170\n",
      "Epoch [14/40], Step [10300/16026], Loss: 0.0189\n",
      "Epoch [14/40], Step [10400/16026], Loss: 0.0135\n",
      "Epoch [14/40], Step [10500/16026], Loss: 0.0298\n",
      "Epoch [14/40], Step [10600/16026], Loss: 0.0179\n",
      "Epoch [14/40], Step [10700/16026], Loss: 0.0307\n",
      "Epoch [14/40], Step [10800/16026], Loss: 0.0171\n",
      "Epoch [14/40], Step [10900/16026], Loss: 0.0255\n",
      "Epoch [14/40], Step [11000/16026], Loss: 0.0187\n",
      "Epoch [14/40], Step [11100/16026], Loss: 0.0166\n",
      "Epoch [14/40], Step [11200/16026], Loss: 0.0261\n",
      "Epoch [14/40], Step [11300/16026], Loss: 0.0100\n",
      "Epoch [14/40], Step [11400/16026], Loss: 0.0245\n",
      "Epoch [14/40], Step [11500/16026], Loss: 0.0197\n",
      "Epoch [14/40], Step [11600/16026], Loss: 0.0210\n",
      "Epoch [14/40], Step [11700/16026], Loss: 0.0480\n",
      "Epoch [14/40], Step [11800/16026], Loss: 0.0202\n",
      "Epoch [14/40], Step [11900/16026], Loss: 0.0191\n",
      "Epoch [14/40], Step [12000/16026], Loss: 0.0187\n",
      "Epoch [14/40], Step [12100/16026], Loss: 0.0142\n",
      "Epoch [14/40], Step [12200/16026], Loss: 0.0253\n",
      "Epoch [14/40], Step [12300/16026], Loss: 0.0193\n",
      "Epoch [14/40], Step [12400/16026], Loss: 0.0153\n",
      "Epoch [14/40], Step [12500/16026], Loss: 0.0243\n",
      "Epoch [14/40], Step [12600/16026], Loss: 0.0360\n",
      "Epoch [14/40], Step [12700/16026], Loss: 0.0229\n",
      "Epoch [14/40], Step [12800/16026], Loss: 0.0137\n",
      "Epoch [14/40], Step [12900/16026], Loss: 0.0362\n",
      "Epoch [14/40], Step [13000/16026], Loss: 0.0247\n",
      "Epoch [14/40], Step [13100/16026], Loss: 0.0314\n",
      "Epoch [14/40], Step [13200/16026], Loss: 0.0318\n",
      "Epoch [14/40], Step [13300/16026], Loss: 0.0304\n",
      "Epoch [14/40], Step [13400/16026], Loss: 0.0318\n",
      "Epoch [14/40], Step [13500/16026], Loss: 0.0235\n",
      "Epoch [14/40], Step [13600/16026], Loss: 0.0358\n",
      "Epoch [14/40], Step [13700/16026], Loss: 0.0252\n",
      "Epoch [14/40], Step [13800/16026], Loss: 0.0233\n",
      "Epoch [14/40], Step [13900/16026], Loss: 0.0193\n",
      "Epoch [14/40], Step [14000/16026], Loss: 0.0284\n",
      "Epoch [14/40], Step [14100/16026], Loss: 0.0303\n",
      "Epoch [14/40], Step [14200/16026], Loss: 0.0255\n",
      "Epoch [14/40], Step [14300/16026], Loss: 0.0167\n",
      "Epoch [14/40], Step [14400/16026], Loss: 0.0282\n",
      "Epoch [14/40], Step [14500/16026], Loss: 0.0147\n",
      "Epoch [14/40], Step [14600/16026], Loss: 0.0229\n",
      "Epoch [14/40], Step [14700/16026], Loss: 0.0278\n",
      "Epoch [14/40], Step [14800/16026], Loss: 0.0277\n",
      "Epoch [14/40], Step [14900/16026], Loss: 0.0245\n",
      "Epoch [14/40], Step [15000/16026], Loss: 0.0243\n",
      "Epoch [14/40], Step [15100/16026], Loss: 0.0358\n",
      "Epoch [14/40], Step [15200/16026], Loss: 0.0237\n",
      "Epoch [14/40], Step [15300/16026], Loss: 0.0171\n",
      "Epoch [14/40], Step [15400/16026], Loss: 0.0183\n",
      "Epoch [14/40], Step [15500/16026], Loss: 0.0201\n",
      "Epoch [14/40], Step [15600/16026], Loss: 0.0426\n",
      "Epoch [14/40], Step [15700/16026], Loss: 0.0204\n",
      "Epoch [14/40], Step [15800/16026], Loss: 0.0255\n",
      "Epoch [14/40], Step [15900/16026], Loss: 0.0313\n",
      "Epoch [14/40], Step [16000/16026], Loss: 0.0261\n",
      "Epoch [15/40], Step [100/16026], Loss: 0.0196\n",
      "Epoch [15/40], Step [200/16026], Loss: 0.0147\n",
      "Epoch [15/40], Step [300/16026], Loss: 0.0168\n",
      "Epoch [15/40], Step [400/16026], Loss: 0.0273\n",
      "Epoch [15/40], Step [500/16026], Loss: 0.0151\n",
      "Epoch [15/40], Step [600/16026], Loss: 0.0252\n",
      "Epoch [15/40], Step [700/16026], Loss: 0.0432\n",
      "Epoch [15/40], Step [800/16026], Loss: 0.0220\n",
      "Epoch [15/40], Step [900/16026], Loss: 0.0295\n",
      "Epoch [15/40], Step [1000/16026], Loss: 0.0238\n",
      "Epoch [15/40], Step [1100/16026], Loss: 0.0209\n",
      "Epoch [15/40], Step [1200/16026], Loss: 0.0221\n",
      "Epoch [15/40], Step [1300/16026], Loss: 0.0308\n",
      "Epoch [15/40], Step [1400/16026], Loss: 0.0382\n",
      "Epoch [15/40], Step [1500/16026], Loss: 0.0215\n",
      "Epoch [15/40], Step [1600/16026], Loss: 0.0247\n",
      "Epoch [15/40], Step [1700/16026], Loss: 0.0264\n",
      "Epoch [15/40], Step [1800/16026], Loss: 0.0310\n",
      "Epoch [15/40], Step [1900/16026], Loss: 0.0275\n",
      "Epoch [15/40], Step [2000/16026], Loss: 0.0222\n",
      "Epoch [15/40], Step [2100/16026], Loss: 0.0215\n",
      "Epoch [15/40], Step [2200/16026], Loss: 0.0217\n",
      "Epoch [15/40], Step [2300/16026], Loss: 0.0274\n",
      "Epoch [15/40], Step [2400/16026], Loss: 0.0286\n",
      "Epoch [15/40], Step [2500/16026], Loss: 0.0243\n",
      "Epoch [15/40], Step [2600/16026], Loss: 0.0140\n",
      "Epoch [15/40], Step [2700/16026], Loss: 0.0234\n",
      "Epoch [15/40], Step [2800/16026], Loss: 0.0167\n",
      "Epoch [15/40], Step [2900/16026], Loss: 0.0262\n",
      "Epoch [15/40], Step [3000/16026], Loss: 0.0129\n",
      "Epoch [15/40], Step [3100/16026], Loss: 0.0240\n",
      "Epoch [15/40], Step [3200/16026], Loss: 0.0238\n",
      "Epoch [15/40], Step [3300/16026], Loss: 0.0224\n",
      "Epoch [15/40], Step [3400/16026], Loss: 0.0266\n",
      "Epoch [15/40], Step [3500/16026], Loss: 0.0305\n",
      "Epoch [15/40], Step [3600/16026], Loss: 0.0163\n",
      "Epoch [15/40], Step [3700/16026], Loss: 0.0236\n",
      "Epoch [15/40], Step [3800/16026], Loss: 0.0184\n",
      "Epoch [15/40], Step [3900/16026], Loss: 0.0138\n",
      "Epoch [15/40], Step [4000/16026], Loss: 0.0293\n",
      "Epoch [15/40], Step [4100/16026], Loss: 0.0141\n",
      "Epoch [15/40], Step [4200/16026], Loss: 0.0199\n",
      "Epoch [15/40], Step [4300/16026], Loss: 0.0217\n",
      "Epoch [15/40], Step [4400/16026], Loss: 0.0241\n",
      "Epoch [15/40], Step [4500/16026], Loss: 0.0213\n",
      "Epoch [15/40], Step [4600/16026], Loss: 0.0165\n",
      "Epoch [15/40], Step [4700/16026], Loss: 0.0147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/40], Step [4800/16026], Loss: 0.0244\n",
      "Epoch [15/40], Step [4900/16026], Loss: 0.0119\n",
      "Epoch [15/40], Step [5000/16026], Loss: 0.0158\n",
      "Epoch [15/40], Step [5100/16026], Loss: 0.0187\n",
      "Epoch [15/40], Step [5200/16026], Loss: 0.0180\n",
      "Epoch [15/40], Step [5300/16026], Loss: 0.0254\n",
      "Epoch [15/40], Step [5400/16026], Loss: 0.0138\n",
      "Epoch [15/40], Step [5500/16026], Loss: 0.0114\n",
      "Epoch [15/40], Step [5600/16026], Loss: 0.0203\n",
      "Epoch [15/40], Step [5700/16026], Loss: 0.0256\n",
      "Epoch [15/40], Step [5800/16026], Loss: 0.0239\n",
      "Epoch [15/40], Step [5900/16026], Loss: 0.0202\n",
      "Epoch [15/40], Step [6000/16026], Loss: 0.0275\n",
      "Epoch [15/40], Step [6100/16026], Loss: 0.0209\n",
      "Epoch [15/40], Step [6200/16026], Loss: 0.0171\n",
      "Epoch [15/40], Step [6300/16026], Loss: 0.0330\n",
      "Epoch [15/40], Step [6400/16026], Loss: 0.0242\n",
      "Epoch [15/40], Step [6500/16026], Loss: 0.0175\n",
      "Epoch [15/40], Step [6600/16026], Loss: 0.0171\n",
      "Epoch [15/40], Step [6700/16026], Loss: 0.0283\n",
      "Epoch [15/40], Step [6800/16026], Loss: 0.0228\n",
      "Epoch [15/40], Step [6900/16026], Loss: 0.0156\n",
      "Epoch [15/40], Step [7000/16026], Loss: 0.0271\n",
      "Epoch [15/40], Step [7100/16026], Loss: 0.0234\n",
      "Epoch [15/40], Step [7200/16026], Loss: 0.0194\n",
      "Epoch [15/40], Step [7300/16026], Loss: 0.0348\n",
      "Epoch [15/40], Step [7400/16026], Loss: 0.0232\n",
      "Epoch [15/40], Step [7500/16026], Loss: 0.0218\n",
      "Epoch [15/40], Step [7600/16026], Loss: 0.0197\n",
      "Epoch [15/40], Step [7700/16026], Loss: 0.0288\n",
      "Epoch [15/40], Step [7800/16026], Loss: 0.0166\n",
      "Epoch [15/40], Step [7900/16026], Loss: 0.0318\n",
      "Epoch [15/40], Step [8000/16026], Loss: 0.0234\n",
      "Epoch [15/40], Step [8100/16026], Loss: 0.0251\n",
      "Epoch [15/40], Step [8200/16026], Loss: 0.0318\n",
      "Epoch [15/40], Step [8300/16026], Loss: 0.0201\n",
      "Epoch [15/40], Step [8400/16026], Loss: 0.0276\n",
      "Epoch [15/40], Step [8500/16026], Loss: 0.0225\n",
      "Epoch [15/40], Step [8600/16026], Loss: 0.0160\n",
      "Epoch [15/40], Step [8700/16026], Loss: 0.0227\n",
      "Epoch [15/40], Step [8800/16026], Loss: 0.0180\n",
      "Epoch [15/40], Step [8900/16026], Loss: 0.0262\n",
      "Epoch [15/40], Step [9000/16026], Loss: 0.0180\n",
      "Epoch [15/40], Step [9100/16026], Loss: 0.0173\n",
      "Epoch [15/40], Step [9200/16026], Loss: 0.0252\n",
      "Epoch [15/40], Step [9300/16026], Loss: 0.0226\n",
      "Epoch [15/40], Step [9400/16026], Loss: 0.0250\n",
      "Epoch [15/40], Step [9500/16026], Loss: 0.0171\n",
      "Epoch [15/40], Step [9600/16026], Loss: 0.0191\n",
      "Epoch [15/40], Step [9700/16026], Loss: 0.0175\n",
      "Epoch [15/40], Step [9800/16026], Loss: 0.0170\n",
      "Epoch [15/40], Step [9900/16026], Loss: 0.0246\n",
      "Epoch [15/40], Step [10000/16026], Loss: 0.0178\n",
      "Epoch [15/40], Step [10100/16026], Loss: 0.0222\n",
      "Epoch [15/40], Step [10200/16026], Loss: 0.0247\n",
      "Epoch [15/40], Step [10300/16026], Loss: 0.0410\n",
      "Epoch [15/40], Step [10400/16026], Loss: 0.0332\n",
      "Epoch [15/40], Step [10500/16026], Loss: 0.0213\n",
      "Epoch [15/40], Step [10600/16026], Loss: 0.0231\n",
      "Epoch [15/40], Step [10700/16026], Loss: 0.0237\n",
      "Epoch [15/40], Step [10800/16026], Loss: 0.0287\n",
      "Epoch [15/40], Step [10900/16026], Loss: 0.0313\n",
      "Epoch [15/40], Step [11000/16026], Loss: 0.0111\n",
      "Epoch [15/40], Step [11100/16026], Loss: 0.0264\n",
      "Epoch [15/40], Step [11200/16026], Loss: 0.0448\n",
      "Epoch [15/40], Step [11300/16026], Loss: 0.0173\n",
      "Epoch [15/40], Step [11400/16026], Loss: 0.0208\n",
      "Epoch [15/40], Step [11500/16026], Loss: 0.0224\n",
      "Epoch [15/40], Step [11600/16026], Loss: 0.0154\n",
      "Epoch [15/40], Step [11700/16026], Loss: 0.0164\n",
      "Epoch [15/40], Step [11800/16026], Loss: 0.0310\n",
      "Epoch [15/40], Step [11900/16026], Loss: 0.0161\n",
      "Epoch [15/40], Step [12000/16026], Loss: 0.0155\n",
      "Epoch [15/40], Step [12100/16026], Loss: 0.0148\n",
      "Epoch [15/40], Step [12200/16026], Loss: 0.0142\n",
      "Epoch [15/40], Step [12300/16026], Loss: 0.0163\n",
      "Epoch [15/40], Step [12400/16026], Loss: 0.0187\n",
      "Epoch [15/40], Step [12500/16026], Loss: 0.0244\n",
      "Epoch [15/40], Step [12600/16026], Loss: 0.0193\n",
      "Epoch [15/40], Step [12700/16026], Loss: 0.0285\n",
      "Epoch [15/40], Step [12800/16026], Loss: 0.0262\n",
      "Epoch [15/40], Step [12900/16026], Loss: 0.0702\n",
      "Epoch [15/40], Step [13000/16026], Loss: 0.0206\n",
      "Epoch [15/40], Step [13100/16026], Loss: 0.0250\n",
      "Epoch [15/40], Step [13200/16026], Loss: 0.0245\n",
      "Epoch [15/40], Step [13300/16026], Loss: 0.0211\n",
      "Epoch [15/40], Step [13400/16026], Loss: 0.0337\n",
      "Epoch [15/40], Step [13500/16026], Loss: 0.0153\n",
      "Epoch [15/40], Step [13600/16026], Loss: 0.0507\n",
      "Epoch [15/40], Step [13700/16026], Loss: 0.0178\n",
      "Epoch [15/40], Step [13800/16026], Loss: 0.0255\n",
      "Epoch [15/40], Step [13900/16026], Loss: 0.0291\n",
      "Epoch [15/40], Step [14000/16026], Loss: 0.0253\n",
      "Epoch [15/40], Step [14100/16026], Loss: 0.0133\n",
      "Epoch [15/40], Step [14200/16026], Loss: 0.0216\n",
      "Epoch [15/40], Step [14300/16026], Loss: 0.0183\n",
      "Epoch [15/40], Step [14400/16026], Loss: 0.0182\n",
      "Epoch [15/40], Step [14500/16026], Loss: 0.0241\n",
      "Epoch [15/40], Step [14600/16026], Loss: 0.0198\n",
      "Epoch [15/40], Step [14700/16026], Loss: 0.0144\n",
      "Epoch [15/40], Step [14800/16026], Loss: 0.0429\n",
      "Epoch [15/40], Step [14900/16026], Loss: 0.0160\n",
      "Epoch [15/40], Step [15000/16026], Loss: 0.0235\n",
      "Epoch [15/40], Step [15100/16026], Loss: 0.0161\n",
      "Epoch [15/40], Step [15200/16026], Loss: 0.0324\n",
      "Epoch [15/40], Step [15300/16026], Loss: 0.0235\n",
      "Epoch [15/40], Step [15400/16026], Loss: 0.0205\n",
      "Epoch [15/40], Step [15500/16026], Loss: 0.0203\n",
      "Epoch [15/40], Step [15600/16026], Loss: 0.0109\n",
      "Epoch [15/40], Step [15700/16026], Loss: 0.0165\n",
      "Epoch [15/40], Step [15800/16026], Loss: 0.0251\n",
      "Epoch [15/40], Step [15900/16026], Loss: 0.0361\n",
      "Epoch [15/40], Step [16000/16026], Loss: 0.0325\n",
      "Epoch [16/40], Step [100/16026], Loss: 0.0161\n",
      "Epoch [16/40], Step [200/16026], Loss: 0.0174\n",
      "Epoch [16/40], Step [300/16026], Loss: 0.0214\n",
      "Epoch [16/40], Step [400/16026], Loss: 0.0234\n",
      "Epoch [16/40], Step [500/16026], Loss: 0.0211\n",
      "Epoch [16/40], Step [600/16026], Loss: 0.0143\n",
      "Epoch [16/40], Step [700/16026], Loss: 0.0168\n",
      "Epoch [16/40], Step [800/16026], Loss: 0.0191\n",
      "Epoch [16/40], Step [900/16026], Loss: 0.0259\n",
      "Epoch [16/40], Step [1000/16026], Loss: 0.0186\n",
      "Epoch [16/40], Step [1100/16026], Loss: 0.0240\n",
      "Epoch [16/40], Step [1200/16026], Loss: 0.0210\n",
      "Epoch [16/40], Step [1300/16026], Loss: 0.0313\n",
      "Epoch [16/40], Step [1400/16026], Loss: 0.0167\n",
      "Epoch [16/40], Step [1500/16026], Loss: 0.0236\n",
      "Epoch [16/40], Step [1600/16026], Loss: 0.0278\n",
      "Epoch [16/40], Step [1700/16026], Loss: 0.0236\n",
      "Epoch [16/40], Step [1800/16026], Loss: 0.0174\n",
      "Epoch [16/40], Step [1900/16026], Loss: 0.0429\n",
      "Epoch [16/40], Step [2000/16026], Loss: 0.0390\n",
      "Epoch [16/40], Step [2100/16026], Loss: 0.0265\n",
      "Epoch [16/40], Step [2200/16026], Loss: 0.0590\n",
      "Epoch [16/40], Step [2300/16026], Loss: 0.0298\n",
      "Epoch [16/40], Step [2400/16026], Loss: 0.0285\n",
      "Epoch [16/40], Step [2500/16026], Loss: 0.0153\n",
      "Epoch [16/40], Step [2600/16026], Loss: 0.0182\n",
      "Epoch [16/40], Step [2700/16026], Loss: 0.0178\n",
      "Epoch [16/40], Step [2800/16026], Loss: 0.0203\n",
      "Epoch [16/40], Step [2900/16026], Loss: 0.0318\n",
      "Epoch [16/40], Step [3000/16026], Loss: 0.0217\n",
      "Epoch [16/40], Step [3100/16026], Loss: 0.0140\n",
      "Epoch [16/40], Step [3200/16026], Loss: 0.0215\n",
      "Epoch [16/40], Step [3300/16026], Loss: 0.0300\n",
      "Epoch [16/40], Step [3400/16026], Loss: 0.0249\n",
      "Epoch [16/40], Step [3500/16026], Loss: 0.0250\n",
      "Epoch [16/40], Step [3600/16026], Loss: 0.0350\n",
      "Epoch [16/40], Step [3700/16026], Loss: 0.0319\n",
      "Epoch [16/40], Step [3800/16026], Loss: 0.0168\n",
      "Epoch [16/40], Step [3900/16026], Loss: 0.0295\n",
      "Epoch [16/40], Step [4000/16026], Loss: 0.0225\n",
      "Epoch [16/40], Step [4100/16026], Loss: 0.0212\n",
      "Epoch [16/40], Step [4200/16026], Loss: 0.0141\n",
      "Epoch [16/40], Step [4300/16026], Loss: 0.0219\n",
      "Epoch [16/40], Step [4400/16026], Loss: 0.0346\n",
      "Epoch [16/40], Step [4500/16026], Loss: 0.0185\n",
      "Epoch [16/40], Step [4600/16026], Loss: 0.0231\n",
      "Epoch [16/40], Step [4700/16026], Loss: 0.0524\n",
      "Epoch [16/40], Step [4800/16026], Loss: 0.0176\n",
      "Epoch [16/40], Step [4900/16026], Loss: 0.0213\n",
      "Epoch [16/40], Step [5000/16026], Loss: 0.0289\n",
      "Epoch [16/40], Step [5100/16026], Loss: 0.0227\n",
      "Epoch [16/40], Step [5200/16026], Loss: 0.0184\n",
      "Epoch [16/40], Step [5300/16026], Loss: 0.0280\n",
      "Epoch [16/40], Step [5400/16026], Loss: 0.0342\n",
      "Epoch [16/40], Step [5500/16026], Loss: 0.0175\n",
      "Epoch [16/40], Step [5600/16026], Loss: 0.0225\n",
      "Epoch [16/40], Step [5700/16026], Loss: 0.0203\n",
      "Epoch [16/40], Step [5800/16026], Loss: 0.0311\n",
      "Epoch [16/40], Step [5900/16026], Loss: 0.0298\n",
      "Epoch [16/40], Step [6000/16026], Loss: 0.0346\n",
      "Epoch [16/40], Step [6100/16026], Loss: 0.0250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/40], Step [6200/16026], Loss: 0.0123\n",
      "Epoch [16/40], Step [6300/16026], Loss: 0.0262\n",
      "Epoch [16/40], Step [6400/16026], Loss: 0.0255\n",
      "Epoch [16/40], Step [6500/16026], Loss: 0.0119\n",
      "Epoch [16/40], Step [6600/16026], Loss: 0.0220\n",
      "Epoch [16/40], Step [6700/16026], Loss: 0.0239\n",
      "Epoch [16/40], Step [6800/16026], Loss: 0.0247\n",
      "Epoch [16/40], Step [6900/16026], Loss: 0.0167\n",
      "Epoch [16/40], Step [7000/16026], Loss: 0.0166\n",
      "Epoch [16/40], Step [7100/16026], Loss: 0.0239\n",
      "Epoch [16/40], Step [7200/16026], Loss: 0.0216\n",
      "Epoch [16/40], Step [7300/16026], Loss: 0.0192\n",
      "Epoch [16/40], Step [7400/16026], Loss: 0.0093\n",
      "Epoch [16/40], Step [7500/16026], Loss: 0.0186\n",
      "Epoch [16/40], Step [7600/16026], Loss: 0.0193\n",
      "Epoch [16/40], Step [7700/16026], Loss: 0.0228\n",
      "Epoch [16/40], Step [7800/16026], Loss: 0.0135\n",
      "Epoch [16/40], Step [7900/16026], Loss: 0.0275\n",
      "Epoch [16/40], Step [8000/16026], Loss: 0.0277\n",
      "Epoch [16/40], Step [8100/16026], Loss: 0.0266\n",
      "Epoch [16/40], Step [8200/16026], Loss: 0.0144\n",
      "Epoch [16/40], Step [8300/16026], Loss: 0.0269\n",
      "Epoch [16/40], Step [8400/16026], Loss: 0.0250\n",
      "Epoch [16/40], Step [8500/16026], Loss: 0.0244\n",
      "Epoch [16/40], Step [8600/16026], Loss: 0.0156\n",
      "Epoch [16/40], Step [8700/16026], Loss: 0.0152\n",
      "Epoch [16/40], Step [8800/16026], Loss: 0.0220\n",
      "Epoch [16/40], Step [8900/16026], Loss: 0.0155\n",
      "Epoch [16/40], Step [9000/16026], Loss: 0.0227\n",
      "Epoch [16/40], Step [9100/16026], Loss: 0.0253\n",
      "Epoch [16/40], Step [9200/16026], Loss: 0.0168\n",
      "Epoch [16/40], Step [9300/16026], Loss: 0.0203\n",
      "Epoch [16/40], Step [9400/16026], Loss: 0.0263\n",
      "Epoch [16/40], Step [9500/16026], Loss: 0.0234\n",
      "Epoch [16/40], Step [9600/16026], Loss: 0.0218\n",
      "Epoch [16/40], Step [9700/16026], Loss: 0.0338\n",
      "Epoch [16/40], Step [9800/16026], Loss: 0.0200\n",
      "Epoch [16/40], Step [9900/16026], Loss: 0.0246\n",
      "Epoch [16/40], Step [10000/16026], Loss: 0.0260\n",
      "Epoch [16/40], Step [10100/16026], Loss: 0.0330\n",
      "Epoch [16/40], Step [10200/16026], Loss: 0.0137\n",
      "Epoch [16/40], Step [10300/16026], Loss: 0.0344\n",
      "Epoch [16/40], Step [10400/16026], Loss: 0.0172\n",
      "Epoch [16/40], Step [10500/16026], Loss: 0.0130\n",
      "Epoch [16/40], Step [10600/16026], Loss: 0.0174\n",
      "Epoch [16/40], Step [10700/16026], Loss: 0.0171\n",
      "Epoch [16/40], Step [10800/16026], Loss: 0.0142\n",
      "Epoch [16/40], Step [10900/16026], Loss: 0.0215\n",
      "Epoch [16/40], Step [11000/16026], Loss: 0.0221\n",
      "Epoch [16/40], Step [11100/16026], Loss: 0.0156\n",
      "Epoch [16/40], Step [11200/16026], Loss: 0.0103\n",
      "Epoch [16/40], Step [11300/16026], Loss: 0.0247\n",
      "Epoch [16/40], Step [11400/16026], Loss: 0.0207\n",
      "Epoch [16/40], Step [11500/16026], Loss: 0.0188\n",
      "Epoch [16/40], Step [11600/16026], Loss: 0.0140\n",
      "Epoch [16/40], Step [11700/16026], Loss: 0.0252\n",
      "Epoch [16/40], Step [11800/16026], Loss: 0.0221\n",
      "Epoch [16/40], Step [11900/16026], Loss: 0.0291\n",
      "Epoch [16/40], Step [12000/16026], Loss: 0.0245\n",
      "Epoch [16/40], Step [12100/16026], Loss: 0.0182\n",
      "Epoch [16/40], Step [12200/16026], Loss: 0.0237\n",
      "Epoch [16/40], Step [12300/16026], Loss: 0.0252\n",
      "Epoch [16/40], Step [12400/16026], Loss: 0.0160\n",
      "Epoch [16/40], Step [12500/16026], Loss: 0.0284\n",
      "Epoch [16/40], Step [12600/16026], Loss: 0.0217\n",
      "Epoch [16/40], Step [12700/16026], Loss: 0.0226\n",
      "Epoch [16/40], Step [12800/16026], Loss: 0.0275\n",
      "Epoch [16/40], Step [12900/16026], Loss: 0.0238\n",
      "Epoch [16/40], Step [13000/16026], Loss: 0.0281\n",
      "Epoch [16/40], Step [13100/16026], Loss: 0.0261\n",
      "Epoch [16/40], Step [13200/16026], Loss: 0.0268\n",
      "Epoch [16/40], Step [13300/16026], Loss: 0.0121\n",
      "Epoch [16/40], Step [13400/16026], Loss: 0.0245\n",
      "Epoch [16/40], Step [13500/16026], Loss: 0.0228\n",
      "Epoch [16/40], Step [13600/16026], Loss: 0.0266\n",
      "Epoch [16/40], Step [13700/16026], Loss: 0.0227\n",
      "Epoch [16/40], Step [13800/16026], Loss: 0.0148\n",
      "Epoch [16/40], Step [13900/16026], Loss: 0.0157\n",
      "Epoch [16/40], Step [14000/16026], Loss: 0.0230\n",
      "Epoch [16/40], Step [14100/16026], Loss: 0.0175\n",
      "Epoch [16/40], Step [14200/16026], Loss: 0.0201\n",
      "Epoch [16/40], Step [14300/16026], Loss: 0.0288\n",
      "Epoch [16/40], Step [14400/16026], Loss: 0.0240\n",
      "Epoch [16/40], Step [14500/16026], Loss: 0.0164\n",
      "Epoch [16/40], Step [14600/16026], Loss: 0.0296\n",
      "Epoch [16/40], Step [14700/16026], Loss: 0.0155\n",
      "Epoch [16/40], Step [14800/16026], Loss: 0.0185\n",
      "Epoch [16/40], Step [14900/16026], Loss: 0.0293\n",
      "Epoch [16/40], Step [15000/16026], Loss: 0.0235\n",
      "Epoch [16/40], Step [15100/16026], Loss: 0.0182\n",
      "Epoch [16/40], Step [15200/16026], Loss: 0.0276\n",
      "Epoch [16/40], Step [15300/16026], Loss: 0.0137\n",
      "Epoch [16/40], Step [15400/16026], Loss: 0.0255\n",
      "Epoch [16/40], Step [15500/16026], Loss: 0.0236\n",
      "Epoch [16/40], Step [15600/16026], Loss: 0.0552\n",
      "Epoch [16/40], Step [15700/16026], Loss: 0.0229\n",
      "Epoch [16/40], Step [15800/16026], Loss: 0.0260\n",
      "Epoch [16/40], Step [15900/16026], Loss: 0.0222\n",
      "Epoch [16/40], Step [16000/16026], Loss: 0.0240\n",
      "Epoch [17/40], Step [100/16026], Loss: 0.0267\n",
      "Epoch [17/40], Step [200/16026], Loss: 0.0189\n",
      "Epoch [17/40], Step [300/16026], Loss: 0.0212\n",
      "Epoch [17/40], Step [400/16026], Loss: 0.0201\n",
      "Epoch [17/40], Step [500/16026], Loss: 0.0175\n",
      "Epoch [17/40], Step [600/16026], Loss: 0.0205\n",
      "Epoch [17/40], Step [700/16026], Loss: 0.0165\n",
      "Epoch [17/40], Step [800/16026], Loss: 0.0278\n",
      "Epoch [17/40], Step [900/16026], Loss: 0.0198\n",
      "Epoch [17/40], Step [1000/16026], Loss: 0.0246\n",
      "Epoch [17/40], Step [1100/16026], Loss: 0.0240\n",
      "Epoch [17/40], Step [1200/16026], Loss: 0.0223\n",
      "Epoch [17/40], Step [1300/16026], Loss: 0.0157\n",
      "Epoch [17/40], Step [1400/16026], Loss: 0.0179\n",
      "Epoch [17/40], Step [1500/16026], Loss: 0.0254\n",
      "Epoch [17/40], Step [1600/16026], Loss: 0.0249\n",
      "Epoch [17/40], Step [1700/16026], Loss: 0.0288\n",
      "Epoch [17/40], Step [1800/16026], Loss: 0.0206\n",
      "Epoch [17/40], Step [1900/16026], Loss: 0.0213\n",
      "Epoch [17/40], Step [2000/16026], Loss: 0.0152\n",
      "Epoch [17/40], Step [2100/16026], Loss: 0.0138\n",
      "Epoch [17/40], Step [2200/16026], Loss: 0.0240\n",
      "Epoch [17/40], Step [2300/16026], Loss: 0.0161\n",
      "Epoch [17/40], Step [2400/16026], Loss: 0.0235\n",
      "Epoch [17/40], Step [2500/16026], Loss: 0.0238\n",
      "Epoch [17/40], Step [2600/16026], Loss: 0.0123\n",
      "Epoch [17/40], Step [2700/16026], Loss: 0.0275\n",
      "Epoch [17/40], Step [2800/16026], Loss: 0.0231\n",
      "Epoch [17/40], Step [2900/16026], Loss: 0.0278\n",
      "Epoch [17/40], Step [3000/16026], Loss: 0.0309\n",
      "Epoch [17/40], Step [3100/16026], Loss: 0.0262\n",
      "Epoch [17/40], Step [3200/16026], Loss: 0.0197\n",
      "Epoch [17/40], Step [3300/16026], Loss: 0.0180\n",
      "Epoch [17/40], Step [3400/16026], Loss: 0.0183\n",
      "Epoch [17/40], Step [3500/16026], Loss: 0.0281\n",
      "Epoch [17/40], Step [3600/16026], Loss: 0.0301\n",
      "Epoch [17/40], Step [3700/16026], Loss: 0.0241\n",
      "Epoch [17/40], Step [3800/16026], Loss: 0.0233\n",
      "Epoch [17/40], Step [3900/16026], Loss: 0.0270\n",
      "Epoch [17/40], Step [4000/16026], Loss: 0.0180\n",
      "Epoch [17/40], Step [4100/16026], Loss: 0.0156\n",
      "Epoch [17/40], Step [4200/16026], Loss: 0.0150\n",
      "Epoch [17/40], Step [4300/16026], Loss: 0.0234\n",
      "Epoch [17/40], Step [4400/16026], Loss: 0.0191\n",
      "Epoch [17/40], Step [4500/16026], Loss: 0.0258\n",
      "Epoch [17/40], Step [4600/16026], Loss: 0.0184\n",
      "Epoch [17/40], Step [4700/16026], Loss: 0.0199\n",
      "Epoch [17/40], Step [4800/16026], Loss: 0.0229\n",
      "Epoch [17/40], Step [4900/16026], Loss: 0.0276\n",
      "Epoch [17/40], Step [5000/16026], Loss: 0.0376\n",
      "Epoch [17/40], Step [5100/16026], Loss: 0.0205\n",
      "Epoch [17/40], Step [5200/16026], Loss: 0.0233\n",
      "Epoch [17/40], Step [5300/16026], Loss: 0.0293\n",
      "Epoch [17/40], Step [5400/16026], Loss: 0.0175\n",
      "Epoch [17/40], Step [5500/16026], Loss: 0.0189\n",
      "Epoch [17/40], Step [5600/16026], Loss: 0.0193\n",
      "Epoch [17/40], Step [5700/16026], Loss: 0.0189\n",
      "Epoch [17/40], Step [5800/16026], Loss: 0.0277\n",
      "Epoch [17/40], Step [5900/16026], Loss: 0.0178\n",
      "Epoch [17/40], Step [6000/16026], Loss: 0.0201\n",
      "Epoch [17/40], Step [6100/16026], Loss: 0.0186\n",
      "Epoch [17/40], Step [6200/16026], Loss: 0.0286\n",
      "Epoch [17/40], Step [6300/16026], Loss: 0.0196\n",
      "Epoch [17/40], Step [6400/16026], Loss: 0.0246\n",
      "Epoch [17/40], Step [6500/16026], Loss: 0.0259\n",
      "Epoch [17/40], Step [6600/16026], Loss: 0.0170\n",
      "Epoch [17/40], Step [6700/16026], Loss: 0.0167\n",
      "Epoch [17/40], Step [6800/16026], Loss: 0.0176\n",
      "Epoch [17/40], Step [6900/16026], Loss: 0.0326\n",
      "Epoch [17/40], Step [7000/16026], Loss: 0.0260\n",
      "Epoch [17/40], Step [7100/16026], Loss: 0.0250\n",
      "Epoch [17/40], Step [7200/16026], Loss: 0.0233\n",
      "Epoch [17/40], Step [7300/16026], Loss: 0.0249\n",
      "Epoch [17/40], Step [7400/16026], Loss: 0.0178\n",
      "Epoch [17/40], Step [7500/16026], Loss: 0.0317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/40], Step [7600/16026], Loss: 0.0183\n",
      "Epoch [17/40], Step [7700/16026], Loss: 0.0557\n",
      "Epoch [17/40], Step [7800/16026], Loss: 0.0233\n",
      "Epoch [17/40], Step [7900/16026], Loss: 0.0206\n",
      "Epoch [17/40], Step [8000/16026], Loss: 0.0210\n",
      "Epoch [17/40], Step [8100/16026], Loss: 0.0125\n",
      "Epoch [17/40], Step [8200/16026], Loss: 0.0165\n",
      "Epoch [17/40], Step [8300/16026], Loss: 0.0186\n",
      "Epoch [17/40], Step [8400/16026], Loss: 0.0190\n",
      "Epoch [17/40], Step [8500/16026], Loss: 0.0250\n",
      "Epoch [17/40], Step [8600/16026], Loss: 0.0186\n",
      "Epoch [17/40], Step [8700/16026], Loss: 0.0173\n",
      "Epoch [17/40], Step [8800/16026], Loss: 0.0264\n",
      "Epoch [17/40], Step [8900/16026], Loss: 0.0202\n",
      "Epoch [17/40], Step [9000/16026], Loss: 0.0220\n",
      "Epoch [17/40], Step [9100/16026], Loss: 0.0240\n",
      "Epoch [17/40], Step [9200/16026], Loss: 0.0203\n",
      "Epoch [17/40], Step [9300/16026], Loss: 0.0208\n",
      "Epoch [17/40], Step [9400/16026], Loss: 0.0186\n",
      "Epoch [17/40], Step [9500/16026], Loss: 0.0318\n",
      "Epoch [17/40], Step [9600/16026], Loss: 0.0212\n",
      "Epoch [17/40], Step [9700/16026], Loss: 0.0194\n",
      "Epoch [17/40], Step [9800/16026], Loss: 0.0268\n",
      "Epoch [17/40], Step [9900/16026], Loss: 0.0208\n",
      "Epoch [17/40], Step [10000/16026], Loss: 0.0237\n",
      "Epoch [17/40], Step [10100/16026], Loss: 0.0361\n",
      "Epoch [17/40], Step [10200/16026], Loss: 0.0194\n",
      "Epoch [17/40], Step [10300/16026], Loss: 0.0274\n",
      "Epoch [17/40], Step [10400/16026], Loss: 0.0252\n",
      "Epoch [17/40], Step [10500/16026], Loss: 0.0260\n",
      "Epoch [17/40], Step [10600/16026], Loss: 0.0239\n",
      "Epoch [17/40], Step [10700/16026], Loss: 0.0207\n",
      "Epoch [17/40], Step [10800/16026], Loss: 0.0228\n",
      "Epoch [17/40], Step [10900/16026], Loss: 0.0230\n",
      "Epoch [17/40], Step [11000/16026], Loss: 0.0162\n",
      "Epoch [17/40], Step [11100/16026], Loss: 0.0558\n",
      "Epoch [17/40], Step [11200/16026], Loss: 0.0511\n",
      "Epoch [17/40], Step [11300/16026], Loss: 0.0209\n",
      "Epoch [17/40], Step [11400/16026], Loss: 0.0248\n",
      "Epoch [17/40], Step [11500/16026], Loss: 0.0214\n",
      "Epoch [17/40], Step [11600/16026], Loss: 0.0264\n",
      "Epoch [17/40], Step [11700/16026], Loss: 0.0200\n",
      "Epoch [17/40], Step [11800/16026], Loss: 0.0203\n",
      "Epoch [17/40], Step [11900/16026], Loss: 0.0186\n",
      "Epoch [17/40], Step [12000/16026], Loss: 0.0158\n",
      "Epoch [17/40], Step [12100/16026], Loss: 0.0116\n",
      "Epoch [17/40], Step [12200/16026], Loss: 0.0258\n",
      "Epoch [17/40], Step [12300/16026], Loss: 0.0145\n",
      "Epoch [17/40], Step [12400/16026], Loss: 0.0320\n",
      "Epoch [17/40], Step [12500/16026], Loss: 0.0300\n",
      "Epoch [17/40], Step [12600/16026], Loss: 0.0113\n",
      "Epoch [17/40], Step [12700/16026], Loss: 0.0264\n",
      "Epoch [17/40], Step [12800/16026], Loss: 0.0204\n",
      "Epoch [17/40], Step [12900/16026], Loss: 0.0226\n",
      "Epoch [17/40], Step [13000/16026], Loss: 0.0182\n",
      "Epoch [17/40], Step [13100/16026], Loss: 0.0291\n",
      "Epoch [17/40], Step [13200/16026], Loss: 0.0257\n",
      "Epoch [17/40], Step [13300/16026], Loss: 0.0128\n",
      "Epoch [17/40], Step [13400/16026], Loss: 0.0173\n",
      "Epoch [17/40], Step [13500/16026], Loss: 0.0242\n",
      "Epoch [17/40], Step [13600/16026], Loss: 0.0217\n",
      "Epoch [17/40], Step [13700/16026], Loss: 0.0196\n",
      "Epoch [17/40], Step [13800/16026], Loss: 0.0273\n",
      "Epoch [17/40], Step [13900/16026], Loss: 0.0360\n",
      "Epoch [17/40], Step [14000/16026], Loss: 0.0373\n",
      "Epoch [17/40], Step [14100/16026], Loss: 0.0137\n",
      "Epoch [17/40], Step [14200/16026], Loss: 0.0326\n",
      "Epoch [17/40], Step [14300/16026], Loss: 0.0227\n",
      "Epoch [17/40], Step [14400/16026], Loss: 0.0174\n",
      "Epoch [17/40], Step [14500/16026], Loss: 0.0231\n",
      "Epoch [17/40], Step [14600/16026], Loss: 0.0222\n",
      "Epoch [17/40], Step [14700/16026], Loss: 0.0349\n",
      "Epoch [17/40], Step [14800/16026], Loss: 0.0260\n",
      "Epoch [17/40], Step [14900/16026], Loss: 0.0237\n",
      "Epoch [17/40], Step [15000/16026], Loss: 0.0240\n",
      "Epoch [17/40], Step [15100/16026], Loss: 0.0217\n",
      "Epoch [17/40], Step [15200/16026], Loss: 0.0147\n",
      "Epoch [17/40], Step [15300/16026], Loss: 0.0167\n",
      "Epoch [17/40], Step [15400/16026], Loss: 0.0355\n",
      "Epoch [17/40], Step [15500/16026], Loss: 0.0234\n",
      "Epoch [17/40], Step [15600/16026], Loss: 0.0338\n",
      "Epoch [17/40], Step [15700/16026], Loss: 0.0289\n",
      "Epoch [17/40], Step [15800/16026], Loss: 0.0226\n",
      "Epoch [17/40], Step [15900/16026], Loss: 0.0215\n",
      "Epoch [17/40], Step [16000/16026], Loss: 0.0166\n",
      "Epoch [18/40], Step [100/16026], Loss: 0.0220\n",
      "Epoch [18/40], Step [200/16026], Loss: 0.0264\n",
      "Epoch [18/40], Step [300/16026], Loss: 0.0231\n",
      "Epoch [18/40], Step [400/16026], Loss: 0.0257\n",
      "Epoch [18/40], Step [500/16026], Loss: 0.0159\n",
      "Epoch [18/40], Step [600/16026], Loss: 0.0221\n",
      "Epoch [18/40], Step [700/16026], Loss: 0.0169\n",
      "Epoch [18/40], Step [800/16026], Loss: 0.0213\n",
      "Epoch [18/40], Step [900/16026], Loss: 0.0164\n",
      "Epoch [18/40], Step [1000/16026], Loss: 0.0213\n",
      "Epoch [18/40], Step [1100/16026], Loss: 0.0241\n",
      "Epoch [18/40], Step [1200/16026], Loss: 0.0218\n",
      "Epoch [18/40], Step [1300/16026], Loss: 0.0178\n",
      "Epoch [18/40], Step [1400/16026], Loss: 0.0281\n",
      "Epoch [18/40], Step [1500/16026], Loss: 0.0230\n",
      "Epoch [18/40], Step [1600/16026], Loss: 0.0269\n",
      "Epoch [18/40], Step [1700/16026], Loss: 0.0192\n",
      "Epoch [18/40], Step [1800/16026], Loss: 0.0130\n",
      "Epoch [18/40], Step [1900/16026], Loss: 0.0297\n",
      "Epoch [18/40], Step [2000/16026], Loss: 0.0204\n",
      "Epoch [18/40], Step [2100/16026], Loss: 0.0284\n",
      "Epoch [18/40], Step [2200/16026], Loss: 0.0174\n",
      "Epoch [18/40], Step [2300/16026], Loss: 0.0201\n",
      "Epoch [18/40], Step [2400/16026], Loss: 0.0417\n",
      "Epoch [18/40], Step [2500/16026], Loss: 0.0363\n",
      "Epoch [18/40], Step [2600/16026], Loss: 0.0150\n",
      "Epoch [18/40], Step [2700/16026], Loss: 0.0183\n",
      "Epoch [18/40], Step [2800/16026], Loss: 0.0178\n",
      "Epoch [18/40], Step [2900/16026], Loss: 0.0235\n",
      "Epoch [18/40], Step [3000/16026], Loss: 0.0228\n",
      "Epoch [18/40], Step [3100/16026], Loss: 0.0215\n",
      "Epoch [18/40], Step [3200/16026], Loss: 0.0173\n",
      "Epoch [18/40], Step [3300/16026], Loss: 0.0154\n",
      "Epoch [18/40], Step [3400/16026], Loss: 0.0249\n",
      "Epoch [18/40], Step [3500/16026], Loss: 0.0321\n",
      "Epoch [18/40], Step [3600/16026], Loss: 0.0200\n",
      "Epoch [18/40], Step [3700/16026], Loss: 0.0140\n",
      "Epoch [18/40], Step [3800/16026], Loss: 0.0511\n",
      "Epoch [18/40], Step [3900/16026], Loss: 0.0185\n",
      "Epoch [18/40], Step [4000/16026], Loss: 0.0118\n",
      "Epoch [18/40], Step [4100/16026], Loss: 0.0254\n",
      "Epoch [18/40], Step [4200/16026], Loss: 0.0204\n",
      "Epoch [18/40], Step [4300/16026], Loss: 0.0175\n",
      "Epoch [18/40], Step [4400/16026], Loss: 0.0215\n",
      "Epoch [18/40], Step [4500/16026], Loss: 0.0208\n",
      "Epoch [18/40], Step [4600/16026], Loss: 0.0150\n",
      "Epoch [18/40], Step [4700/16026], Loss: 0.0175\n",
      "Epoch [18/40], Step [4800/16026], Loss: 0.0150\n",
      "Epoch [18/40], Step [4900/16026], Loss: 0.0230\n",
      "Epoch [18/40], Step [5000/16026], Loss: 0.0213\n",
      "Epoch [18/40], Step [5100/16026], Loss: 0.0148\n",
      "Epoch [18/40], Step [5200/16026], Loss: 0.0214\n",
      "Epoch [18/40], Step [5300/16026], Loss: 0.0152\n",
      "Epoch [18/40], Step [5400/16026], Loss: 0.0246\n",
      "Epoch [18/40], Step [5500/16026], Loss: 0.0213\n",
      "Epoch [18/40], Step [5600/16026], Loss: 0.0174\n",
      "Epoch [18/40], Step [5700/16026], Loss: 0.0164\n",
      "Epoch [18/40], Step [5800/16026], Loss: 0.0311\n",
      "Epoch [18/40], Step [5900/16026], Loss: 0.0477\n",
      "Epoch [18/40], Step [6000/16026], Loss: 0.0167\n",
      "Epoch [18/40], Step [6100/16026], Loss: 0.0173\n",
      "Epoch [18/40], Step [6200/16026], Loss: 0.0221\n",
      "Epoch [18/40], Step [6300/16026], Loss: 0.0166\n",
      "Epoch [18/40], Step [6400/16026], Loss: 0.0229\n",
      "Epoch [18/40], Step [6500/16026], Loss: 0.0240\n",
      "Epoch [18/40], Step [6600/16026], Loss: 0.0196\n",
      "Epoch [18/40], Step [6700/16026], Loss: 0.0247\n",
      "Epoch [18/40], Step [6800/16026], Loss: 0.0171\n",
      "Epoch [18/40], Step [6900/16026], Loss: 0.0254\n",
      "Epoch [18/40], Step [7000/16026], Loss: 0.0185\n",
      "Epoch [18/40], Step [7100/16026], Loss: 0.0198\n",
      "Epoch [18/40], Step [7200/16026], Loss: 0.0233\n",
      "Epoch [18/40], Step [7300/16026], Loss: 0.0341\n",
      "Epoch [18/40], Step [7400/16026], Loss: 0.0208\n",
      "Epoch [18/40], Step [7500/16026], Loss: 0.0216\n",
      "Epoch [18/40], Step [7600/16026], Loss: 0.0173\n",
      "Epoch [18/40], Step [7700/16026], Loss: 0.0166\n",
      "Epoch [18/40], Step [7800/16026], Loss: 0.0227\n",
      "Epoch [18/40], Step [7900/16026], Loss: 0.0151\n",
      "Epoch [18/40], Step [8000/16026], Loss: 0.0395\n",
      "Epoch [18/40], Step [8100/16026], Loss: 0.0228\n",
      "Epoch [18/40], Step [8200/16026], Loss: 0.0182\n",
      "Epoch [18/40], Step [8300/16026], Loss: 0.0270\n",
      "Epoch [18/40], Step [8400/16026], Loss: 0.0327\n",
      "Epoch [18/40], Step [8500/16026], Loss: 0.0176\n",
      "Epoch [18/40], Step [8600/16026], Loss: 0.0186\n",
      "Epoch [18/40], Step [8700/16026], Loss: 0.0224\n",
      "Epoch [18/40], Step [8800/16026], Loss: 0.0213\n",
      "Epoch [18/40], Step [8900/16026], Loss: 0.0260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/40], Step [9000/16026], Loss: 0.0204\n",
      "Epoch [18/40], Step [9100/16026], Loss: 0.0409\n",
      "Epoch [18/40], Step [9200/16026], Loss: 0.0278\n",
      "Epoch [18/40], Step [9300/16026], Loss: 0.0165\n",
      "Epoch [18/40], Step [9400/16026], Loss: 0.0119\n",
      "Epoch [18/40], Step [9500/16026], Loss: 0.0133\n",
      "Epoch [18/40], Step [9600/16026], Loss: 0.0294\n",
      "Epoch [18/40], Step [9700/16026], Loss: 0.0231\n",
      "Epoch [18/40], Step [9800/16026], Loss: 0.0344\n",
      "Epoch [18/40], Step [9900/16026], Loss: 0.0284\n",
      "Epoch [18/40], Step [10000/16026], Loss: 0.0266\n",
      "Epoch [18/40], Step [10100/16026], Loss: 0.0211\n",
      "Epoch [18/40], Step [10200/16026], Loss: 0.0133\n",
      "Epoch [18/40], Step [10300/16026], Loss: 0.0154\n",
      "Epoch [18/40], Step [10400/16026], Loss: 0.0273\n",
      "Epoch [18/40], Step [10500/16026], Loss: 0.0173\n",
      "Epoch [18/40], Step [10600/16026], Loss: 0.0192\n",
      "Epoch [18/40], Step [10700/16026], Loss: 0.0219\n",
      "Epoch [18/40], Step [10800/16026], Loss: 0.0227\n",
      "Epoch [18/40], Step [10900/16026], Loss: 0.0245\n",
      "Epoch [18/40], Step [11000/16026], Loss: 0.0152\n",
      "Epoch [18/40], Step [11100/16026], Loss: 0.0177\n",
      "Epoch [18/40], Step [11200/16026], Loss: 0.0204\n",
      "Epoch [18/40], Step [11300/16026], Loss: 0.0245\n",
      "Epoch [18/40], Step [11400/16026], Loss: 0.0201\n",
      "Epoch [18/40], Step [11500/16026], Loss: 0.0349\n",
      "Epoch [18/40], Step [11600/16026], Loss: 0.0203\n",
      "Epoch [18/40], Step [11700/16026], Loss: 0.0372\n",
      "Epoch [18/40], Step [11800/16026], Loss: 0.0216\n",
      "Epoch [18/40], Step [11900/16026], Loss: 0.0137\n",
      "Epoch [18/40], Step [12000/16026], Loss: 0.0269\n",
      "Epoch [18/40], Step [12100/16026], Loss: 0.0180\n",
      "Epoch [18/40], Step [12200/16026], Loss: 0.0273\n",
      "Epoch [18/40], Step [12300/16026], Loss: 0.0311\n",
      "Epoch [18/40], Step [12400/16026], Loss: 0.0238\n",
      "Epoch [18/40], Step [12500/16026], Loss: 0.0237\n",
      "Epoch [18/40], Step [12600/16026], Loss: 0.0144\n",
      "Epoch [18/40], Step [12700/16026], Loss: 0.0229\n",
      "Epoch [18/40], Step [12800/16026], Loss: 0.0227\n",
      "Epoch [18/40], Step [12900/16026], Loss: 0.0264\n",
      "Epoch [18/40], Step [13000/16026], Loss: 0.0206\n",
      "Epoch [18/40], Step [13100/16026], Loss: 0.0265\n",
      "Epoch [18/40], Step [13200/16026], Loss: 0.0127\n",
      "Epoch [18/40], Step [13300/16026], Loss: 0.0253\n",
      "Epoch [18/40], Step [13400/16026], Loss: 0.0223\n",
      "Epoch [18/40], Step [13500/16026], Loss: 0.0237\n",
      "Epoch [18/40], Step [13600/16026], Loss: 0.0186\n",
      "Epoch [18/40], Step [13700/16026], Loss: 0.0223\n",
      "Epoch [18/40], Step [13800/16026], Loss: 0.0397\n",
      "Epoch [18/40], Step [13900/16026], Loss: 0.0202\n",
      "Epoch [18/40], Step [14000/16026], Loss: 0.0219\n",
      "Epoch [18/40], Step [14100/16026], Loss: 0.0220\n",
      "Epoch [18/40], Step [14200/16026], Loss: 0.0223\n",
      "Epoch [18/40], Step [14300/16026], Loss: 0.0213\n",
      "Epoch [18/40], Step [14400/16026], Loss: 0.0121\n",
      "Epoch [18/40], Step [14500/16026], Loss: 0.0155\n",
      "Epoch [18/40], Step [14600/16026], Loss: 0.0140\n",
      "Epoch [18/40], Step [14700/16026], Loss: 0.0222\n",
      "Epoch [18/40], Step [14800/16026], Loss: 0.0214\n",
      "Epoch [18/40], Step [14900/16026], Loss: 0.0162\n",
      "Epoch [18/40], Step [15000/16026], Loss: 0.0226\n",
      "Epoch [18/40], Step [15100/16026], Loss: 0.0231\n",
      "Epoch [18/40], Step [15200/16026], Loss: 0.0246\n",
      "Epoch [18/40], Step [15300/16026], Loss: 0.0225\n",
      "Epoch [18/40], Step [15400/16026], Loss: 0.0125\n",
      "Epoch [18/40], Step [15500/16026], Loss: 0.0284\n",
      "Epoch [18/40], Step [15600/16026], Loss: 0.0187\n",
      "Epoch [18/40], Step [15700/16026], Loss: 0.0133\n",
      "Epoch [18/40], Step [15800/16026], Loss: 0.0243\n",
      "Epoch [18/40], Step [15900/16026], Loss: 0.0181\n",
      "Epoch [18/40], Step [16000/16026], Loss: 0.0225\n",
      "Epoch [19/40], Step [100/16026], Loss: 0.0231\n",
      "Epoch [19/40], Step [200/16026], Loss: 0.0165\n",
      "Epoch [19/40], Step [300/16026], Loss: 0.0159\n",
      "Epoch [19/40], Step [400/16026], Loss: 0.0181\n",
      "Epoch [19/40], Step [500/16026], Loss: 0.0171\n",
      "Epoch [19/40], Step [600/16026], Loss: 0.0276\n",
      "Epoch [19/40], Step [700/16026], Loss: 0.0166\n",
      "Epoch [19/40], Step [800/16026], Loss: 0.0373\n",
      "Epoch [19/40], Step [900/16026], Loss: 0.0278\n",
      "Epoch [19/40], Step [1000/16026], Loss: 0.0289\n",
      "Epoch [19/40], Step [1100/16026], Loss: 0.0153\n",
      "Epoch [19/40], Step [1200/16026], Loss: 0.0233\n",
      "Epoch [19/40], Step [1300/16026], Loss: 0.0184\n",
      "Epoch [19/40], Step [1400/16026], Loss: 0.0216\n",
      "Epoch [19/40], Step [1500/16026], Loss: 0.0140\n",
      "Epoch [19/40], Step [1600/16026], Loss: 0.0160\n",
      "Epoch [19/40], Step [1700/16026], Loss: 0.0156\n",
      "Epoch [19/40], Step [1800/16026], Loss: 0.0260\n",
      "Epoch [19/40], Step [1900/16026], Loss: 0.0191\n",
      "Epoch [19/40], Step [2000/16026], Loss: 0.0164\n",
      "Epoch [19/40], Step [2100/16026], Loss: 0.0195\n",
      "Epoch [19/40], Step [2200/16026], Loss: 0.0146\n",
      "Epoch [19/40], Step [2300/16026], Loss: 0.0308\n",
      "Epoch [19/40], Step [2400/16026], Loss: 0.0144\n",
      "Epoch [19/40], Step [2500/16026], Loss: 0.0179\n",
      "Epoch [19/40], Step [2600/16026], Loss: 0.0268\n",
      "Epoch [19/40], Step [2700/16026], Loss: 0.0212\n",
      "Epoch [19/40], Step [2800/16026], Loss: 0.0254\n",
      "Epoch [19/40], Step [2900/16026], Loss: 0.0113\n",
      "Epoch [19/40], Step [3000/16026], Loss: 0.0184\n",
      "Epoch [19/40], Step [3100/16026], Loss: 0.0334\n",
      "Epoch [19/40], Step [3200/16026], Loss: 0.0185\n",
      "Epoch [19/40], Step [3300/16026], Loss: 0.0254\n",
      "Epoch [19/40], Step [3400/16026], Loss: 0.0282\n",
      "Epoch [19/40], Step [3500/16026], Loss: 0.0176\n",
      "Epoch [19/40], Step [3600/16026], Loss: 0.0232\n",
      "Epoch [19/40], Step [3700/16026], Loss: 0.0178\n",
      "Epoch [19/40], Step [3800/16026], Loss: 0.0264\n",
      "Epoch [19/40], Step [3900/16026], Loss: 0.0148\n",
      "Epoch [19/40], Step [4000/16026], Loss: 0.0273\n",
      "Epoch [19/40], Step [4100/16026], Loss: 0.0149\n",
      "Epoch [19/40], Step [4200/16026], Loss: 0.0257\n",
      "Epoch [19/40], Step [4300/16026], Loss: 0.0184\n",
      "Epoch [19/40], Step [4400/16026], Loss: 0.0176\n",
      "Epoch [19/40], Step [4500/16026], Loss: 0.0235\n",
      "Epoch [19/40], Step [4600/16026], Loss: 0.0163\n",
      "Epoch [19/40], Step [4700/16026], Loss: 0.0238\n",
      "Epoch [19/40], Step [4800/16026], Loss: 0.0152\n",
      "Epoch [19/40], Step [4900/16026], Loss: 0.0282\n",
      "Epoch [19/40], Step [5000/16026], Loss: 0.0328\n",
      "Epoch [19/40], Step [5100/16026], Loss: 0.0300\n",
      "Epoch [19/40], Step [5200/16026], Loss: 0.0203\n",
      "Epoch [19/40], Step [5300/16026], Loss: 0.0259\n",
      "Epoch [19/40], Step [5400/16026], Loss: 0.0253\n",
      "Epoch [19/40], Step [5500/16026], Loss: 0.0195\n",
      "Epoch [19/40], Step [5600/16026], Loss: 0.0177\n",
      "Epoch [19/40], Step [5700/16026], Loss: 0.0166\n",
      "Epoch [19/40], Step [5800/16026], Loss: 0.0165\n",
      "Epoch [19/40], Step [5900/16026], Loss: 0.0208\n",
      "Epoch [19/40], Step [6000/16026], Loss: 0.0183\n",
      "Epoch [19/40], Step [6100/16026], Loss: 0.0256\n",
      "Epoch [19/40], Step [6200/16026], Loss: 0.0205\n",
      "Epoch [19/40], Step [6300/16026], Loss: 0.0169\n",
      "Epoch [19/40], Step [6400/16026], Loss: 0.0258\n",
      "Epoch [19/40], Step [6500/16026], Loss: 0.0247\n",
      "Epoch [19/40], Step [6600/16026], Loss: 0.0186\n",
      "Epoch [19/40], Step [6700/16026], Loss: 0.0226\n",
      "Epoch [19/40], Step [6800/16026], Loss: 0.0244\n",
      "Epoch [19/40], Step [6900/16026], Loss: 0.0167\n",
      "Epoch [19/40], Step [7000/16026], Loss: 0.0193\n",
      "Epoch [19/40], Step [7100/16026], Loss: 0.0305\n",
      "Epoch [19/40], Step [7200/16026], Loss: 0.0182\n",
      "Epoch [19/40], Step [7300/16026], Loss: 0.0336\n",
      "Epoch [19/40], Step [7400/16026], Loss: 0.0117\n",
      "Epoch [19/40], Step [7500/16026], Loss: 0.0138\n",
      "Epoch [19/40], Step [7600/16026], Loss: 0.0178\n",
      "Epoch [19/40], Step [7700/16026], Loss: 0.0286\n",
      "Epoch [19/40], Step [7800/16026], Loss: 0.0307\n",
      "Epoch [19/40], Step [7900/16026], Loss: 0.0225\n",
      "Epoch [19/40], Step [8000/16026], Loss: 0.0297\n",
      "Epoch [19/40], Step [8100/16026], Loss: 0.0205\n",
      "Epoch [19/40], Step [8200/16026], Loss: 0.0205\n",
      "Epoch [19/40], Step [8300/16026], Loss: 0.0221\n",
      "Epoch [19/40], Step [8400/16026], Loss: 0.0262\n",
      "Epoch [19/40], Step [8500/16026], Loss: 0.0225\n",
      "Epoch [19/40], Step [8600/16026], Loss: 0.0219\n",
      "Epoch [19/40], Step [8700/16026], Loss: 0.0274\n",
      "Epoch [19/40], Step [8800/16026], Loss: 0.0230\n",
      "Epoch [19/40], Step [8900/16026], Loss: 0.0180\n",
      "Epoch [19/40], Step [9000/16026], Loss: 0.0226\n",
      "Epoch [19/40], Step [9100/16026], Loss: 0.0270\n",
      "Epoch [19/40], Step [9200/16026], Loss: 0.0260\n",
      "Epoch [19/40], Step [9300/16026], Loss: 0.0282\n",
      "Epoch [19/40], Step [9400/16026], Loss: 0.0266\n",
      "Epoch [19/40], Step [9500/16026], Loss: 0.0485\n",
      "Epoch [19/40], Step [9600/16026], Loss: 0.0284\n",
      "Epoch [19/40], Step [9700/16026], Loss: 0.0090\n",
      "Epoch [19/40], Step [9800/16026], Loss: 0.0167\n",
      "Epoch [19/40], Step [9900/16026], Loss: 0.0139\n",
      "Epoch [19/40], Step [10000/16026], Loss: 0.0240\n",
      "Epoch [19/40], Step [10100/16026], Loss: 0.0308\n",
      "Epoch [19/40], Step [10200/16026], Loss: 0.0137\n",
      "Epoch [19/40], Step [10300/16026], Loss: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/40], Step [10400/16026], Loss: 0.0248\n",
      "Epoch [19/40], Step [10500/16026], Loss: 0.0184\n",
      "Epoch [19/40], Step [10600/16026], Loss: 0.0151\n",
      "Epoch [19/40], Step [10700/16026], Loss: 0.0192\n",
      "Epoch [19/40], Step [10800/16026], Loss: 0.0241\n",
      "Epoch [19/40], Step [10900/16026], Loss: 0.0251\n",
      "Epoch [19/40], Step [11000/16026], Loss: 0.0234\n",
      "Epoch [19/40], Step [11100/16026], Loss: 0.0192\n",
      "Epoch [19/40], Step [11200/16026], Loss: 0.0167\n",
      "Epoch [19/40], Step [11300/16026], Loss: 0.0197\n",
      "Epoch [19/40], Step [11400/16026], Loss: 0.0341\n",
      "Epoch [19/40], Step [11500/16026], Loss: 0.0266\n",
      "Epoch [19/40], Step [11600/16026], Loss: 0.0204\n",
      "Epoch [19/40], Step [11700/16026], Loss: 0.0134\n",
      "Epoch [19/40], Step [11800/16026], Loss: 0.0123\n",
      "Epoch [19/40], Step [11900/16026], Loss: 0.0296\n",
      "Epoch [19/40], Step [12000/16026], Loss: 0.0269\n",
      "Epoch [19/40], Step [12100/16026], Loss: 0.0198\n",
      "Epoch [19/40], Step [12200/16026], Loss: 0.0231\n",
      "Epoch [19/40], Step [12300/16026], Loss: 0.0160\n",
      "Epoch [19/40], Step [12400/16026], Loss: 0.0211\n",
      "Epoch [19/40], Step [12500/16026], Loss: 0.0288\n",
      "Epoch [19/40], Step [12600/16026], Loss: 0.0212\n",
      "Epoch [19/40], Step [12700/16026], Loss: 0.0160\n",
      "Epoch [19/40], Step [12800/16026], Loss: 0.0273\n",
      "Epoch [19/40], Step [12900/16026], Loss: 0.0217\n",
      "Epoch [19/40], Step [13000/16026], Loss: 0.0351\n",
      "Epoch [19/40], Step [13100/16026], Loss: 0.0128\n",
      "Epoch [19/40], Step [13200/16026], Loss: 0.0174\n",
      "Epoch [19/40], Step [13300/16026], Loss: 0.0151\n",
      "Epoch [19/40], Step [13400/16026], Loss: 0.0191\n",
      "Epoch [19/40], Step [13500/16026], Loss: 0.0178\n",
      "Epoch [19/40], Step [13600/16026], Loss: 0.0135\n",
      "Epoch [19/40], Step [13700/16026], Loss: 0.0243\n",
      "Epoch [19/40], Step [13800/16026], Loss: 0.0187\n",
      "Epoch [19/40], Step [13900/16026], Loss: 0.0208\n",
      "Epoch [19/40], Step [14000/16026], Loss: 0.0229\n",
      "Epoch [19/40], Step [14100/16026], Loss: 0.0162\n",
      "Epoch [19/40], Step [14200/16026], Loss: 0.0152\n",
      "Epoch [19/40], Step [14300/16026], Loss: 0.0201\n",
      "Epoch [19/40], Step [14400/16026], Loss: 0.0234\n",
      "Epoch [19/40], Step [14500/16026], Loss: 0.0122\n",
      "Epoch [19/40], Step [14600/16026], Loss: 0.0253\n",
      "Epoch [19/40], Step [14700/16026], Loss: 0.0161\n",
      "Epoch [19/40], Step [14800/16026], Loss: 0.0205\n",
      "Epoch [19/40], Step [14900/16026], Loss: 0.0245\n",
      "Epoch [19/40], Step [15000/16026], Loss: 0.0276\n",
      "Epoch [19/40], Step [15100/16026], Loss: 0.0256\n",
      "Epoch [19/40], Step [15200/16026], Loss: 0.0144\n",
      "Epoch [19/40], Step [15300/16026], Loss: 0.0144\n",
      "Epoch [19/40], Step [15400/16026], Loss: 0.0216\n",
      "Epoch [19/40], Step [15500/16026], Loss: 0.0134\n",
      "Epoch [19/40], Step [15600/16026], Loss: 0.0271\n",
      "Epoch [19/40], Step [15700/16026], Loss: 0.0213\n",
      "Epoch [19/40], Step [15800/16026], Loss: 0.0158\n",
      "Epoch [19/40], Step [15900/16026], Loss: 0.0295\n",
      "Epoch [19/40], Step [16000/16026], Loss: 0.0254\n",
      "Epoch [20/40], Step [100/16026], Loss: 0.0207\n",
      "Epoch [20/40], Step [200/16026], Loss: 0.0191\n",
      "Epoch [20/40], Step [300/16026], Loss: 0.0266\n",
      "Epoch [20/40], Step [400/16026], Loss: 0.0176\n",
      "Epoch [20/40], Step [500/16026], Loss: 0.0220\n",
      "Epoch [20/40], Step [600/16026], Loss: 0.0161\n",
      "Epoch [20/40], Step [700/16026], Loss: 0.0195\n",
      "Epoch [20/40], Step [800/16026], Loss: 0.0274\n",
      "Epoch [20/40], Step [900/16026], Loss: 0.0214\n",
      "Epoch [20/40], Step [1000/16026], Loss: 0.0157\n",
      "Epoch [20/40], Step [1100/16026], Loss: 0.0299\n",
      "Epoch [20/40], Step [1200/16026], Loss: 0.0129\n",
      "Epoch [20/40], Step [1300/16026], Loss: 0.0149\n",
      "Epoch [20/40], Step [1400/16026], Loss: 0.0196\n",
      "Epoch [20/40], Step [1500/16026], Loss: 0.0225\n",
      "Epoch [20/40], Step [1600/16026], Loss: 0.0200\n",
      "Epoch [20/40], Step [1700/16026], Loss: 0.0208\n",
      "Epoch [20/40], Step [1800/16026], Loss: 0.0184\n",
      "Epoch [20/40], Step [1900/16026], Loss: 0.0147\n",
      "Epoch [20/40], Step [2000/16026], Loss: 0.0176\n",
      "Epoch [20/40], Step [2100/16026], Loss: 0.0209\n",
      "Epoch [20/40], Step [2200/16026], Loss: 0.0209\n",
      "Epoch [20/40], Step [2300/16026], Loss: 0.0245\n",
      "Epoch [20/40], Step [2400/16026], Loss: 0.0186\n",
      "Epoch [20/40], Step [2500/16026], Loss: 0.0182\n",
      "Epoch [20/40], Step [2600/16026], Loss: 0.0293\n",
      "Epoch [20/40], Step [2700/16026], Loss: 0.0269\n",
      "Epoch [20/40], Step [2800/16026], Loss: 0.0212\n",
      "Epoch [20/40], Step [2900/16026], Loss: 0.0263\n",
      "Epoch [20/40], Step [3000/16026], Loss: 0.0292\n",
      "Epoch [20/40], Step [3100/16026], Loss: 0.0199\n",
      "Epoch [20/40], Step [3200/16026], Loss: 0.0239\n",
      "Epoch [20/40], Step [3300/16026], Loss: 0.0210\n",
      "Epoch [20/40], Step [3400/16026], Loss: 0.0239\n",
      "Epoch [20/40], Step [3500/16026], Loss: 0.0186\n",
      "Epoch [20/40], Step [3600/16026], Loss: 0.0166\n",
      "Epoch [20/40], Step [3700/16026], Loss: 0.0150\n",
      "Epoch [20/40], Step [3800/16026], Loss: 0.0146\n",
      "Epoch [20/40], Step [3900/16026], Loss: 0.0314\n",
      "Epoch [20/40], Step [4000/16026], Loss: 0.0208\n",
      "Epoch [20/40], Step [4100/16026], Loss: 0.0212\n",
      "Epoch [20/40], Step [4200/16026], Loss: 0.0152\n",
      "Epoch [20/40], Step [4300/16026], Loss: 0.0256\n",
      "Epoch [20/40], Step [4400/16026], Loss: 0.0139\n",
      "Epoch [20/40], Step [4500/16026], Loss: 0.0122\n",
      "Epoch [20/40], Step [4600/16026], Loss: 0.0297\n",
      "Epoch [20/40], Step [4700/16026], Loss: 0.0260\n",
      "Epoch [20/40], Step [4800/16026], Loss: 0.0264\n",
      "Epoch [20/40], Step [4900/16026], Loss: 0.0152\n",
      "Epoch [20/40], Step [5000/16026], Loss: 0.0170\n",
      "Epoch [20/40], Step [5100/16026], Loss: 0.0153\n",
      "Epoch [20/40], Step [5200/16026], Loss: 0.0285\n",
      "Epoch [20/40], Step [5300/16026], Loss: 0.0182\n",
      "Epoch [20/40], Step [5400/16026], Loss: 0.0160\n",
      "Epoch [20/40], Step [5500/16026], Loss: 0.0132\n",
      "Epoch [20/40], Step [5600/16026], Loss: 0.0167\n",
      "Epoch [20/40], Step [5700/16026], Loss: 0.0318\n",
      "Epoch [20/40], Step [5800/16026], Loss: 0.0208\n",
      "Epoch [20/40], Step [5900/16026], Loss: 0.0153\n",
      "Epoch [20/40], Step [6000/16026], Loss: 0.0300\n",
      "Epoch [20/40], Step [6100/16026], Loss: 0.0189\n",
      "Epoch [20/40], Step [6200/16026], Loss: 0.0211\n",
      "Epoch [20/40], Step [6300/16026], Loss: 0.0540\n",
      "Epoch [20/40], Step [6400/16026], Loss: 0.0225\n",
      "Epoch [20/40], Step [6500/16026], Loss: 0.0146\n",
      "Epoch [20/40], Step [6600/16026], Loss: 0.0277\n",
      "Epoch [20/40], Step [6700/16026], Loss: 0.0208\n",
      "Epoch [20/40], Step [6800/16026], Loss: 0.0265\n",
      "Epoch [20/40], Step [6900/16026], Loss: 0.0147\n",
      "Epoch [20/40], Step [7000/16026], Loss: 0.0173\n",
      "Epoch [20/40], Step [7100/16026], Loss: 0.0157\n",
      "Epoch [20/40], Step [7200/16026], Loss: 0.0232\n",
      "Epoch [20/40], Step [7300/16026], Loss: 0.0261\n",
      "Epoch [20/40], Step [7400/16026], Loss: 0.0235\n",
      "Epoch [20/40], Step [7500/16026], Loss: 0.0201\n",
      "Epoch [20/40], Step [7600/16026], Loss: 0.0198\n",
      "Epoch [20/40], Step [7700/16026], Loss: 0.0165\n",
      "Epoch [20/40], Step [7800/16026], Loss: 0.0228\n",
      "Epoch [20/40], Step [7900/16026], Loss: 0.0256\n",
      "Epoch [20/40], Step [8000/16026], Loss: 0.0226\n",
      "Epoch [20/40], Step [8100/16026], Loss: 0.0271\n",
      "Epoch [20/40], Step [8200/16026], Loss: 0.0131\n",
      "Epoch [20/40], Step [8300/16026], Loss: 0.0267\n",
      "Epoch [20/40], Step [8400/16026], Loss: 0.0213\n",
      "Epoch [20/40], Step [8500/16026], Loss: 0.0156\n",
      "Epoch [20/40], Step [8600/16026], Loss: 0.0148\n",
      "Epoch [20/40], Step [8700/16026], Loss: 0.0124\n",
      "Epoch [20/40], Step [8800/16026], Loss: 0.0217\n",
      "Epoch [20/40], Step [8900/16026], Loss: 0.0209\n",
      "Epoch [20/40], Step [9000/16026], Loss: 0.0157\n",
      "Epoch [20/40], Step [9100/16026], Loss: 0.0143\n",
      "Epoch [20/40], Step [9200/16026], Loss: 0.0365\n",
      "Epoch [20/40], Step [9300/16026], Loss: 0.0246\n",
      "Epoch [20/40], Step [9400/16026], Loss: 0.0206\n",
      "Epoch [20/40], Step [9500/16026], Loss: 0.0198\n",
      "Epoch [20/40], Step [9600/16026], Loss: 0.0234\n",
      "Epoch [20/40], Step [9700/16026], Loss: 0.0214\n",
      "Epoch [20/40], Step [9800/16026], Loss: 0.0168\n",
      "Epoch [20/40], Step [9900/16026], Loss: 0.0236\n",
      "Epoch [20/40], Step [10000/16026], Loss: 0.0193\n",
      "Epoch [20/40], Step [10100/16026], Loss: 0.0197\n",
      "Epoch [20/40], Step [10200/16026], Loss: 0.0156\n",
      "Epoch [20/40], Step [10300/16026], Loss: 0.0240\n",
      "Epoch [20/40], Step [10400/16026], Loss: 0.0149\n",
      "Epoch [20/40], Step [10500/16026], Loss: 0.0348\n",
      "Epoch [20/40], Step [10600/16026], Loss: 0.0145\n",
      "Epoch [20/40], Step [10700/16026], Loss: 0.0214\n",
      "Epoch [20/40], Step [10800/16026], Loss: 0.0241\n",
      "Epoch [20/40], Step [10900/16026], Loss: 0.0171\n",
      "Epoch [20/40], Step [11000/16026], Loss: 0.0218\n",
      "Epoch [20/40], Step [11100/16026], Loss: 0.0125\n",
      "Epoch [20/40], Step [11200/16026], Loss: 0.0236\n",
      "Epoch [20/40], Step [11300/16026], Loss: 0.0159\n",
      "Epoch [20/40], Step [11400/16026], Loss: 0.0198\n",
      "Epoch [20/40], Step [11500/16026], Loss: 0.0195\n",
      "Epoch [20/40], Step [11600/16026], Loss: 0.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40], Step [11700/16026], Loss: 0.0146\n",
      "Epoch [20/40], Step [11800/16026], Loss: 0.0214\n",
      "Epoch [20/40], Step [11900/16026], Loss: 0.0234\n",
      "Epoch [20/40], Step [12000/16026], Loss: 0.0255\n",
      "Epoch [20/40], Step [12100/16026], Loss: 0.0245\n",
      "Epoch [20/40], Step [12200/16026], Loss: 0.0313\n",
      "Epoch [20/40], Step [12300/16026], Loss: 0.0309\n",
      "Epoch [20/40], Step [12400/16026], Loss: 0.0289\n",
      "Epoch [20/40], Step [12500/16026], Loss: 0.0198\n",
      "Epoch [20/40], Step [12600/16026], Loss: 0.0126\n",
      "Epoch [20/40], Step [12700/16026], Loss: 0.0252\n",
      "Epoch [20/40], Step [12800/16026], Loss: 0.0149\n",
      "Epoch [20/40], Step [12900/16026], Loss: 0.0170\n",
      "Epoch [20/40], Step [13000/16026], Loss: 0.0142\n",
      "Epoch [20/40], Step [13100/16026], Loss: 0.0243\n",
      "Epoch [20/40], Step [13200/16026], Loss: 0.0200\n",
      "Epoch [20/40], Step [13300/16026], Loss: 0.0213\n",
      "Epoch [20/40], Step [13400/16026], Loss: 0.0322\n",
      "Epoch [20/40], Step [13500/16026], Loss: 0.0224\n",
      "Epoch [20/40], Step [13600/16026], Loss: 0.0253\n",
      "Epoch [20/40], Step [13700/16026], Loss: 0.0307\n",
      "Epoch [20/40], Step [13800/16026], Loss: 0.0130\n",
      "Epoch [20/40], Step [13900/16026], Loss: 0.0334\n",
      "Epoch [20/40], Step [14000/16026], Loss: 0.0206\n",
      "Epoch [20/40], Step [14100/16026], Loss: 0.0284\n",
      "Epoch [20/40], Step [14200/16026], Loss: 0.0187\n",
      "Epoch [20/40], Step [14300/16026], Loss: 0.0269\n",
      "Epoch [20/40], Step [14400/16026], Loss: 0.0300\n",
      "Epoch [20/40], Step [14500/16026], Loss: 0.0289\n",
      "Epoch [20/40], Step [14600/16026], Loss: 0.0259\n",
      "Epoch [20/40], Step [14700/16026], Loss: 0.0138\n",
      "Epoch [20/40], Step [14800/16026], Loss: 0.0212\n",
      "Epoch [20/40], Step [14900/16026], Loss: 0.0139\n",
      "Epoch [20/40], Step [15000/16026], Loss: 0.0237\n",
      "Epoch [20/40], Step [15100/16026], Loss: 0.0136\n",
      "Epoch [20/40], Step [15200/16026], Loss: 0.0194\n",
      "Epoch [20/40], Step [15300/16026], Loss: 0.0260\n",
      "Epoch [20/40], Step [15400/16026], Loss: 0.0197\n",
      "Epoch [20/40], Step [15500/16026], Loss: 0.0190\n",
      "Epoch [20/40], Step [15600/16026], Loss: 0.0210\n",
      "Epoch [20/40], Step [15700/16026], Loss: 0.0147\n",
      "Epoch [20/40], Step [15800/16026], Loss: 0.0236\n",
      "Epoch [20/40], Step [15900/16026], Loss: 0.0224\n",
      "Epoch [20/40], Step [16000/16026], Loss: 0.0140\n",
      "Epoch [21/40], Step [100/16026], Loss: 0.0240\n",
      "Epoch [21/40], Step [200/16026], Loss: 0.0196\n",
      "Epoch [21/40], Step [300/16026], Loss: 0.0303\n",
      "Epoch [21/40], Step [400/16026], Loss: 0.0299\n",
      "Epoch [21/40], Step [500/16026], Loss: 0.0185\n",
      "Epoch [21/40], Step [600/16026], Loss: 0.0272\n",
      "Epoch [21/40], Step [700/16026], Loss: 0.0292\n",
      "Epoch [21/40], Step [800/16026], Loss: 0.0126\n",
      "Epoch [21/40], Step [900/16026], Loss: 0.0162\n",
      "Epoch [21/40], Step [1000/16026], Loss: 0.0189\n",
      "Epoch [21/40], Step [1100/16026], Loss: 0.0216\n",
      "Epoch [21/40], Step [1200/16026], Loss: 0.0316\n",
      "Epoch [21/40], Step [1300/16026], Loss: 0.0188\n",
      "Epoch [21/40], Step [1400/16026], Loss: 0.0193\n",
      "Epoch [21/40], Step [1500/16026], Loss: 0.0180\n",
      "Epoch [21/40], Step [1600/16026], Loss: 0.0227\n",
      "Epoch [21/40], Step [1700/16026], Loss: 0.0252\n",
      "Epoch [21/40], Step [1800/16026], Loss: 0.0121\n",
      "Epoch [21/40], Step [1900/16026], Loss: 0.0254\n",
      "Epoch [21/40], Step [2000/16026], Loss: 0.0147\n",
      "Epoch [21/40], Step [2100/16026], Loss: 0.0253\n",
      "Epoch [21/40], Step [2200/16026], Loss: 0.0225\n",
      "Epoch [21/40], Step [2300/16026], Loss: 0.0339\n",
      "Epoch [21/40], Step [2400/16026], Loss: 0.0251\n",
      "Epoch [21/40], Step [2500/16026], Loss: 0.0124\n",
      "Epoch [21/40], Step [2600/16026], Loss: 0.0282\n",
      "Epoch [21/40], Step [2700/16026], Loss: 0.0181\n",
      "Epoch [21/40], Step [2800/16026], Loss: 0.0195\n",
      "Epoch [21/40], Step [2900/16026], Loss: 0.0191\n",
      "Epoch [21/40], Step [3000/16026], Loss: 0.0149\n",
      "Epoch [21/40], Step [3100/16026], Loss: 0.0281\n",
      "Epoch [21/40], Step [3200/16026], Loss: 0.0137\n",
      "Epoch [21/40], Step [3300/16026], Loss: 0.0116\n",
      "Epoch [21/40], Step [3400/16026], Loss: 0.0191\n",
      "Epoch [21/40], Step [3500/16026], Loss: 0.0157\n",
      "Epoch [21/40], Step [3600/16026], Loss: 0.0143\n",
      "Epoch [21/40], Step [3700/16026], Loss: 0.0287\n",
      "Epoch [21/40], Step [3800/16026], Loss: 0.0180\n",
      "Epoch [21/40], Step [3900/16026], Loss: 0.0330\n",
      "Epoch [21/40], Step [4000/16026], Loss: 0.0187\n",
      "Epoch [21/40], Step [4100/16026], Loss: 0.0314\n",
      "Epoch [21/40], Step [4200/16026], Loss: 0.0249\n",
      "Epoch [21/40], Step [4300/16026], Loss: 0.0226\n",
      "Epoch [21/40], Step [4400/16026], Loss: 0.0172\n",
      "Epoch [21/40], Step [4500/16026], Loss: 0.0211\n",
      "Epoch [21/40], Step [4600/16026], Loss: 0.0173\n",
      "Epoch [21/40], Step [4700/16026], Loss: 0.0170\n",
      "Epoch [21/40], Step [4800/16026], Loss: 0.0201\n",
      "Epoch [21/40], Step [4900/16026], Loss: 0.0212\n",
      "Epoch [21/40], Step [5000/16026], Loss: 0.0226\n",
      "Epoch [21/40], Step [5100/16026], Loss: 0.0253\n",
      "Epoch [21/40], Step [5200/16026], Loss: 0.0279\n",
      "Epoch [21/40], Step [5300/16026], Loss: 0.0199\n",
      "Epoch [21/40], Step [5400/16026], Loss: 0.0137\n",
      "Epoch [21/40], Step [5500/16026], Loss: 0.0347\n",
      "Epoch [21/40], Step [5600/16026], Loss: 0.0232\n",
      "Epoch [21/40], Step [5700/16026], Loss: 0.0220\n",
      "Epoch [21/40], Step [5800/16026], Loss: 0.0229\n",
      "Epoch [21/40], Step [5900/16026], Loss: 0.0180\n",
      "Epoch [21/40], Step [6000/16026], Loss: 0.0119\n",
      "Epoch [21/40], Step [6100/16026], Loss: 0.0202\n",
      "Epoch [21/40], Step [6200/16026], Loss: 0.0252\n",
      "Epoch [21/40], Step [6300/16026], Loss: 0.0309\n",
      "Epoch [21/40], Step [6400/16026], Loss: 0.0214\n",
      "Epoch [21/40], Step [6500/16026], Loss: 0.0275\n",
      "Epoch [21/40], Step [6600/16026], Loss: 0.0160\n",
      "Epoch [21/40], Step [6700/16026], Loss: 0.0149\n",
      "Epoch [21/40], Step [6800/16026], Loss: 0.0204\n",
      "Epoch [21/40], Step [6900/16026], Loss: 0.0227\n",
      "Epoch [21/40], Step [7000/16026], Loss: 0.0194\n",
      "Epoch [21/40], Step [7100/16026], Loss: 0.0144\n",
      "Epoch [21/40], Step [7200/16026], Loss: 0.0234\n",
      "Epoch [21/40], Step [7300/16026], Loss: 0.0198\n",
      "Epoch [21/40], Step [7400/16026], Loss: 0.0236\n",
      "Epoch [21/40], Step [7500/16026], Loss: 0.0232\n",
      "Epoch [21/40], Step [7600/16026], Loss: 0.0321\n",
      "Epoch [21/40], Step [7700/16026], Loss: 0.0372\n",
      "Epoch [21/40], Step [7800/16026], Loss: 0.0349\n",
      "Epoch [21/40], Step [7900/16026], Loss: 0.0285\n",
      "Epoch [21/40], Step [8000/16026], Loss: 0.0197\n",
      "Epoch [21/40], Step [8100/16026], Loss: 0.0169\n",
      "Epoch [21/40], Step [8200/16026], Loss: 0.0202\n",
      "Epoch [21/40], Step [8300/16026], Loss: 0.0154\n",
      "Epoch [21/40], Step [8400/16026], Loss: 0.0202\n",
      "Epoch [21/40], Step [8500/16026], Loss: 0.0261\n",
      "Epoch [21/40], Step [8600/16026], Loss: 0.0329\n",
      "Epoch [21/40], Step [8700/16026], Loss: 0.0156\n",
      "Epoch [21/40], Step [8800/16026], Loss: 0.0213\n",
      "Epoch [21/40], Step [8900/16026], Loss: 0.0244\n",
      "Epoch [21/40], Step [9000/16026], Loss: 0.0195\n",
      "Epoch [21/40], Step [9100/16026], Loss: 0.0859\n",
      "Epoch [21/40], Step [9200/16026], Loss: 0.0123\n",
      "Epoch [21/40], Step [9300/16026], Loss: 0.0265\n",
      "Epoch [21/40], Step [9400/16026], Loss: 0.0286\n",
      "Epoch [21/40], Step [9500/16026], Loss: 0.0370\n",
      "Epoch [21/40], Step [9600/16026], Loss: 0.0201\n",
      "Epoch [21/40], Step [9700/16026], Loss: 0.0168\n",
      "Epoch [21/40], Step [9800/16026], Loss: 0.0208\n",
      "Epoch [21/40], Step [9900/16026], Loss: 0.0231\n",
      "Epoch [21/40], Step [10000/16026], Loss: 0.0348\n",
      "Epoch [21/40], Step [10100/16026], Loss: 0.0201\n",
      "Epoch [21/40], Step [10200/16026], Loss: 0.0151\n",
      "Epoch [21/40], Step [10300/16026], Loss: 0.0336\n",
      "Epoch [21/40], Step [10400/16026], Loss: 0.0221\n",
      "Epoch [21/40], Step [10500/16026], Loss: 0.0213\n",
      "Epoch [21/40], Step [10600/16026], Loss: 0.0182\n",
      "Epoch [21/40], Step [10700/16026], Loss: 0.0296\n",
      "Epoch [21/40], Step [10800/16026], Loss: 0.0170\n",
      "Epoch [21/40], Step [10900/16026], Loss: 0.0138\n",
      "Epoch [21/40], Step [11000/16026], Loss: 0.0250\n",
      "Epoch [21/40], Step [11100/16026], Loss: 0.0229\n",
      "Epoch [21/40], Step [11200/16026], Loss: 0.0248\n",
      "Epoch [21/40], Step [11300/16026], Loss: 0.0146\n",
      "Epoch [21/40], Step [11400/16026], Loss: 0.0182\n",
      "Epoch [21/40], Step [11500/16026], Loss: 0.0179\n",
      "Epoch [21/40], Step [11600/16026], Loss: 0.0248\n",
      "Epoch [21/40], Step [11700/16026], Loss: 0.0239\n",
      "Epoch [21/40], Step [11800/16026], Loss: 0.0193\n",
      "Epoch [21/40], Step [11900/16026], Loss: 0.0169\n",
      "Epoch [21/40], Step [12000/16026], Loss: 0.0269\n",
      "Epoch [21/40], Step [12100/16026], Loss: 0.0266\n",
      "Epoch [21/40], Step [12200/16026], Loss: 0.0221\n",
      "Epoch [21/40], Step [12300/16026], Loss: 0.0273\n",
      "Epoch [21/40], Step [12400/16026], Loss: 0.0181\n",
      "Epoch [21/40], Step [12500/16026], Loss: 0.0340\n",
      "Epoch [21/40], Step [12600/16026], Loss: 0.0189\n",
      "Epoch [21/40], Step [12700/16026], Loss: 0.0161\n",
      "Epoch [21/40], Step [12800/16026], Loss: 0.0242\n",
      "Epoch [21/40], Step [12900/16026], Loss: 0.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/40], Step [13000/16026], Loss: 0.0180\n",
      "Epoch [21/40], Step [13100/16026], Loss: 0.0221\n",
      "Epoch [21/40], Step [13200/16026], Loss: 0.0298\n",
      "Epoch [21/40], Step [13300/16026], Loss: 0.0224\n",
      "Epoch [21/40], Step [13400/16026], Loss: 0.0315\n",
      "Epoch [21/40], Step [13500/16026], Loss: 0.0226\n",
      "Epoch [21/40], Step [13600/16026], Loss: 0.0183\n",
      "Epoch [21/40], Step [13700/16026], Loss: 0.0166\n",
      "Epoch [21/40], Step [13800/16026], Loss: 0.0145\n",
      "Epoch [21/40], Step [13900/16026], Loss: 0.0184\n",
      "Epoch [21/40], Step [14000/16026], Loss: 0.0178\n",
      "Epoch [21/40], Step [14100/16026], Loss: 0.0179\n",
      "Epoch [21/40], Step [14200/16026], Loss: 0.0187\n",
      "Epoch [21/40], Step [14300/16026], Loss: 0.0143\n",
      "Epoch [21/40], Step [14400/16026], Loss: 0.0345\n",
      "Epoch [21/40], Step [14500/16026], Loss: 0.0166\n",
      "Epoch [21/40], Step [14600/16026], Loss: 0.0162\n",
      "Epoch [21/40], Step [14700/16026], Loss: 0.0254\n",
      "Epoch [21/40], Step [14800/16026], Loss: 0.0220\n",
      "Epoch [21/40], Step [14900/16026], Loss: 0.0121\n",
      "Epoch [21/40], Step [15000/16026], Loss: 0.0237\n",
      "Epoch [21/40], Step [15100/16026], Loss: 0.0232\n",
      "Epoch [21/40], Step [15200/16026], Loss: 0.0270\n",
      "Epoch [21/40], Step [15300/16026], Loss: 0.0199\n",
      "Epoch [21/40], Step [15400/16026], Loss: 0.0286\n",
      "Epoch [21/40], Step [15500/16026], Loss: 0.0132\n",
      "Epoch [21/40], Step [15600/16026], Loss: 0.0276\n",
      "Epoch [21/40], Step [15700/16026], Loss: 0.0175\n",
      "Epoch [21/40], Step [15800/16026], Loss: 0.0561\n",
      "Epoch [21/40], Step [15900/16026], Loss: 0.0199\n",
      "Epoch [21/40], Step [16000/16026], Loss: 0.0177\n",
      "Epoch [22/40], Step [100/16026], Loss: 0.0202\n",
      "Epoch [22/40], Step [200/16026], Loss: 0.0193\n",
      "Epoch [22/40], Step [300/16026], Loss: 0.0195\n",
      "Epoch [22/40], Step [400/16026], Loss: 0.0218\n",
      "Epoch [22/40], Step [500/16026], Loss: 0.0258\n",
      "Epoch [22/40], Step [600/16026], Loss: 0.0158\n",
      "Epoch [22/40], Step [700/16026], Loss: 0.0224\n",
      "Epoch [22/40], Step [800/16026], Loss: 0.0227\n",
      "Epoch [22/40], Step [900/16026], Loss: 0.0191\n",
      "Epoch [22/40], Step [1000/16026], Loss: 0.0298\n",
      "Epoch [22/40], Step [1100/16026], Loss: 0.0263\n",
      "Epoch [22/40], Step [1200/16026], Loss: 0.0147\n",
      "Epoch [22/40], Step [1300/16026], Loss: 0.0203\n",
      "Epoch [22/40], Step [1400/16026], Loss: 0.0353\n",
      "Epoch [22/40], Step [1500/16026], Loss: 0.0314\n",
      "Epoch [22/40], Step [1600/16026], Loss: 0.0186\n",
      "Epoch [22/40], Step [1700/16026], Loss: 0.0171\n",
      "Epoch [22/40], Step [1800/16026], Loss: 0.0213\n",
      "Epoch [22/40], Step [1900/16026], Loss: 0.0211\n",
      "Epoch [22/40], Step [2000/16026], Loss: 0.0226\n",
      "Epoch [22/40], Step [2100/16026], Loss: 0.0185\n",
      "Epoch [22/40], Step [2200/16026], Loss: 0.0180\n",
      "Epoch [22/40], Step [2300/16026], Loss: 0.0272\n",
      "Epoch [22/40], Step [2400/16026], Loss: 0.0137\n",
      "Epoch [22/40], Step [2500/16026], Loss: 0.0153\n",
      "Epoch [22/40], Step [2600/16026], Loss: 0.0116\n",
      "Epoch [22/40], Step [2700/16026], Loss: 0.0175\n",
      "Epoch [22/40], Step [2800/16026], Loss: 0.0233\n",
      "Epoch [22/40], Step [2900/16026], Loss: 0.0188\n",
      "Epoch [22/40], Step [3000/16026], Loss: 0.0214\n",
      "Epoch [22/40], Step [3100/16026], Loss: 0.0170\n",
      "Epoch [22/40], Step [3200/16026], Loss: 0.0183\n",
      "Epoch [22/40], Step [3300/16026], Loss: 0.0133\n",
      "Epoch [22/40], Step [3400/16026], Loss: 0.0268\n",
      "Epoch [22/40], Step [3500/16026], Loss: 0.0150\n",
      "Epoch [22/40], Step [3600/16026], Loss: 0.0156\n",
      "Epoch [22/40], Step [3700/16026], Loss: 0.0252\n",
      "Epoch [22/40], Step [3800/16026], Loss: 0.0188\n",
      "Epoch [22/40], Step [3900/16026], Loss: 0.0271\n",
      "Epoch [22/40], Step [4000/16026], Loss: 0.0225\n",
      "Epoch [22/40], Step [4100/16026], Loss: 0.0173\n",
      "Epoch [22/40], Step [4200/16026], Loss: 0.0357\n",
      "Epoch [22/40], Step [4300/16026], Loss: 0.0282\n",
      "Epoch [22/40], Step [4400/16026], Loss: 0.0172\n",
      "Epoch [22/40], Step [4500/16026], Loss: 0.0132\n",
      "Epoch [22/40], Step [4600/16026], Loss: 0.0248\n",
      "Epoch [22/40], Step [4700/16026], Loss: 0.0114\n",
      "Epoch [22/40], Step [4800/16026], Loss: 0.0305\n",
      "Epoch [22/40], Step [4900/16026], Loss: 0.0237\n",
      "Epoch [22/40], Step [5000/16026], Loss: 0.0206\n",
      "Epoch [22/40], Step [5100/16026], Loss: 0.0312\n",
      "Epoch [22/40], Step [5200/16026], Loss: 0.0206\n",
      "Epoch [22/40], Step [5300/16026], Loss: 0.0200\n",
      "Epoch [22/40], Step [5400/16026], Loss: 0.0192\n",
      "Epoch [22/40], Step [5500/16026], Loss: 0.0237\n",
      "Epoch [22/40], Step [5600/16026], Loss: 0.0190\n",
      "Epoch [22/40], Step [5700/16026], Loss: 0.0151\n",
      "Epoch [22/40], Step [5800/16026], Loss: 0.0311\n",
      "Epoch [22/40], Step [5900/16026], Loss: 0.0265\n",
      "Epoch [22/40], Step [6000/16026], Loss: 0.0243\n",
      "Epoch [22/40], Step [6100/16026], Loss: 0.0330\n",
      "Epoch [22/40], Step [6200/16026], Loss: 0.0274\n",
      "Epoch [22/40], Step [6300/16026], Loss: 0.0224\n",
      "Epoch [22/40], Step [6400/16026], Loss: 0.0103\n",
      "Epoch [22/40], Step [6500/16026], Loss: 0.0265\n",
      "Epoch [22/40], Step [6600/16026], Loss: 0.0147\n",
      "Epoch [22/40], Step [6700/16026], Loss: 0.0295\n",
      "Epoch [22/40], Step [6800/16026], Loss: 0.0148\n",
      "Epoch [22/40], Step [6900/16026], Loss: 0.0260\n",
      "Epoch [22/40], Step [7000/16026], Loss: 0.0219\n",
      "Epoch [22/40], Step [7100/16026], Loss: 0.0172\n",
      "Epoch [22/40], Step [7200/16026], Loss: 0.0139\n",
      "Epoch [22/40], Step [7300/16026], Loss: 0.0214\n",
      "Epoch [22/40], Step [7400/16026], Loss: 0.0162\n",
      "Epoch [22/40], Step [7500/16026], Loss: 0.0169\n",
      "Epoch [22/40], Step [7600/16026], Loss: 0.0171\n",
      "Epoch [22/40], Step [7700/16026], Loss: 0.0289\n",
      "Epoch [22/40], Step [7800/16026], Loss: 0.0199\n",
      "Epoch [22/40], Step [7900/16026], Loss: 0.0236\n",
      "Epoch [22/40], Step [8000/16026], Loss: 0.0289\n",
      "Epoch [22/40], Step [8100/16026], Loss: 0.0234\n",
      "Epoch [22/40], Step [8200/16026], Loss: 0.0225\n",
      "Epoch [22/40], Step [8300/16026], Loss: 0.0166\n",
      "Epoch [22/40], Step [8400/16026], Loss: 0.0240\n",
      "Epoch [22/40], Step [8500/16026], Loss: 0.0258\n",
      "Epoch [22/40], Step [8600/16026], Loss: 0.0192\n",
      "Epoch [22/40], Step [8700/16026], Loss: 0.0260\n",
      "Epoch [22/40], Step [8800/16026], Loss: 0.0292\n",
      "Epoch [22/40], Step [8900/16026], Loss: 0.0327\n",
      "Epoch [22/40], Step [9000/16026], Loss: 0.0241\n",
      "Epoch [22/40], Step [9100/16026], Loss: 0.0153\n",
      "Epoch [22/40], Step [9200/16026], Loss: 0.0130\n",
      "Epoch [22/40], Step [9300/16026], Loss: 0.0188\n",
      "Epoch [22/40], Step [9400/16026], Loss: 0.0229\n",
      "Epoch [22/40], Step [9500/16026], Loss: 0.0181\n",
      "Epoch [22/40], Step [9600/16026], Loss: 0.0179\n",
      "Epoch [22/40], Step [9700/16026], Loss: 0.0254\n",
      "Epoch [22/40], Step [9800/16026], Loss: 0.0172\n",
      "Epoch [22/40], Step [9900/16026], Loss: 0.0169\n",
      "Epoch [22/40], Step [10000/16026], Loss: 0.0219\n",
      "Epoch [22/40], Step [10100/16026], Loss: 0.0249\n",
      "Epoch [22/40], Step [10200/16026], Loss: 0.0118\n",
      "Epoch [22/40], Step [10300/16026], Loss: 0.0121\n",
      "Epoch [22/40], Step [10400/16026], Loss: 0.0191\n",
      "Epoch [22/40], Step [10500/16026], Loss: 0.0297\n",
      "Epoch [22/40], Step [10600/16026], Loss: 0.0198\n",
      "Epoch [22/40], Step [10700/16026], Loss: 0.0339\n",
      "Epoch [22/40], Step [10800/16026], Loss: 0.0193\n",
      "Epoch [22/40], Step [10900/16026], Loss: 0.0176\n",
      "Epoch [22/40], Step [11000/16026], Loss: 0.0139\n",
      "Epoch [22/40], Step [11100/16026], Loss: 0.0266\n",
      "Epoch [22/40], Step [11200/16026], Loss: 0.0178\n",
      "Epoch [22/40], Step [11300/16026], Loss: 0.0278\n",
      "Epoch [22/40], Step [11400/16026], Loss: 0.0145\n",
      "Epoch [22/40], Step [11500/16026], Loss: 0.0213\n",
      "Epoch [22/40], Step [11600/16026], Loss: 0.0237\n",
      "Epoch [22/40], Step [11700/16026], Loss: 0.0752\n",
      "Epoch [22/40], Step [11800/16026], Loss: 0.0213\n",
      "Epoch [22/40], Step [11900/16026], Loss: 0.0234\n",
      "Epoch [22/40], Step [12000/16026], Loss: 0.0287\n",
      "Epoch [22/40], Step [12100/16026], Loss: 0.0235\n",
      "Epoch [22/40], Step [12200/16026], Loss: 0.0153\n",
      "Epoch [22/40], Step [12300/16026], Loss: 0.0227\n",
      "Epoch [22/40], Step [12400/16026], Loss: 0.0289\n",
      "Epoch [22/40], Step [12500/16026], Loss: 0.0247\n",
      "Epoch [22/40], Step [12600/16026], Loss: 0.0156\n",
      "Epoch [22/40], Step [12700/16026], Loss: 0.0356\n",
      "Epoch [22/40], Step [12800/16026], Loss: 0.0243\n",
      "Epoch [22/40], Step [12900/16026], Loss: 0.0368\n",
      "Epoch [22/40], Step [13000/16026], Loss: 0.0152\n",
      "Epoch [22/40], Step [13100/16026], Loss: 0.0138\n",
      "Epoch [22/40], Step [13200/16026], Loss: 0.0200\n",
      "Epoch [22/40], Step [13300/16026], Loss: 0.0172\n",
      "Epoch [22/40], Step [13400/16026], Loss: 0.0164\n",
      "Epoch [22/40], Step [13500/16026], Loss: 0.0370\n",
      "Epoch [22/40], Step [13600/16026], Loss: 0.0200\n",
      "Epoch [22/40], Step [13700/16026], Loss: 0.0165\n",
      "Epoch [22/40], Step [13800/16026], Loss: 0.0151\n",
      "Epoch [22/40], Step [13900/16026], Loss: 0.0190\n",
      "Epoch [22/40], Step [14000/16026], Loss: 0.0296\n",
      "Epoch [22/40], Step [14100/16026], Loss: 0.0355\n",
      "Epoch [22/40], Step [14200/16026], Loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/40], Step [14300/16026], Loss: 0.0220\n",
      "Epoch [22/40], Step [14400/16026], Loss: 0.0227\n",
      "Epoch [22/40], Step [14500/16026], Loss: 0.0276\n",
      "Epoch [22/40], Step [14600/16026], Loss: 0.0286\n",
      "Epoch [22/40], Step [14700/16026], Loss: 0.0284\n",
      "Epoch [22/40], Step [14800/16026], Loss: 0.0217\n",
      "Epoch [22/40], Step [14900/16026], Loss: 0.0306\n",
      "Epoch [22/40], Step [15000/16026], Loss: 0.0177\n",
      "Epoch [22/40], Step [15100/16026], Loss: 0.0168\n",
      "Epoch [22/40], Step [15200/16026], Loss: 0.0280\n",
      "Epoch [22/40], Step [15300/16026], Loss: 0.0182\n",
      "Epoch [22/40], Step [15400/16026], Loss: 0.0158\n",
      "Epoch [22/40], Step [15500/16026], Loss: 0.0189\n",
      "Epoch [22/40], Step [15600/16026], Loss: 0.0262\n",
      "Epoch [22/40], Step [15700/16026], Loss: 0.0231\n",
      "Epoch [22/40], Step [15800/16026], Loss: 0.0231\n",
      "Epoch [22/40], Step [15900/16026], Loss: 0.0185\n",
      "Epoch [22/40], Step [16000/16026], Loss: 0.0194\n",
      "Epoch [23/40], Step [100/16026], Loss: 0.0221\n",
      "Epoch [23/40], Step [200/16026], Loss: 0.0174\n",
      "Epoch [23/40], Step [300/16026], Loss: 0.0161\n",
      "Epoch [23/40], Step [400/16026], Loss: 0.0168\n",
      "Epoch [23/40], Step [500/16026], Loss: 0.0192\n",
      "Epoch [23/40], Step [600/16026], Loss: 0.0226\n",
      "Epoch [23/40], Step [700/16026], Loss: 0.0153\n",
      "Epoch [23/40], Step [800/16026], Loss: 0.0189\n",
      "Epoch [23/40], Step [900/16026], Loss: 0.0242\n",
      "Epoch [23/40], Step [1000/16026], Loss: 0.0125\n",
      "Epoch [23/40], Step [1100/16026], Loss: 0.0252\n",
      "Epoch [23/40], Step [1200/16026], Loss: 0.0135\n",
      "Epoch [23/40], Step [1300/16026], Loss: 0.0223\n",
      "Epoch [23/40], Step [1400/16026], Loss: 0.0145\n",
      "Epoch [23/40], Step [1500/16026], Loss: 0.0164\n",
      "Epoch [23/40], Step [1600/16026], Loss: 0.0253\n",
      "Epoch [23/40], Step [1700/16026], Loss: 0.0145\n",
      "Epoch [23/40], Step [1800/16026], Loss: 0.0303\n",
      "Epoch [23/40], Step [1900/16026], Loss: 0.0247\n",
      "Epoch [23/40], Step [2000/16026], Loss: 0.0203\n",
      "Epoch [23/40], Step [2100/16026], Loss: 0.0201\n",
      "Epoch [23/40], Step [2200/16026], Loss: 0.0189\n",
      "Epoch [23/40], Step [2300/16026], Loss: 0.0214\n",
      "Epoch [23/40], Step [2400/16026], Loss: 0.0229\n",
      "Epoch [23/40], Step [2500/16026], Loss: 0.0188\n",
      "Epoch [23/40], Step [2600/16026], Loss: 0.0132\n",
      "Epoch [23/40], Step [2700/16026], Loss: 0.0137\n",
      "Epoch [23/40], Step [2800/16026], Loss: 0.0215\n",
      "Epoch [23/40], Step [2900/16026], Loss: 0.0224\n",
      "Epoch [23/40], Step [3000/16026], Loss: 0.0316\n",
      "Epoch [23/40], Step [3100/16026], Loss: 0.0127\n",
      "Epoch [23/40], Step [3200/16026], Loss: 0.0172\n",
      "Epoch [23/40], Step [3300/16026], Loss: 0.0188\n",
      "Epoch [23/40], Step [3400/16026], Loss: 0.0176\n",
      "Epoch [23/40], Step [3500/16026], Loss: 0.0235\n",
      "Epoch [23/40], Step [3600/16026], Loss: 0.0303\n",
      "Epoch [23/40], Step [3700/16026], Loss: 0.0248\n",
      "Epoch [23/40], Step [3800/16026], Loss: 0.0203\n",
      "Epoch [23/40], Step [3900/16026], Loss: 0.0244\n",
      "Epoch [23/40], Step [4000/16026], Loss: 0.0276\n",
      "Epoch [23/40], Step [4100/16026], Loss: 0.0146\n",
      "Epoch [23/40], Step [4200/16026], Loss: 0.0194\n",
      "Epoch [23/40], Step [4300/16026], Loss: 0.0324\n",
      "Epoch [23/40], Step [4400/16026], Loss: 0.0247\n",
      "Epoch [23/40], Step [4500/16026], Loss: 0.0168\n",
      "Epoch [23/40], Step [4600/16026], Loss: 0.0186\n",
      "Epoch [23/40], Step [4700/16026], Loss: 0.0211\n",
      "Epoch [23/40], Step [4800/16026], Loss: 0.0243\n",
      "Epoch [23/40], Step [4900/16026], Loss: 0.0251\n",
      "Epoch [23/40], Step [5000/16026], Loss: 0.0222\n",
      "Epoch [23/40], Step [5100/16026], Loss: 0.0170\n",
      "Epoch [23/40], Step [5200/16026], Loss: 0.0217\n",
      "Epoch [23/40], Step [5300/16026], Loss: 0.0286\n",
      "Epoch [23/40], Step [5400/16026], Loss: 0.0197\n",
      "Epoch [23/40], Step [5500/16026], Loss: 0.0254\n",
      "Epoch [23/40], Step [5600/16026], Loss: 0.0225\n",
      "Epoch [23/40], Step [5700/16026], Loss: 0.0165\n",
      "Epoch [23/40], Step [5800/16026], Loss: 0.0297\n",
      "Epoch [23/40], Step [5900/16026], Loss: 0.0152\n",
      "Epoch [23/40], Step [6000/16026], Loss: 0.0338\n",
      "Epoch [23/40], Step [6100/16026], Loss: 0.0226\n",
      "Epoch [23/40], Step [6200/16026], Loss: 0.0228\n",
      "Epoch [23/40], Step [6300/16026], Loss: 0.0160\n",
      "Epoch [23/40], Step [6400/16026], Loss: 0.0161\n",
      "Epoch [23/40], Step [6500/16026], Loss: 0.0202\n",
      "Epoch [23/40], Step [6600/16026], Loss: 0.0207\n",
      "Epoch [23/40], Step [6700/16026], Loss: 0.0309\n",
      "Epoch [23/40], Step [6800/16026], Loss: 0.0216\n",
      "Epoch [23/40], Step [6900/16026], Loss: 0.0251\n",
      "Epoch [23/40], Step [7000/16026], Loss: 0.0149\n",
      "Epoch [23/40], Step [7100/16026], Loss: 0.0253\n",
      "Epoch [23/40], Step [7200/16026], Loss: 0.0153\n",
      "Epoch [23/40], Step [7300/16026], Loss: 0.0176\n",
      "Epoch [23/40], Step [7400/16026], Loss: 0.0224\n",
      "Epoch [23/40], Step [7500/16026], Loss: 0.0167\n",
      "Epoch [23/40], Step [7600/16026], Loss: 0.0283\n",
      "Epoch [23/40], Step [7700/16026], Loss: 0.0205\n",
      "Epoch [23/40], Step [7800/16026], Loss: 0.0109\n",
      "Epoch [23/40], Step [7900/16026], Loss: 0.0174\n",
      "Epoch [23/40], Step [8000/16026], Loss: 0.0143\n",
      "Epoch [23/40], Step [8100/16026], Loss: 0.0148\n",
      "Epoch [23/40], Step [8200/16026], Loss: 0.0249\n",
      "Epoch [23/40], Step [8300/16026], Loss: 0.0292\n",
      "Epoch [23/40], Step [8400/16026], Loss: 0.0148\n",
      "Epoch [23/40], Step [8500/16026], Loss: 0.0161\n",
      "Epoch [23/40], Step [8600/16026], Loss: 0.0210\n",
      "Epoch [23/40], Step [8700/16026], Loss: 0.0211\n",
      "Epoch [23/40], Step [8800/16026], Loss: 0.0201\n",
      "Epoch [23/40], Step [8900/16026], Loss: 0.0147\n",
      "Epoch [23/40], Step [9000/16026], Loss: 0.0142\n",
      "Epoch [23/40], Step [9100/16026], Loss: 0.0224\n",
      "Epoch [23/40], Step [9200/16026], Loss: 0.0211\n",
      "Epoch [23/40], Step [9300/16026], Loss: 0.0123\n",
      "Epoch [23/40], Step [9400/16026], Loss: 0.0252\n",
      "Epoch [23/40], Step [9500/16026], Loss: 0.0235\n",
      "Epoch [23/40], Step [9600/16026], Loss: 0.0115\n",
      "Epoch [23/40], Step [9700/16026], Loss: 0.0154\n",
      "Epoch [23/40], Step [9800/16026], Loss: 0.0128\n",
      "Epoch [23/40], Step [9900/16026], Loss: 0.0264\n",
      "Epoch [23/40], Step [10000/16026], Loss: 0.0205\n",
      "Epoch [23/40], Step [10100/16026], Loss: 0.0205\n",
      "Epoch [23/40], Step [10200/16026], Loss: 0.0216\n",
      "Epoch [23/40], Step [10300/16026], Loss: 0.0246\n",
      "Epoch [23/40], Step [10400/16026], Loss: 0.0183\n",
      "Epoch [23/40], Step [10500/16026], Loss: 0.0189\n",
      "Epoch [23/40], Step [10600/16026], Loss: 0.0176\n",
      "Epoch [23/40], Step [10700/16026], Loss: 0.0267\n",
      "Epoch [23/40], Step [10800/16026], Loss: 0.0151\n",
      "Epoch [23/40], Step [10900/16026], Loss: 0.0217\n",
      "Epoch [23/40], Step [11000/16026], Loss: 0.0275\n",
      "Epoch [23/40], Step [11100/16026], Loss: 0.0192\n",
      "Epoch [23/40], Step [11200/16026], Loss: 0.0286\n",
      "Epoch [23/40], Step [11300/16026], Loss: 0.0184\n",
      "Epoch [23/40], Step [11400/16026], Loss: 0.0212\n",
      "Epoch [23/40], Step [11500/16026], Loss: 0.0128\n",
      "Epoch [23/40], Step [11600/16026], Loss: 0.0189\n",
      "Epoch [23/40], Step [11700/16026], Loss: 0.0304\n",
      "Epoch [23/40], Step [11800/16026], Loss: 0.0268\n",
      "Epoch [23/40], Step [11900/16026], Loss: 0.0275\n",
      "Epoch [23/40], Step [12000/16026], Loss: 0.0179\n",
      "Epoch [23/40], Step [12100/16026], Loss: 0.0204\n",
      "Epoch [23/40], Step [12200/16026], Loss: 0.0238\n",
      "Epoch [23/40], Step [12300/16026], Loss: 0.0124\n",
      "Epoch [23/40], Step [12400/16026], Loss: 0.0193\n",
      "Epoch [23/40], Step [12500/16026], Loss: 0.0248\n",
      "Epoch [23/40], Step [12600/16026], Loss: 0.0172\n",
      "Epoch [23/40], Step [12700/16026], Loss: 0.0400\n",
      "Epoch [23/40], Step [12800/16026], Loss: 0.0208\n",
      "Epoch [23/40], Step [12900/16026], Loss: 0.0153\n",
      "Epoch [23/40], Step [13000/16026], Loss: 0.0198\n",
      "Epoch [23/40], Step [13100/16026], Loss: 0.0149\n",
      "Epoch [23/40], Step [13200/16026], Loss: 0.0156\n",
      "Epoch [23/40], Step [13300/16026], Loss: 0.0206\n",
      "Epoch [23/40], Step [13400/16026], Loss: 0.0223\n",
      "Epoch [23/40], Step [13500/16026], Loss: 0.0168\n",
      "Epoch [23/40], Step [13600/16026], Loss: 0.0231\n",
      "Epoch [23/40], Step [13700/16026], Loss: 0.0299\n",
      "Epoch [23/40], Step [13800/16026], Loss: 0.0129\n",
      "Epoch [23/40], Step [13900/16026], Loss: 0.0202\n",
      "Epoch [23/40], Step [14000/16026], Loss: 0.0228\n",
      "Epoch [23/40], Step [14100/16026], Loss: 0.0339\n",
      "Epoch [23/40], Step [14200/16026], Loss: 0.0153\n",
      "Epoch [23/40], Step [14300/16026], Loss: 0.0170\n",
      "Epoch [23/40], Step [14400/16026], Loss: 0.0246\n",
      "Epoch [23/40], Step [14500/16026], Loss: 0.0225\n",
      "Epoch [23/40], Step [14600/16026], Loss: 0.0242\n",
      "Epoch [23/40], Step [14700/16026], Loss: 0.0198\n",
      "Epoch [23/40], Step [14800/16026], Loss: 0.0157\n",
      "Epoch [23/40], Step [14900/16026], Loss: 0.0144\n",
      "Epoch [23/40], Step [15000/16026], Loss: 0.0117\n",
      "Epoch [23/40], Step [15100/16026], Loss: 0.0234\n",
      "Epoch [23/40], Step [15200/16026], Loss: 0.0200\n",
      "Epoch [23/40], Step [15300/16026], Loss: 0.0301\n",
      "Epoch [23/40], Step [15400/16026], Loss: 0.0206\n",
      "Epoch [23/40], Step [15500/16026], Loss: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/40], Step [15600/16026], Loss: 0.0190\n",
      "Epoch [23/40], Step [15700/16026], Loss: 0.0183\n",
      "Epoch [23/40], Step [15800/16026], Loss: 0.0205\n",
      "Epoch [23/40], Step [15900/16026], Loss: 0.0194\n",
      "Epoch [23/40], Step [16000/16026], Loss: 0.0158\n",
      "Epoch [24/40], Step [100/16026], Loss: 0.0156\n",
      "Epoch [24/40], Step [200/16026], Loss: 0.0191\n",
      "Epoch [24/40], Step [300/16026], Loss: 0.0179\n",
      "Epoch [24/40], Step [400/16026], Loss: 0.0192\n",
      "Epoch [24/40], Step [500/16026], Loss: 0.0257\n",
      "Epoch [24/40], Step [600/16026], Loss: 0.0220\n",
      "Epoch [24/40], Step [700/16026], Loss: 0.0166\n",
      "Epoch [24/40], Step [800/16026], Loss: 0.0261\n",
      "Epoch [24/40], Step [900/16026], Loss: 0.0194\n",
      "Epoch [24/40], Step [1000/16026], Loss: 0.0136\n",
      "Epoch [24/40], Step [1100/16026], Loss: 0.0188\n",
      "Epoch [24/40], Step [1200/16026], Loss: 0.0217\n",
      "Epoch [24/40], Step [1300/16026], Loss: 0.0137\n",
      "Epoch [24/40], Step [1400/16026], Loss: 0.0118\n",
      "Epoch [24/40], Step [1500/16026], Loss: 0.0153\n",
      "Epoch [24/40], Step [1600/16026], Loss: 0.0142\n",
      "Epoch [24/40], Step [1700/16026], Loss: 0.0281\n",
      "Epoch [24/40], Step [1800/16026], Loss: 0.0226\n",
      "Epoch [24/40], Step [1900/16026], Loss: 0.0149\n",
      "Epoch [24/40], Step [2000/16026], Loss: 0.0186\n",
      "Epoch [24/40], Step [2100/16026], Loss: 0.0184\n",
      "Epoch [24/40], Step [2200/16026], Loss: 0.0241\n",
      "Epoch [24/40], Step [2300/16026], Loss: 0.0189\n",
      "Epoch [24/40], Step [2400/16026], Loss: 0.0134\n",
      "Epoch [24/40], Step [2500/16026], Loss: 0.0235\n",
      "Epoch [24/40], Step [2600/16026], Loss: 0.0178\n",
      "Epoch [24/40], Step [2700/16026], Loss: 0.0223\n",
      "Epoch [24/40], Step [2800/16026], Loss: 0.0188\n",
      "Epoch [24/40], Step [2900/16026], Loss: 0.0254\n",
      "Epoch [24/40], Step [3000/16026], Loss: 0.0292\n",
      "Epoch [24/40], Step [3100/16026], Loss: 0.0209\n",
      "Epoch [24/40], Step [3200/16026], Loss: 0.0268\n",
      "Epoch [24/40], Step [3300/16026], Loss: 0.0165\n",
      "Epoch [24/40], Step [3400/16026], Loss: 0.0160\n",
      "Epoch [24/40], Step [3500/16026], Loss: 0.0141\n",
      "Epoch [24/40], Step [3600/16026], Loss: 0.0181\n",
      "Epoch [24/40], Step [3700/16026], Loss: 0.0176\n",
      "Epoch [24/40], Step [3800/16026], Loss: 0.0255\n",
      "Epoch [24/40], Step [3900/16026], Loss: 0.0235\n",
      "Epoch [24/40], Step [4000/16026], Loss: 0.0195\n",
      "Epoch [24/40], Step [4100/16026], Loss: 0.0189\n",
      "Epoch [24/40], Step [4200/16026], Loss: 0.0257\n",
      "Epoch [24/40], Step [4300/16026], Loss: 0.0230\n",
      "Epoch [24/40], Step [4400/16026], Loss: 0.0171\n",
      "Epoch [24/40], Step [4500/16026], Loss: 0.0181\n",
      "Epoch [24/40], Step [4600/16026], Loss: 0.0186\n",
      "Epoch [24/40], Step [4700/16026], Loss: 0.0177\n",
      "Epoch [24/40], Step [4800/16026], Loss: 0.0197\n",
      "Epoch [24/40], Step [4900/16026], Loss: 0.0143\n",
      "Epoch [24/40], Step [5000/16026], Loss: 0.0323\n",
      "Epoch [24/40], Step [5100/16026], Loss: 0.0186\n",
      "Epoch [24/40], Step [5200/16026], Loss: 0.0149\n",
      "Epoch [24/40], Step [5300/16026], Loss: 0.0162\n",
      "Epoch [24/40], Step [5400/16026], Loss: 0.0186\n",
      "Epoch [24/40], Step [5500/16026], Loss: 0.0176\n",
      "Epoch [24/40], Step [5600/16026], Loss: 0.0122\n",
      "Epoch [24/40], Step [5700/16026], Loss: 0.0269\n",
      "Epoch [24/40], Step [5800/16026], Loss: 0.0179\n",
      "Epoch [24/40], Step [5900/16026], Loss: 0.0217\n",
      "Epoch [24/40], Step [6000/16026], Loss: 0.0278\n",
      "Epoch [24/40], Step [6100/16026], Loss: 0.0329\n",
      "Epoch [24/40], Step [6200/16026], Loss: 0.0202\n",
      "Epoch [24/40], Step [6300/16026], Loss: 0.0193\n",
      "Epoch [24/40], Step [6400/16026], Loss: 0.0186\n",
      "Epoch [24/40], Step [6500/16026], Loss: 0.0299\n",
      "Epoch [24/40], Step [6600/16026], Loss: 0.0155\n",
      "Epoch [24/40], Step [6700/16026], Loss: 0.0282\n",
      "Epoch [24/40], Step [6800/16026], Loss: 0.0236\n",
      "Epoch [24/40], Step [6900/16026], Loss: 0.0089\n",
      "Epoch [24/40], Step [7000/16026], Loss: 0.0225\n",
      "Epoch [24/40], Step [7100/16026], Loss: 0.0145\n",
      "Epoch [24/40], Step [7200/16026], Loss: 0.0188\n",
      "Epoch [24/40], Step [7300/16026], Loss: 0.0161\n",
      "Epoch [24/40], Step [7400/16026], Loss: 0.0135\n",
      "Epoch [24/40], Step [7500/16026], Loss: 0.0202\n",
      "Epoch [24/40], Step [7600/16026], Loss: 0.0235\n",
      "Epoch [24/40], Step [7700/16026], Loss: 0.0166\n",
      "Epoch [24/40], Step [7800/16026], Loss: 0.0425\n",
      "Epoch [24/40], Step [7900/16026], Loss: 0.0339\n",
      "Epoch [24/40], Step [8000/16026], Loss: 0.0256\n",
      "Epoch [24/40], Step [8100/16026], Loss: 0.0195\n",
      "Epoch [24/40], Step [8200/16026], Loss: 0.0132\n",
      "Epoch [24/40], Step [8300/16026], Loss: 0.0139\n",
      "Epoch [24/40], Step [8400/16026], Loss: 0.0189\n",
      "Epoch [24/40], Step [8500/16026], Loss: 0.0194\n",
      "Epoch [24/40], Step [8600/16026], Loss: 0.0342\n",
      "Epoch [24/40], Step [8700/16026], Loss: 0.0211\n",
      "Epoch [24/40], Step [8800/16026], Loss: 0.0262\n",
      "Epoch [24/40], Step [8900/16026], Loss: 0.0200\n",
      "Epoch [24/40], Step [9000/16026], Loss: 0.0158\n",
      "Epoch [24/40], Step [9100/16026], Loss: 0.0223\n",
      "Epoch [24/40], Step [9200/16026], Loss: 0.0184\n",
      "Epoch [24/40], Step [9300/16026], Loss: 0.0174\n",
      "Epoch [24/40], Step [9400/16026], Loss: 0.0218\n",
      "Epoch [24/40], Step [9500/16026], Loss: 0.0229\n",
      "Epoch [24/40], Step [9600/16026], Loss: 0.0126\n",
      "Epoch [24/40], Step [9700/16026], Loss: 0.0140\n",
      "Epoch [24/40], Step [9800/16026], Loss: 0.0230\n",
      "Epoch [24/40], Step [9900/16026], Loss: 0.0204\n",
      "Epoch [24/40], Step [10000/16026], Loss: 0.0231\n",
      "Epoch [24/40], Step [10100/16026], Loss: 0.0168\n",
      "Epoch [24/40], Step [10200/16026], Loss: 0.0147\n",
      "Epoch [24/40], Step [10300/16026], Loss: 0.0152\n",
      "Epoch [24/40], Step [10400/16026], Loss: 0.0179\n",
      "Epoch [24/40], Step [10500/16026], Loss: 0.0152\n",
      "Epoch [24/40], Step [10600/16026], Loss: 0.0252\n",
      "Epoch [24/40], Step [10700/16026], Loss: 0.0194\n",
      "Epoch [24/40], Step [10800/16026], Loss: 0.0196\n",
      "Epoch [24/40], Step [10900/16026], Loss: 0.0237\n",
      "Epoch [24/40], Step [11000/16026], Loss: 0.0141\n",
      "Epoch [24/40], Step [11100/16026], Loss: 0.0268\n",
      "Epoch [24/40], Step [11200/16026], Loss: 0.0344\n",
      "Epoch [24/40], Step [11300/16026], Loss: 0.0146\n",
      "Epoch [24/40], Step [11400/16026], Loss: 0.0197\n",
      "Epoch [24/40], Step [11500/16026], Loss: 0.0335\n",
      "Epoch [24/40], Step [11600/16026], Loss: 0.0135\n",
      "Epoch [24/40], Step [11700/16026], Loss: 0.0269\n",
      "Epoch [24/40], Step [11800/16026], Loss: 0.0188\n",
      "Epoch [24/40], Step [11900/16026], Loss: 0.0234\n",
      "Epoch [24/40], Step [12000/16026], Loss: 0.0193\n",
      "Epoch [24/40], Step [12100/16026], Loss: 0.0295\n",
      "Epoch [24/40], Step [12200/16026], Loss: 0.0160\n",
      "Epoch [24/40], Step [12300/16026], Loss: 0.0138\n",
      "Epoch [24/40], Step [12400/16026], Loss: 0.0288\n",
      "Epoch [24/40], Step [12500/16026], Loss: 0.0238\n",
      "Epoch [24/40], Step [12600/16026], Loss: 0.0227\n",
      "Epoch [24/40], Step [12700/16026], Loss: 0.0216\n",
      "Epoch [24/40], Step [12800/16026], Loss: 0.0240\n",
      "Epoch [24/40], Step [12900/16026], Loss: 0.0351\n",
      "Epoch [24/40], Step [13000/16026], Loss: 0.0190\n",
      "Epoch [24/40], Step [13100/16026], Loss: 0.0241\n",
      "Epoch [24/40], Step [13200/16026], Loss: 0.0263\n",
      "Epoch [24/40], Step [13300/16026], Loss: 0.0251\n",
      "Epoch [24/40], Step [13400/16026], Loss: 0.0152\n",
      "Epoch [24/40], Step [13500/16026], Loss: 0.0218\n",
      "Epoch [24/40], Step [13600/16026], Loss: 0.0399\n",
      "Epoch [24/40], Step [13700/16026], Loss: 0.0122\n",
      "Epoch [24/40], Step [13800/16026], Loss: 0.0253\n",
      "Epoch [24/40], Step [13900/16026], Loss: 0.0236\n",
      "Epoch [24/40], Step [14000/16026], Loss: 0.0206\n",
      "Epoch [24/40], Step [14100/16026], Loss: 0.0228\n",
      "Epoch [24/40], Step [14200/16026], Loss: 0.0119\n",
      "Epoch [24/40], Step [14300/16026], Loss: 0.0143\n",
      "Epoch [24/40], Step [14400/16026], Loss: 0.0305\n",
      "Epoch [24/40], Step [14500/16026], Loss: 0.0455\n",
      "Epoch [24/40], Step [14600/16026], Loss: 0.0200\n",
      "Epoch [24/40], Step [14700/16026], Loss: 0.0272\n",
      "Epoch [24/40], Step [14800/16026], Loss: 0.0186\n",
      "Epoch [24/40], Step [14900/16026], Loss: 0.0179\n",
      "Epoch [24/40], Step [15000/16026], Loss: 0.0119\n",
      "Epoch [24/40], Step [15100/16026], Loss: 0.0179\n",
      "Epoch [24/40], Step [15200/16026], Loss: 0.0233\n",
      "Epoch [24/40], Step [15300/16026], Loss: 0.0248\n",
      "Epoch [24/40], Step [15400/16026], Loss: 0.0123\n",
      "Epoch [24/40], Step [15500/16026], Loss: 0.0302\n",
      "Epoch [24/40], Step [15600/16026], Loss: 0.0284\n",
      "Epoch [24/40], Step [15700/16026], Loss: 0.0172\n",
      "Epoch [24/40], Step [15800/16026], Loss: 0.0151\n",
      "Epoch [24/40], Step [15900/16026], Loss: 0.0157\n",
      "Epoch [24/40], Step [16000/16026], Loss: 0.0274\n",
      "Epoch [25/40], Step [100/16026], Loss: 0.0176\n",
      "Epoch [25/40], Step [200/16026], Loss: 0.0230\n",
      "Epoch [25/40], Step [300/16026], Loss: 0.0100\n",
      "Epoch [25/40], Step [400/16026], Loss: 0.0262\n",
      "Epoch [25/40], Step [500/16026], Loss: 0.0101\n",
      "Epoch [25/40], Step [600/16026], Loss: 0.0255\n",
      "Epoch [25/40], Step [700/16026], Loss: 0.0217\n",
      "Epoch [25/40], Step [800/16026], Loss: 0.0136\n",
      "Epoch [25/40], Step [900/16026], Loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/40], Step [1000/16026], Loss: 0.0195\n",
      "Epoch [25/40], Step [1100/16026], Loss: 0.0212\n",
      "Epoch [25/40], Step [1200/16026], Loss: 0.0232\n",
      "Epoch [25/40], Step [1300/16026], Loss: 0.0218\n",
      "Epoch [25/40], Step [1400/16026], Loss: 0.0232\n",
      "Epoch [25/40], Step [1500/16026], Loss: 0.0108\n",
      "Epoch [25/40], Step [1600/16026], Loss: 0.0195\n",
      "Epoch [25/40], Step [1700/16026], Loss: 0.0138\n",
      "Epoch [25/40], Step [1800/16026], Loss: 0.0172\n",
      "Epoch [25/40], Step [1900/16026], Loss: 0.0155\n",
      "Epoch [25/40], Step [2000/16026], Loss: 0.0219\n",
      "Epoch [25/40], Step [2100/16026], Loss: 0.0207\n",
      "Epoch [25/40], Step [2200/16026], Loss: 0.0213\n",
      "Epoch [25/40], Step [2300/16026], Loss: 0.0682\n",
      "Epoch [25/40], Step [2400/16026], Loss: 0.0267\n",
      "Epoch [25/40], Step [2500/16026], Loss: 0.0315\n",
      "Epoch [25/40], Step [2600/16026], Loss: 0.0156\n",
      "Epoch [25/40], Step [2700/16026], Loss: 0.0214\n",
      "Epoch [25/40], Step [2800/16026], Loss: 0.0290\n",
      "Epoch [25/40], Step [2900/16026], Loss: 0.0216\n",
      "Epoch [25/40], Step [3000/16026], Loss: 0.0191\n",
      "Epoch [25/40], Step [3100/16026], Loss: 0.0229\n",
      "Epoch [25/40], Step [3200/16026], Loss: 0.0257\n",
      "Epoch [25/40], Step [3300/16026], Loss: 0.0156\n",
      "Epoch [25/40], Step [3400/16026], Loss: 0.0211\n",
      "Epoch [25/40], Step [3500/16026], Loss: 0.0245\n",
      "Epoch [25/40], Step [3600/16026], Loss: 0.0187\n",
      "Epoch [25/40], Step [3700/16026], Loss: 0.0165\n",
      "Epoch [25/40], Step [3800/16026], Loss: 0.0263\n",
      "Epoch [25/40], Step [3900/16026], Loss: 0.0310\n",
      "Epoch [25/40], Step [4000/16026], Loss: 0.0224\n",
      "Epoch [25/40], Step [4100/16026], Loss: 0.0731\n",
      "Epoch [25/40], Step [4200/16026], Loss: 0.0168\n",
      "Epoch [25/40], Step [4300/16026], Loss: 0.0135\n",
      "Epoch [25/40], Step [4400/16026], Loss: 0.0324\n",
      "Epoch [25/40], Step [4500/16026], Loss: 0.0151\n",
      "Epoch [25/40], Step [4600/16026], Loss: 0.0219\n",
      "Epoch [25/40], Step [4700/16026], Loss: 0.0304\n",
      "Epoch [25/40], Step [4800/16026], Loss: 0.0149\n",
      "Epoch [25/40], Step [4900/16026], Loss: 0.0153\n",
      "Epoch [25/40], Step [5000/16026], Loss: 0.0136\n",
      "Epoch [25/40], Step [5100/16026], Loss: 0.0177\n",
      "Epoch [25/40], Step [5200/16026], Loss: 0.0317\n",
      "Epoch [25/40], Step [5300/16026], Loss: 0.0166\n",
      "Epoch [25/40], Step [5400/16026], Loss: 0.0187\n",
      "Epoch [25/40], Step [5500/16026], Loss: 0.0301\n",
      "Epoch [25/40], Step [5600/16026], Loss: 0.0174\n",
      "Epoch [25/40], Step [5700/16026], Loss: 0.0108\n",
      "Epoch [25/40], Step [5800/16026], Loss: 0.0142\n",
      "Epoch [25/40], Step [5900/16026], Loss: 0.0199\n",
      "Epoch [25/40], Step [6000/16026], Loss: 0.0211\n",
      "Epoch [25/40], Step [6100/16026], Loss: 0.0292\n",
      "Epoch [25/40], Step [6200/16026], Loss: 0.0225\n",
      "Epoch [25/40], Step [6300/16026], Loss: 0.0135\n",
      "Epoch [25/40], Step [6400/16026], Loss: 0.0237\n",
      "Epoch [25/40], Step [6500/16026], Loss: 0.0193\n",
      "Epoch [25/40], Step [6600/16026], Loss: 0.0556\n",
      "Epoch [25/40], Step [6700/16026], Loss: 0.0224\n",
      "Epoch [25/40], Step [6800/16026], Loss: 0.0163\n",
      "Epoch [25/40], Step [6900/16026], Loss: 0.0179\n",
      "Epoch [25/40], Step [7000/16026], Loss: 0.0191\n",
      "Epoch [25/40], Step [7100/16026], Loss: 0.0247\n",
      "Epoch [25/40], Step [7200/16026], Loss: 0.0285\n",
      "Epoch [25/40], Step [7300/16026], Loss: 0.0351\n",
      "Epoch [25/40], Step [7400/16026], Loss: 0.0185\n",
      "Epoch [25/40], Step [7500/16026], Loss: 0.0199\n",
      "Epoch [25/40], Step [7600/16026], Loss: 0.0204\n",
      "Epoch [25/40], Step [7700/16026], Loss: 0.0083\n",
      "Epoch [25/40], Step [7800/16026], Loss: 0.0266\n",
      "Epoch [25/40], Step [7900/16026], Loss: 0.0188\n",
      "Epoch [25/40], Step [8000/16026], Loss: 0.0691\n",
      "Epoch [25/40], Step [8100/16026], Loss: 0.0294\n",
      "Epoch [25/40], Step [8200/16026], Loss: 0.0177\n",
      "Epoch [25/40], Step [8300/16026], Loss: 0.0188\n",
      "Epoch [25/40], Step [8400/16026], Loss: 0.0239\n",
      "Epoch [25/40], Step [8500/16026], Loss: 0.0160\n",
      "Epoch [25/40], Step [8600/16026], Loss: 0.0182\n",
      "Epoch [25/40], Step [8700/16026], Loss: 0.0158\n",
      "Epoch [25/40], Step [8800/16026], Loss: 0.0352\n",
      "Epoch [25/40], Step [8900/16026], Loss: 0.0219\n",
      "Epoch [25/40], Step [9000/16026], Loss: 0.0277\n",
      "Epoch [25/40], Step [9100/16026], Loss: 0.0241\n",
      "Epoch [25/40], Step [9200/16026], Loss: 0.0163\n",
      "Epoch [25/40], Step [9300/16026], Loss: 0.0239\n",
      "Epoch [25/40], Step [9400/16026], Loss: 0.0190\n",
      "Epoch [25/40], Step [9500/16026], Loss: 0.0207\n",
      "Epoch [25/40], Step [9600/16026], Loss: 0.0183\n",
      "Epoch [25/40], Step [9700/16026], Loss: 0.0203\n",
      "Epoch [25/40], Step [9800/16026], Loss: 0.0172\n",
      "Epoch [25/40], Step [9900/16026], Loss: 0.0205\n",
      "Epoch [25/40], Step [10000/16026], Loss: 0.0242\n",
      "Epoch [25/40], Step [10100/16026], Loss: 0.0185\n",
      "Epoch [25/40], Step [10200/16026], Loss: 0.0216\n",
      "Epoch [25/40], Step [10300/16026], Loss: 0.0202\n",
      "Epoch [25/40], Step [10400/16026], Loss: 0.0210\n",
      "Epoch [25/40], Step [10500/16026], Loss: 0.0157\n",
      "Epoch [25/40], Step [10600/16026], Loss: 0.0200\n",
      "Epoch [25/40], Step [10700/16026], Loss: 0.0150\n",
      "Epoch [25/40], Step [10800/16026], Loss: 0.0151\n",
      "Epoch [25/40], Step [10900/16026], Loss: 0.0203\n",
      "Epoch [25/40], Step [11000/16026], Loss: 0.0143\n",
      "Epoch [25/40], Step [11100/16026], Loss: 0.0145\n",
      "Epoch [25/40], Step [11200/16026], Loss: 0.0150\n",
      "Epoch [25/40], Step [11300/16026], Loss: 0.0188\n",
      "Epoch [25/40], Step [11400/16026], Loss: 0.0160\n",
      "Epoch [25/40], Step [11500/16026], Loss: 0.0719\n",
      "Epoch [25/40], Step [11600/16026], Loss: 0.0739\n",
      "Epoch [25/40], Step [11700/16026], Loss: 0.0161\n",
      "Epoch [25/40], Step [11800/16026], Loss: 0.0289\n",
      "Epoch [25/40], Step [11900/16026], Loss: 0.0213\n",
      "Epoch [25/40], Step [12000/16026], Loss: 0.0181\n",
      "Epoch [25/40], Step [12100/16026], Loss: 0.0183\n",
      "Epoch [25/40], Step [12200/16026], Loss: 0.0277\n",
      "Epoch [25/40], Step [12300/16026], Loss: 0.0234\n",
      "Epoch [25/40], Step [12400/16026], Loss: 0.0322\n",
      "Epoch [25/40], Step [12500/16026], Loss: 0.0199\n",
      "Epoch [25/40], Step [12600/16026], Loss: 0.0219\n",
      "Epoch [25/40], Step [12700/16026], Loss: 0.0225\n",
      "Epoch [25/40], Step [12800/16026], Loss: 0.0237\n",
      "Epoch [25/40], Step [12900/16026], Loss: 0.0209\n",
      "Epoch [25/40], Step [13000/16026], Loss: 0.0180\n",
      "Epoch [25/40], Step [13100/16026], Loss: 0.0140\n",
      "Epoch [25/40], Step [13200/16026], Loss: 0.0164\n",
      "Epoch [25/40], Step [13300/16026], Loss: 0.0254\n",
      "Epoch [25/40], Step [13400/16026], Loss: 0.0224\n",
      "Epoch [25/40], Step [13500/16026], Loss: 0.0219\n",
      "Epoch [25/40], Step [13600/16026], Loss: 0.0274\n",
      "Epoch [25/40], Step [13700/16026], Loss: 0.0289\n",
      "Epoch [25/40], Step [13800/16026], Loss: 0.0190\n",
      "Epoch [25/40], Step [13900/16026], Loss: 0.0153\n",
      "Epoch [25/40], Step [14000/16026], Loss: 0.0358\n",
      "Epoch [25/40], Step [14100/16026], Loss: 0.0152\n",
      "Epoch [25/40], Step [14200/16026], Loss: 0.0193\n",
      "Epoch [25/40], Step [14300/16026], Loss: 0.0187\n",
      "Epoch [25/40], Step [14400/16026], Loss: 0.0247\n",
      "Epoch [25/40], Step [14500/16026], Loss: 0.0435\n",
      "Epoch [25/40], Step [14600/16026], Loss: 0.0226\n",
      "Epoch [25/40], Step [14700/16026], Loss: 0.0285\n",
      "Epoch [25/40], Step [14800/16026], Loss: 0.0122\n",
      "Epoch [25/40], Step [14900/16026], Loss: 0.0250\n",
      "Epoch [25/40], Step [15000/16026], Loss: 0.0161\n",
      "Epoch [25/40], Step [15100/16026], Loss: 0.0155\n",
      "Epoch [25/40], Step [15200/16026], Loss: 0.0192\n",
      "Epoch [25/40], Step [15300/16026], Loss: 0.0175\n",
      "Epoch [25/40], Step [15400/16026], Loss: 0.0214\n",
      "Epoch [25/40], Step [15500/16026], Loss: 0.0165\n",
      "Epoch [25/40], Step [15600/16026], Loss: 0.0300\n",
      "Epoch [25/40], Step [15700/16026], Loss: 0.0230\n",
      "Epoch [25/40], Step [15800/16026], Loss: 0.0213\n",
      "Epoch [25/40], Step [15900/16026], Loss: 0.0178\n",
      "Epoch [25/40], Step [16000/16026], Loss: 0.0230\n",
      "Epoch [26/40], Step [100/16026], Loss: 0.0209\n",
      "Epoch [26/40], Step [200/16026], Loss: 0.0186\n",
      "Epoch [26/40], Step [300/16026], Loss: 0.0273\n",
      "Epoch [26/40], Step [400/16026], Loss: 0.0232\n",
      "Epoch [26/40], Step [500/16026], Loss: 0.0116\n",
      "Epoch [26/40], Step [600/16026], Loss: 0.0226\n",
      "Epoch [26/40], Step [700/16026], Loss: 0.0200\n",
      "Epoch [26/40], Step [800/16026], Loss: 0.0182\n",
      "Epoch [26/40], Step [900/16026], Loss: 0.0340\n",
      "Epoch [26/40], Step [1000/16026], Loss: 0.0188\n",
      "Epoch [26/40], Step [1100/16026], Loss: 0.0188\n",
      "Epoch [26/40], Step [1200/16026], Loss: 0.0196\n",
      "Epoch [26/40], Step [1300/16026], Loss: 0.0215\n",
      "Epoch [26/40], Step [1400/16026], Loss: 0.0187\n",
      "Epoch [26/40], Step [1500/16026], Loss: 0.0181\n",
      "Epoch [26/40], Step [1600/16026], Loss: 0.0172\n",
      "Epoch [26/40], Step [1700/16026], Loss: 0.0153\n",
      "Epoch [26/40], Step [1800/16026], Loss: 0.0136\n",
      "Epoch [26/40], Step [1900/16026], Loss: 0.0156\n",
      "Epoch [26/40], Step [2000/16026], Loss: 0.0271\n",
      "Epoch [26/40], Step [2100/16026], Loss: 0.0212\n",
      "Epoch [26/40], Step [2200/16026], Loss: 0.0289\n",
      "Epoch [26/40], Step [2300/16026], Loss: 0.0339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/40], Step [2400/16026], Loss: 0.0275\n",
      "Epoch [26/40], Step [2500/16026], Loss: 0.0111\n",
      "Epoch [26/40], Step [2600/16026], Loss: 0.0153\n",
      "Epoch [26/40], Step [2700/16026], Loss: 0.0159\n",
      "Epoch [26/40], Step [2800/16026], Loss: 0.0202\n",
      "Epoch [26/40], Step [2900/16026], Loss: 0.0208\n",
      "Epoch [26/40], Step [3000/16026], Loss: 0.0218\n",
      "Epoch [26/40], Step [3100/16026], Loss: 0.0170\n",
      "Epoch [26/40], Step [3200/16026], Loss: 0.0152\n",
      "Epoch [26/40], Step [3300/16026], Loss: 0.0183\n",
      "Epoch [26/40], Step [3400/16026], Loss: 0.0220\n",
      "Epoch [26/40], Step [3500/16026], Loss: 0.0206\n",
      "Epoch [26/40], Step [3600/16026], Loss: 0.0166\n",
      "Epoch [26/40], Step [3700/16026], Loss: 0.0234\n",
      "Epoch [26/40], Step [3800/16026], Loss: 0.0114\n",
      "Epoch [26/40], Step [3900/16026], Loss: 0.0199\n",
      "Epoch [26/40], Step [4000/16026], Loss: 0.0117\n",
      "Epoch [26/40], Step [4100/16026], Loss: 0.0203\n",
      "Epoch [26/40], Step [4200/16026], Loss: 0.0160\n",
      "Epoch [26/40], Step [4300/16026], Loss: 0.0218\n",
      "Epoch [26/40], Step [4400/16026], Loss: 0.0226\n",
      "Epoch [26/40], Step [4500/16026], Loss: 0.0189\n",
      "Epoch [26/40], Step [4600/16026], Loss: 0.0187\n",
      "Epoch [26/40], Step [4700/16026], Loss: 0.0252\n",
      "Epoch [26/40], Step [4800/16026], Loss: 0.0223\n",
      "Epoch [26/40], Step [4900/16026], Loss: 0.0147\n",
      "Epoch [26/40], Step [5000/16026], Loss: 0.0109\n",
      "Epoch [26/40], Step [5100/16026], Loss: 0.0195\n",
      "Epoch [26/40], Step [5200/16026], Loss: 0.0343\n",
      "Epoch [26/40], Step [5300/16026], Loss: 0.0257\n",
      "Epoch [26/40], Step [5400/16026], Loss: 0.0251\n",
      "Epoch [26/40], Step [5500/16026], Loss: 0.0189\n",
      "Epoch [26/40], Step [5600/16026], Loss: 0.0246\n",
      "Epoch [26/40], Step [5700/16026], Loss: 0.0172\n",
      "Epoch [26/40], Step [5800/16026], Loss: 0.0220\n",
      "Epoch [26/40], Step [5900/16026], Loss: 0.0209\n",
      "Epoch [26/40], Step [6000/16026], Loss: 0.0218\n",
      "Epoch [26/40], Step [6100/16026], Loss: 0.0222\n",
      "Epoch [26/40], Step [6200/16026], Loss: 0.0256\n",
      "Epoch [26/40], Step [6300/16026], Loss: 0.0200\n",
      "Epoch [26/40], Step [6400/16026], Loss: 0.0240\n",
      "Epoch [26/40], Step [6500/16026], Loss: 0.0143\n",
      "Epoch [26/40], Step [6600/16026], Loss: 0.0266\n",
      "Epoch [26/40], Step [6700/16026], Loss: 0.0159\n",
      "Epoch [26/40], Step [6800/16026], Loss: 0.0172\n",
      "Epoch [26/40], Step [6900/16026], Loss: 0.0231\n",
      "Epoch [26/40], Step [7000/16026], Loss: 0.0190\n",
      "Epoch [26/40], Step [7100/16026], Loss: 0.0135\n",
      "Epoch [26/40], Step [7200/16026], Loss: 0.0206\n",
      "Epoch [26/40], Step [7300/16026], Loss: 0.0185\n",
      "Epoch [26/40], Step [7400/16026], Loss: 0.0148\n",
      "Epoch [26/40], Step [7500/16026], Loss: 0.0153\n",
      "Epoch [26/40], Step [7600/16026], Loss: 0.0322\n",
      "Epoch [26/40], Step [7700/16026], Loss: 0.0203\n",
      "Epoch [26/40], Step [7800/16026], Loss: 0.0285\n",
      "Epoch [26/40], Step [7900/16026], Loss: 0.0246\n",
      "Epoch [26/40], Step [8000/16026], Loss: 0.0208\n",
      "Epoch [26/40], Step [8100/16026], Loss: 0.0214\n",
      "Epoch [26/40], Step [8200/16026], Loss: 0.0207\n",
      "Epoch [26/40], Step [8300/16026], Loss: 0.0193\n",
      "Epoch [26/40], Step [8400/16026], Loss: 0.0160\n",
      "Epoch [26/40], Step [8500/16026], Loss: 0.0250\n",
      "Epoch [26/40], Step [8600/16026], Loss: 0.0136\n",
      "Epoch [26/40], Step [8700/16026], Loss: 0.0299\n",
      "Epoch [26/40], Step [8800/16026], Loss: 0.0265\n",
      "Epoch [26/40], Step [8900/16026], Loss: 0.0236\n",
      "Epoch [26/40], Step [9000/16026], Loss: 0.0243\n",
      "Epoch [26/40], Step [9100/16026], Loss: 0.0223\n",
      "Epoch [26/40], Step [9200/16026], Loss: 0.0329\n",
      "Epoch [26/40], Step [9300/16026], Loss: 0.0208\n",
      "Epoch [26/40], Step [9400/16026], Loss: 0.0253\n",
      "Epoch [26/40], Step [9500/16026], Loss: 0.0216\n",
      "Epoch [26/40], Step [9600/16026], Loss: 0.0268\n",
      "Epoch [26/40], Step [9700/16026], Loss: 0.0313\n",
      "Epoch [26/40], Step [9800/16026], Loss: 0.0145\n",
      "Epoch [26/40], Step [9900/16026], Loss: 0.0142\n",
      "Epoch [26/40], Step [10000/16026], Loss: 0.0247\n",
      "Epoch [26/40], Step [10100/16026], Loss: 0.0226\n",
      "Epoch [26/40], Step [10200/16026], Loss: 0.0266\n",
      "Epoch [26/40], Step [10300/16026], Loss: 0.0201\n",
      "Epoch [26/40], Step [10400/16026], Loss: 0.0315\n",
      "Epoch [26/40], Step [10500/16026], Loss: 0.0227\n",
      "Epoch [26/40], Step [10600/16026], Loss: 0.0134\n",
      "Epoch [26/40], Step [10700/16026], Loss: 0.0302\n",
      "Epoch [26/40], Step [10800/16026], Loss: 0.0170\n",
      "Epoch [26/40], Step [10900/16026], Loss: 0.0162\n",
      "Epoch [26/40], Step [11000/16026], Loss: 0.0220\n",
      "Epoch [26/40], Step [11100/16026], Loss: 0.0225\n",
      "Epoch [26/40], Step [11200/16026], Loss: 0.0319\n",
      "Epoch [26/40], Step [11300/16026], Loss: 0.0163\n",
      "Epoch [26/40], Step [11400/16026], Loss: 0.0195\n",
      "Epoch [26/40], Step [11500/16026], Loss: 0.0167\n",
      "Epoch [26/40], Step [11600/16026], Loss: 0.0212\n",
      "Epoch [26/40], Step [11700/16026], Loss: 0.0220\n",
      "Epoch [26/40], Step [11800/16026], Loss: 0.0237\n",
      "Epoch [26/40], Step [11900/16026], Loss: 0.0276\n",
      "Epoch [26/40], Step [12000/16026], Loss: 0.0156\n",
      "Epoch [26/40], Step [12100/16026], Loss: 0.0242\n",
      "Epoch [26/40], Step [12200/16026], Loss: 0.0228\n",
      "Epoch [26/40], Step [12300/16026], Loss: 0.0320\n",
      "Epoch [26/40], Step [12400/16026], Loss: 0.0203\n",
      "Epoch [26/40], Step [12500/16026], Loss: 0.0188\n",
      "Epoch [26/40], Step [12600/16026], Loss: 0.0159\n",
      "Epoch [26/40], Step [12700/16026], Loss: 0.0135\n",
      "Epoch [26/40], Step [12800/16026], Loss: 0.0361\n",
      "Epoch [26/40], Step [12900/16026], Loss: 0.0162\n",
      "Epoch [26/40], Step [13000/16026], Loss: 0.0233\n",
      "Epoch [26/40], Step [13100/16026], Loss: 0.0178\n",
      "Epoch [26/40], Step [13200/16026], Loss: 0.0181\n",
      "Epoch [26/40], Step [13300/16026], Loss: 0.0377\n",
      "Epoch [26/40], Step [13400/16026], Loss: 0.0195\n",
      "Epoch [26/40], Step [13500/16026], Loss: 0.0293\n",
      "Epoch [26/40], Step [13600/16026], Loss: 0.0232\n",
      "Epoch [26/40], Step [13700/16026], Loss: 0.0184\n",
      "Epoch [26/40], Step [13800/16026], Loss: 0.0234\n",
      "Epoch [26/40], Step [13900/16026], Loss: 0.0210\n",
      "Epoch [26/40], Step [14000/16026], Loss: 0.0178\n",
      "Epoch [26/40], Step [14100/16026], Loss: 0.0153\n",
      "Epoch [26/40], Step [14200/16026], Loss: 0.0180\n",
      "Epoch [26/40], Step [14300/16026], Loss: 0.0206\n",
      "Epoch [26/40], Step [14400/16026], Loss: 0.0374\n",
      "Epoch [26/40], Step [14500/16026], Loss: 0.0183\n",
      "Epoch [26/40], Step [14600/16026], Loss: 0.0160\n",
      "Epoch [26/40], Step [14700/16026], Loss: 0.0194\n",
      "Epoch [26/40], Step [14800/16026], Loss: 0.0285\n",
      "Epoch [26/40], Step [14900/16026], Loss: 0.0183\n",
      "Epoch [26/40], Step [15000/16026], Loss: 0.0230\n",
      "Epoch [26/40], Step [15100/16026], Loss: 0.0153\n",
      "Epoch [26/40], Step [15200/16026], Loss: 0.0166\n",
      "Epoch [26/40], Step [15300/16026], Loss: 0.0315\n",
      "Epoch [26/40], Step [15400/16026], Loss: 0.0649\n",
      "Epoch [26/40], Step [15500/16026], Loss: 0.0247\n",
      "Epoch [26/40], Step [15600/16026], Loss: 0.0219\n",
      "Epoch [26/40], Step [15700/16026], Loss: 0.0185\n",
      "Epoch [26/40], Step [15800/16026], Loss: 0.0176\n",
      "Epoch [26/40], Step [15900/16026], Loss: 0.0159\n",
      "Epoch [26/40], Step [16000/16026], Loss: 0.0150\n",
      "Epoch [27/40], Step [100/16026], Loss: 0.0210\n",
      "Epoch [27/40], Step [200/16026], Loss: 0.0260\n",
      "Epoch [27/40], Step [300/16026], Loss: 0.0202\n",
      "Epoch [27/40], Step [400/16026], Loss: 0.0122\n",
      "Epoch [27/40], Step [500/16026], Loss: 0.0265\n",
      "Epoch [27/40], Step [600/16026], Loss: 0.0136\n",
      "Epoch [27/40], Step [700/16026], Loss: 0.0230\n",
      "Epoch [27/40], Step [800/16026], Loss: 0.0177\n",
      "Epoch [27/40], Step [900/16026], Loss: 0.0169\n",
      "Epoch [27/40], Step [1000/16026], Loss: 0.0274\n",
      "Epoch [27/40], Step [1100/16026], Loss: 0.0165\n",
      "Epoch [27/40], Step [1200/16026], Loss: 0.0158\n",
      "Epoch [27/40], Step [1300/16026], Loss: 0.0127\n",
      "Epoch [27/40], Step [1400/16026], Loss: 0.0159\n",
      "Epoch [27/40], Step [1500/16026], Loss: 0.0099\n",
      "Epoch [27/40], Step [1600/16026], Loss: 0.0246\n",
      "Epoch [27/40], Step [1700/16026], Loss: 0.0156\n",
      "Epoch [27/40], Step [1800/16026], Loss: 0.0171\n",
      "Epoch [27/40], Step [1900/16026], Loss: 0.0127\n",
      "Epoch [27/40], Step [2000/16026], Loss: 0.0212\n",
      "Epoch [27/40], Step [2100/16026], Loss: 0.0120\n",
      "Epoch [27/40], Step [2200/16026], Loss: 0.0144\n",
      "Epoch [27/40], Step [2300/16026], Loss: 0.0448\n",
      "Epoch [27/40], Step [2400/16026], Loss: 0.0192\n",
      "Epoch [27/40], Step [2500/16026], Loss: 0.0271\n",
      "Epoch [27/40], Step [2600/16026], Loss: 0.0198\n",
      "Epoch [27/40], Step [2700/16026], Loss: 0.0147\n",
      "Epoch [27/40], Step [2800/16026], Loss: 0.0188\n",
      "Epoch [27/40], Step [2900/16026], Loss: 0.0226\n",
      "Epoch [27/40], Step [3000/16026], Loss: 0.0223\n",
      "Epoch [27/40], Step [3100/16026], Loss: 0.0154\n",
      "Epoch [27/40], Step [3200/16026], Loss: 0.0221\n",
      "Epoch [27/40], Step [3300/16026], Loss: 0.0222\n",
      "Epoch [27/40], Step [3400/16026], Loss: 0.0221\n",
      "Epoch [27/40], Step [3500/16026], Loss: 0.0163\n",
      "Epoch [27/40], Step [3600/16026], Loss: 0.0180\n",
      "Epoch [27/40], Step [3700/16026], Loss: 0.0216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/40], Step [3800/16026], Loss: 0.0267\n",
      "Epoch [27/40], Step [3900/16026], Loss: 0.0096\n",
      "Epoch [27/40], Step [4000/16026], Loss: 0.0172\n",
      "Epoch [27/40], Step [4100/16026], Loss: 0.0128\n",
      "Epoch [27/40], Step [4200/16026], Loss: 0.0221\n",
      "Epoch [27/40], Step [4300/16026], Loss: 0.0203\n",
      "Epoch [27/40], Step [4400/16026], Loss: 0.0189\n",
      "Epoch [27/40], Step [4500/16026], Loss: 0.0204\n",
      "Epoch [27/40], Step [4600/16026], Loss: 0.0209\n",
      "Epoch [27/40], Step [4700/16026], Loss: 0.0221\n",
      "Epoch [27/40], Step [4800/16026], Loss: 0.0226\n",
      "Epoch [27/40], Step [4900/16026], Loss: 0.0233\n",
      "Epoch [27/40], Step [5000/16026], Loss: 0.0176\n",
      "Epoch [27/40], Step [5100/16026], Loss: 0.0252\n",
      "Epoch [27/40], Step [5200/16026], Loss: 0.0142\n",
      "Epoch [27/40], Step [5300/16026], Loss: 0.0236\n",
      "Epoch [27/40], Step [5400/16026], Loss: 0.0225\n",
      "Epoch [27/40], Step [5500/16026], Loss: 0.0219\n",
      "Epoch [27/40], Step [5600/16026], Loss: 0.0190\n",
      "Epoch [27/40], Step [5700/16026], Loss: 0.0157\n",
      "Epoch [27/40], Step [5800/16026], Loss: 0.0184\n",
      "Epoch [27/40], Step [5900/16026], Loss: 0.0455\n",
      "Epoch [27/40], Step [6000/16026], Loss: 0.0263\n",
      "Epoch [27/40], Step [6100/16026], Loss: 0.0199\n",
      "Epoch [27/40], Step [6200/16026], Loss: 0.0146\n",
      "Epoch [27/40], Step [6300/16026], Loss: 0.0320\n",
      "Epoch [27/40], Step [6400/16026], Loss: 0.0175\n",
      "Epoch [27/40], Step [6500/16026], Loss: 0.0263\n",
      "Epoch [27/40], Step [6600/16026], Loss: 0.0268\n",
      "Epoch [27/40], Step [6700/16026], Loss: 0.0280\n",
      "Epoch [27/40], Step [6800/16026], Loss: 0.0195\n",
      "Epoch [27/40], Step [6900/16026], Loss: 0.0272\n",
      "Epoch [27/40], Step [7000/16026], Loss: 0.0188\n",
      "Epoch [27/40], Step [7100/16026], Loss: 0.0197\n",
      "Epoch [27/40], Step [7200/16026], Loss: 0.0281\n",
      "Epoch [27/40], Step [7300/16026], Loss: 0.0183\n",
      "Epoch [27/40], Step [7400/16026], Loss: 0.0165\n",
      "Epoch [27/40], Step [7500/16026], Loss: 0.0147\n",
      "Epoch [27/40], Step [7600/16026], Loss: 0.0347\n",
      "Epoch [27/40], Step [7700/16026], Loss: 0.0332\n",
      "Epoch [27/40], Step [7800/16026], Loss: 0.0202\n",
      "Epoch [27/40], Step [7900/16026], Loss: 0.0399\n",
      "Epoch [27/40], Step [8000/16026], Loss: 0.0104\n",
      "Epoch [27/40], Step [8100/16026], Loss: 0.0254\n",
      "Epoch [27/40], Step [8200/16026], Loss: 0.0278\n",
      "Epoch [27/40], Step [8300/16026], Loss: 0.0270\n",
      "Epoch [27/40], Step [8400/16026], Loss: 0.0142\n",
      "Epoch [27/40], Step [8500/16026], Loss: 0.0207\n",
      "Epoch [27/40], Step [8600/16026], Loss: 0.0189\n",
      "Epoch [27/40], Step [8700/16026], Loss: 0.0211\n",
      "Epoch [27/40], Step [8800/16026], Loss: 0.0105\n",
      "Epoch [27/40], Step [8900/16026], Loss: 0.0199\n",
      "Epoch [27/40], Step [9000/16026], Loss: 0.0202\n",
      "Epoch [27/40], Step [9100/16026], Loss: 0.0199\n",
      "Epoch [27/40], Step [9200/16026], Loss: 0.0342\n",
      "Epoch [27/40], Step [9300/16026], Loss: 0.0203\n",
      "Epoch [27/40], Step [9400/16026], Loss: 0.0203\n",
      "Epoch [27/40], Step [9500/16026], Loss: 0.0237\n",
      "Epoch [27/40], Step [9600/16026], Loss: 0.0254\n",
      "Epoch [27/40], Step [9700/16026], Loss: 0.0179\n",
      "Epoch [27/40], Step [9800/16026], Loss: 0.0278\n",
      "Epoch [27/40], Step [9900/16026], Loss: 0.0131\n",
      "Epoch [27/40], Step [10000/16026], Loss: 0.0220\n",
      "Epoch [27/40], Step [10100/16026], Loss: 0.0156\n",
      "Epoch [27/40], Step [10200/16026], Loss: 0.0231\n",
      "Epoch [27/40], Step [10300/16026], Loss: 0.0192\n",
      "Epoch [27/40], Step [10400/16026], Loss: 0.0120\n",
      "Epoch [27/40], Step [10500/16026], Loss: 0.0187\n",
      "Epoch [27/40], Step [10600/16026], Loss: 0.0232\n",
      "Epoch [27/40], Step [10700/16026], Loss: 0.0211\n",
      "Epoch [27/40], Step [10800/16026], Loss: 0.0219\n",
      "Epoch [27/40], Step [10900/16026], Loss: 0.0249\n",
      "Epoch [27/40], Step [11000/16026], Loss: 0.0242\n",
      "Epoch [27/40], Step [11100/16026], Loss: 0.0226\n",
      "Epoch [27/40], Step [11200/16026], Loss: 0.0218\n",
      "Epoch [27/40], Step [11300/16026], Loss: 0.0137\n",
      "Epoch [27/40], Step [11400/16026], Loss: 0.0184\n",
      "Epoch [27/40], Step [11500/16026], Loss: 0.0428\n",
      "Epoch [27/40], Step [11600/16026], Loss: 0.0178\n",
      "Epoch [27/40], Step [11700/16026], Loss: 0.0215\n",
      "Epoch [27/40], Step [11800/16026], Loss: 0.0125\n",
      "Epoch [27/40], Step [11900/16026], Loss: 0.0192\n",
      "Epoch [27/40], Step [12000/16026], Loss: 0.0165\n",
      "Epoch [27/40], Step [12100/16026], Loss: 0.0148\n",
      "Epoch [27/40], Step [12200/16026], Loss: 0.0229\n",
      "Epoch [27/40], Step [12300/16026], Loss: 0.0166\n",
      "Epoch [27/40], Step [12400/16026], Loss: 0.0138\n",
      "Epoch [27/40], Step [12500/16026], Loss: 0.0183\n",
      "Epoch [27/40], Step [12600/16026], Loss: 0.0207\n",
      "Epoch [27/40], Step [12700/16026], Loss: 0.0394\n",
      "Epoch [27/40], Step [12800/16026], Loss: 0.0145\n",
      "Epoch [27/40], Step [12900/16026], Loss: 0.0137\n",
      "Epoch [27/40], Step [13000/16026], Loss: 0.0310\n",
      "Epoch [27/40], Step [13100/16026], Loss: 0.0277\n",
      "Epoch [27/40], Step [13200/16026], Loss: 0.0314\n",
      "Epoch [27/40], Step [13300/16026], Loss: 0.0071\n",
      "Epoch [27/40], Step [13400/16026], Loss: 0.0128\n",
      "Epoch [27/40], Step [13500/16026], Loss: 0.0209\n",
      "Epoch [27/40], Step [13600/16026], Loss: 0.0152\n",
      "Epoch [27/40], Step [13700/16026], Loss: 0.0143\n",
      "Epoch [27/40], Step [13800/16026], Loss: 0.0180\n",
      "Epoch [27/40], Step [13900/16026], Loss: 0.0196\n",
      "Epoch [27/40], Step [14000/16026], Loss: 0.0305\n",
      "Epoch [27/40], Step [14100/16026], Loss: 0.0182\n",
      "Epoch [27/40], Step [14200/16026], Loss: 0.0132\n",
      "Epoch [27/40], Step [14300/16026], Loss: 0.0228\n",
      "Epoch [27/40], Step [14400/16026], Loss: 0.0199\n",
      "Epoch [27/40], Step [14500/16026], Loss: 0.0147\n",
      "Epoch [27/40], Step [14600/16026], Loss: 0.0241\n",
      "Epoch [27/40], Step [14700/16026], Loss: 0.0157\n",
      "Epoch [27/40], Step [14800/16026], Loss: 0.0152\n",
      "Epoch [27/40], Step [14900/16026], Loss: 0.0151\n",
      "Epoch [27/40], Step [15000/16026], Loss: 0.0183\n",
      "Epoch [27/40], Step [15100/16026], Loss: 0.0215\n",
      "Epoch [27/40], Step [15200/16026], Loss: 0.0146\n",
      "Epoch [27/40], Step [15300/16026], Loss: 0.0177\n",
      "Epoch [27/40], Step [15400/16026], Loss: 0.0164\n",
      "Epoch [27/40], Step [15500/16026], Loss: 0.0232\n",
      "Epoch [27/40], Step [15600/16026], Loss: 0.0122\n",
      "Epoch [27/40], Step [15700/16026], Loss: 0.0164\n",
      "Epoch [27/40], Step [15800/16026], Loss: 0.0165\n",
      "Epoch [27/40], Step [15900/16026], Loss: 0.0156\n",
      "Epoch [27/40], Step [16000/16026], Loss: 0.0150\n",
      "Epoch [28/40], Step [100/16026], Loss: 0.0203\n",
      "Epoch [28/40], Step [200/16026], Loss: 0.0137\n",
      "Epoch [28/40], Step [300/16026], Loss: 0.0138\n",
      "Epoch [28/40], Step [400/16026], Loss: 0.0224\n",
      "Epoch [28/40], Step [500/16026], Loss: 0.0187\n",
      "Epoch [28/40], Step [600/16026], Loss: 0.0225\n",
      "Epoch [28/40], Step [700/16026], Loss: 0.0138\n",
      "Epoch [28/40], Step [800/16026], Loss: 0.0285\n",
      "Epoch [28/40], Step [900/16026], Loss: 0.0228\n",
      "Epoch [28/40], Step [1000/16026], Loss: 0.0190\n",
      "Epoch [28/40], Step [1100/16026], Loss: 0.0127\n",
      "Epoch [28/40], Step [1200/16026], Loss: 0.0212\n",
      "Epoch [28/40], Step [1300/16026], Loss: 0.0167\n",
      "Epoch [28/40], Step [1400/16026], Loss: 0.0113\n",
      "Epoch [28/40], Step [1500/16026], Loss: 0.0181\n",
      "Epoch [28/40], Step [1600/16026], Loss: 0.0197\n",
      "Epoch [28/40], Step [1700/16026], Loss: 0.0206\n",
      "Epoch [28/40], Step [1800/16026], Loss: 0.0285\n",
      "Epoch [28/40], Step [1900/16026], Loss: 0.0158\n",
      "Epoch [28/40], Step [2000/16026], Loss: 0.0253\n",
      "Epoch [28/40], Step [2100/16026], Loss: 0.0163\n",
      "Epoch [28/40], Step [2200/16026], Loss: 0.0220\n",
      "Epoch [28/40], Step [2300/16026], Loss: 0.0170\n",
      "Epoch [28/40], Step [2400/16026], Loss: 0.0154\n",
      "Epoch [28/40], Step [2500/16026], Loss: 0.0200\n",
      "Epoch [28/40], Step [2600/16026], Loss: 0.0189\n",
      "Epoch [28/40], Step [2700/16026], Loss: 0.0133\n",
      "Epoch [28/40], Step [2800/16026], Loss: 0.0350\n",
      "Epoch [28/40], Step [2900/16026], Loss: 0.0225\n",
      "Epoch [28/40], Step [3000/16026], Loss: 0.0182\n",
      "Epoch [28/40], Step [3100/16026], Loss: 0.0346\n",
      "Epoch [28/40], Step [3200/16026], Loss: 0.0267\n",
      "Epoch [28/40], Step [3300/16026], Loss: 0.0530\n",
      "Epoch [28/40], Step [3400/16026], Loss: 0.0246\n",
      "Epoch [28/40], Step [3500/16026], Loss: 0.0246\n",
      "Epoch [28/40], Step [3600/16026], Loss: 0.0121\n",
      "Epoch [28/40], Step [3700/16026], Loss: 0.0107\n",
      "Epoch [28/40], Step [3800/16026], Loss: 0.0190\n",
      "Epoch [28/40], Step [3900/16026], Loss: 0.0153\n",
      "Epoch [28/40], Step [4000/16026], Loss: 0.0182\n",
      "Epoch [28/40], Step [4100/16026], Loss: 0.0238\n",
      "Epoch [28/40], Step [4200/16026], Loss: 0.0143\n",
      "Epoch [28/40], Step [4300/16026], Loss: 0.0145\n",
      "Epoch [28/40], Step [4400/16026], Loss: 0.0274\n",
      "Epoch [28/40], Step [4500/16026], Loss: 0.0154\n",
      "Epoch [28/40], Step [4600/16026], Loss: 0.0186\n",
      "Epoch [28/40], Step [4700/16026], Loss: 0.0154\n",
      "Epoch [28/40], Step [4800/16026], Loss: 0.0699\n",
      "Epoch [28/40], Step [4900/16026], Loss: 0.0186\n",
      "Epoch [28/40], Step [5000/16026], Loss: 0.0216\n",
      "Epoch [28/40], Step [5100/16026], Loss: 0.0551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/40], Step [5200/16026], Loss: 0.0169\n",
      "Epoch [28/40], Step [5300/16026], Loss: 0.0182\n",
      "Epoch [28/40], Step [5400/16026], Loss: 0.0220\n",
      "Epoch [28/40], Step [5500/16026], Loss: 0.0233\n",
      "Epoch [28/40], Step [5600/16026], Loss: 0.0338\n",
      "Epoch [28/40], Step [5700/16026], Loss: 0.0172\n",
      "Epoch [28/40], Step [5800/16026], Loss: 0.0280\n",
      "Epoch [28/40], Step [5900/16026], Loss: 0.0205\n",
      "Epoch [28/40], Step [6000/16026], Loss: 0.0207\n",
      "Epoch [28/40], Step [6100/16026], Loss: 0.0151\n",
      "Epoch [28/40], Step [6200/16026], Loss: 0.0104\n",
      "Epoch [28/40], Step [6300/16026], Loss: 0.0110\n",
      "Epoch [28/40], Step [6400/16026], Loss: 0.0211\n",
      "Epoch [28/40], Step [6500/16026], Loss: 0.0290\n",
      "Epoch [28/40], Step [6600/16026], Loss: 0.0214\n",
      "Epoch [28/40], Step [6700/16026], Loss: 0.0177\n",
      "Epoch [28/40], Step [6800/16026], Loss: 0.0250\n",
      "Epoch [28/40], Step [6900/16026], Loss: 0.0275\n",
      "Epoch [28/40], Step [7000/16026], Loss: 0.0145\n",
      "Epoch [28/40], Step [7100/16026], Loss: 0.0206\n",
      "Epoch [28/40], Step [7200/16026], Loss: 0.0185\n",
      "Epoch [28/40], Step [7300/16026], Loss: 0.0208\n",
      "Epoch [28/40], Step [7400/16026], Loss: 0.0132\n",
      "Epoch [28/40], Step [7500/16026], Loss: 0.0216\n",
      "Epoch [28/40], Step [7600/16026], Loss: 0.0222\n",
      "Epoch [28/40], Step [7700/16026], Loss: 0.0159\n",
      "Epoch [28/40], Step [7800/16026], Loss: 0.0245\n",
      "Epoch [28/40], Step [7900/16026], Loss: 0.0216\n",
      "Epoch [28/40], Step [8000/16026], Loss: 0.0156\n",
      "Epoch [28/40], Step [8100/16026], Loss: 0.0124\n",
      "Epoch [28/40], Step [8200/16026], Loss: 0.0170\n",
      "Epoch [28/40], Step [8300/16026], Loss: 0.0154\n",
      "Epoch [28/40], Step [8400/16026], Loss: 0.0193\n",
      "Epoch [28/40], Step [8500/16026], Loss: 0.0135\n",
      "Epoch [28/40], Step [8600/16026], Loss: 0.0182\n",
      "Epoch [28/40], Step [8700/16026], Loss: 0.0183\n",
      "Epoch [28/40], Step [8800/16026], Loss: 0.0210\n",
      "Epoch [28/40], Step [8900/16026], Loss: 0.0303\n",
      "Epoch [28/40], Step [9000/16026], Loss: 0.0343\n",
      "Epoch [28/40], Step [9100/16026], Loss: 0.0208\n",
      "Epoch [28/40], Step [9200/16026], Loss: 0.0158\n",
      "Epoch [28/40], Step [9300/16026], Loss: 0.0175\n",
      "Epoch [28/40], Step [9400/16026], Loss: 0.0347\n",
      "Epoch [28/40], Step [9500/16026], Loss: 0.0222\n",
      "Epoch [28/40], Step [9600/16026], Loss: 0.0216\n",
      "Epoch [28/40], Step [9700/16026], Loss: 0.0164\n",
      "Epoch [28/40], Step [9800/16026], Loss: 0.0196\n",
      "Epoch [28/40], Step [9900/16026], Loss: 0.0219\n",
      "Epoch [28/40], Step [10000/16026], Loss: 0.0241\n",
      "Epoch [28/40], Step [10100/16026], Loss: 0.0191\n",
      "Epoch [28/40], Step [10200/16026], Loss: 0.0342\n",
      "Epoch [28/40], Step [10300/16026], Loss: 0.0208\n",
      "Epoch [28/40], Step [10400/16026], Loss: 0.0204\n",
      "Epoch [28/40], Step [10500/16026], Loss: 0.0208\n",
      "Epoch [28/40], Step [10600/16026], Loss: 0.0244\n",
      "Epoch [28/40], Step [10700/16026], Loss: 0.0277\n",
      "Epoch [28/40], Step [10800/16026], Loss: 0.0210\n",
      "Epoch [28/40], Step [10900/16026], Loss: 0.0286\n",
      "Epoch [28/40], Step [11000/16026], Loss: 0.0209\n",
      "Epoch [28/40], Step [11100/16026], Loss: 0.0194\n",
      "Epoch [28/40], Step [11200/16026], Loss: 0.0259\n",
      "Epoch [28/40], Step [11300/16026], Loss: 0.0215\n",
      "Epoch [28/40], Step [11400/16026], Loss: 0.0173\n",
      "Epoch [28/40], Step [11500/16026], Loss: 0.0261\n",
      "Epoch [28/40], Step [11600/16026], Loss: 0.0146\n",
      "Epoch [28/40], Step [11700/16026], Loss: 0.0180\n",
      "Epoch [28/40], Step [11800/16026], Loss: 0.0186\n",
      "Epoch [28/40], Step [11900/16026], Loss: 0.0177\n",
      "Epoch [28/40], Step [12000/16026], Loss: 0.0255\n",
      "Epoch [28/40], Step [12100/16026], Loss: 0.0129\n",
      "Epoch [28/40], Step [12200/16026], Loss: 0.0215\n",
      "Epoch [28/40], Step [12300/16026], Loss: 0.0167\n",
      "Epoch [28/40], Step [12400/16026], Loss: 0.0223\n",
      "Epoch [28/40], Step [12500/16026], Loss: 0.0203\n",
      "Epoch [28/40], Step [12600/16026], Loss: 0.0184\n",
      "Epoch [28/40], Step [12700/16026], Loss: 0.0319\n",
      "Epoch [28/40], Step [12800/16026], Loss: 0.0107\n",
      "Epoch [28/40], Step [12900/16026], Loss: 0.0228\n",
      "Epoch [28/40], Step [13000/16026], Loss: 0.0184\n",
      "Epoch [28/40], Step [13100/16026], Loss: 0.0181\n",
      "Epoch [28/40], Step [13200/16026], Loss: 0.0220\n",
      "Epoch [28/40], Step [13300/16026], Loss: 0.0156\n",
      "Epoch [28/40], Step [13400/16026], Loss: 0.0202\n",
      "Epoch [28/40], Step [13500/16026], Loss: 0.0189\n",
      "Epoch [28/40], Step [13600/16026], Loss: 0.0081\n",
      "Epoch [28/40], Step [13700/16026], Loss: 0.0175\n",
      "Epoch [28/40], Step [13800/16026], Loss: 0.0278\n",
      "Epoch [28/40], Step [13900/16026], Loss: 0.0365\n",
      "Epoch [28/40], Step [14000/16026], Loss: 0.0234\n",
      "Epoch [28/40], Step [14100/16026], Loss: 0.0209\n",
      "Epoch [28/40], Step [14200/16026], Loss: 0.0136\n",
      "Epoch [28/40], Step [14300/16026], Loss: 0.0209\n",
      "Epoch [28/40], Step [14400/16026], Loss: 0.0175\n",
      "Epoch [28/40], Step [14500/16026], Loss: 0.0189\n",
      "Epoch [28/40], Step [14600/16026], Loss: 0.0218\n",
      "Epoch [28/40], Step [14700/16026], Loss: 0.0118\n",
      "Epoch [28/40], Step [14800/16026], Loss: 0.0192\n",
      "Epoch [28/40], Step [14900/16026], Loss: 0.0317\n",
      "Epoch [28/40], Step [15000/16026], Loss: 0.0140\n",
      "Epoch [28/40], Step [15100/16026], Loss: 0.0222\n",
      "Epoch [28/40], Step [15200/16026], Loss: 0.0118\n",
      "Epoch [28/40], Step [15300/16026], Loss: 0.0113\n",
      "Epoch [28/40], Step [15400/16026], Loss: 0.0314\n",
      "Epoch [28/40], Step [15500/16026], Loss: 0.0148\n",
      "Epoch [28/40], Step [15600/16026], Loss: 0.0120\n",
      "Epoch [28/40], Step [15700/16026], Loss: 0.0121\n",
      "Epoch [28/40], Step [15800/16026], Loss: 0.0206\n",
      "Epoch [28/40], Step [15900/16026], Loss: 0.0136\n",
      "Epoch [28/40], Step [16000/16026], Loss: 0.0135\n",
      "Epoch [29/40], Step [100/16026], Loss: 0.0233\n",
      "Epoch [29/40], Step [200/16026], Loss: 0.0216\n",
      "Epoch [29/40], Step [300/16026], Loss: 0.0285\n",
      "Epoch [29/40], Step [400/16026], Loss: 0.0189\n",
      "Epoch [29/40], Step [500/16026], Loss: 0.0161\n",
      "Epoch [29/40], Step [600/16026], Loss: 0.0289\n",
      "Epoch [29/40], Step [700/16026], Loss: 0.0269\n",
      "Epoch [29/40], Step [800/16026], Loss: 0.0232\n",
      "Epoch [29/40], Step [900/16026], Loss: 0.0266\n",
      "Epoch [29/40], Step [1000/16026], Loss: 0.0142\n",
      "Epoch [29/40], Step [1100/16026], Loss: 0.0177\n",
      "Epoch [29/40], Step [1200/16026], Loss: 0.0166\n",
      "Epoch [29/40], Step [1300/16026], Loss: 0.0248\n",
      "Epoch [29/40], Step [1400/16026], Loss: 0.0196\n",
      "Epoch [29/40], Step [1500/16026], Loss: 0.0239\n",
      "Epoch [29/40], Step [1600/16026], Loss: 0.0159\n",
      "Epoch [29/40], Step [1700/16026], Loss: 0.0281\n",
      "Epoch [29/40], Step [1800/16026], Loss: 0.0159\n",
      "Epoch [29/40], Step [1900/16026], Loss: 0.0160\n",
      "Epoch [29/40], Step [2000/16026], Loss: 0.0237\n",
      "Epoch [29/40], Step [2100/16026], Loss: 0.0170\n",
      "Epoch [29/40], Step [2200/16026], Loss: 0.0190\n",
      "Epoch [29/40], Step [2300/16026], Loss: 0.0216\n",
      "Epoch [29/40], Step [2400/16026], Loss: 0.0248\n",
      "Epoch [29/40], Step [2500/16026], Loss: 0.0196\n",
      "Epoch [29/40], Step [2600/16026], Loss: 0.0111\n",
      "Epoch [29/40], Step [2700/16026], Loss: 0.0200\n",
      "Epoch [29/40], Step [2800/16026], Loss: 0.0194\n",
      "Epoch [29/40], Step [2900/16026], Loss: 0.0231\n",
      "Epoch [29/40], Step [3000/16026], Loss: 0.0169\n",
      "Epoch [29/40], Step [3100/16026], Loss: 0.0190\n",
      "Epoch [29/40], Step [3200/16026], Loss: 0.0292\n",
      "Epoch [29/40], Step [3300/16026], Loss: 0.0197\n",
      "Epoch [29/40], Step [3400/16026], Loss: 0.0179\n",
      "Epoch [29/40], Step [3500/16026], Loss: 0.0182\n",
      "Epoch [29/40], Step [3600/16026], Loss: 0.0274\n",
      "Epoch [29/40], Step [3700/16026], Loss: 0.0216\n",
      "Epoch [29/40], Step [3800/16026], Loss: 0.0159\n",
      "Epoch [29/40], Step [3900/16026], Loss: 0.0179\n",
      "Epoch [29/40], Step [4000/16026], Loss: 0.0196\n",
      "Epoch [29/40], Step [4100/16026], Loss: 0.0199\n",
      "Epoch [29/40], Step [4200/16026], Loss: 0.0387\n",
      "Epoch [29/40], Step [4300/16026], Loss: 0.0203\n",
      "Epoch [29/40], Step [4400/16026], Loss: 0.0223\n",
      "Epoch [29/40], Step [4500/16026], Loss: 0.0234\n",
      "Epoch [29/40], Step [4600/16026], Loss: 0.0171\n",
      "Epoch [29/40], Step [4700/16026], Loss: 0.0180\n",
      "Epoch [29/40], Step [4800/16026], Loss: 0.0162\n",
      "Epoch [29/40], Step [4900/16026], Loss: 0.0335\n",
      "Epoch [29/40], Step [5000/16026], Loss: 0.0238\n",
      "Epoch [29/40], Step [5100/16026], Loss: 0.0142\n",
      "Epoch [29/40], Step [5200/16026], Loss: 0.0094\n",
      "Epoch [29/40], Step [5300/16026], Loss: 0.0097\n",
      "Epoch [29/40], Step [5400/16026], Loss: 0.0182\n",
      "Epoch [29/40], Step [5500/16026], Loss: 0.0217\n",
      "Epoch [29/40], Step [5600/16026], Loss: 0.0166\n",
      "Epoch [29/40], Step [5700/16026], Loss: 0.0148\n",
      "Epoch [29/40], Step [5800/16026], Loss: 0.0273\n",
      "Epoch [29/40], Step [5900/16026], Loss: 0.0216\n",
      "Epoch [29/40], Step [6000/16026], Loss: 0.0323\n",
      "Epoch [29/40], Step [6100/16026], Loss: 0.0268\n",
      "Epoch [29/40], Step [6200/16026], Loss: 0.0212\n",
      "Epoch [29/40], Step [6300/16026], Loss: 0.0175\n",
      "Epoch [29/40], Step [6400/16026], Loss: 0.0246\n",
      "Epoch [29/40], Step [6500/16026], Loss: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/40], Step [6600/16026], Loss: 0.0151\n",
      "Epoch [29/40], Step [6700/16026], Loss: 0.0187\n",
      "Epoch [29/40], Step [6800/16026], Loss: 0.0188\n",
      "Epoch [29/40], Step [6900/16026], Loss: 0.0239\n",
      "Epoch [29/40], Step [7000/16026], Loss: 0.0164\n",
      "Epoch [29/40], Step [7100/16026], Loss: 0.0324\n",
      "Epoch [29/40], Step [7200/16026], Loss: 0.0160\n",
      "Epoch [29/40], Step [7300/16026], Loss: 0.0326\n",
      "Epoch [29/40], Step [7400/16026], Loss: 0.0116\n",
      "Epoch [29/40], Step [7500/16026], Loss: 0.0243\n",
      "Epoch [29/40], Step [7600/16026], Loss: 0.0271\n",
      "Epoch [29/40], Step [7700/16026], Loss: 0.0151\n",
      "Epoch [29/40], Step [7800/16026], Loss: 0.0194\n",
      "Epoch [29/40], Step [7900/16026], Loss: 0.0163\n",
      "Epoch [29/40], Step [8000/16026], Loss: 0.0117\n",
      "Epoch [29/40], Step [8100/16026], Loss: 0.0319\n",
      "Epoch [29/40], Step [8200/16026], Loss: 0.0230\n",
      "Epoch [29/40], Step [8300/16026], Loss: 0.0224\n",
      "Epoch [29/40], Step [8400/16026], Loss: 0.0166\n",
      "Epoch [29/40], Step [8500/16026], Loss: 0.0260\n",
      "Epoch [29/40], Step [8600/16026], Loss: 0.0086\n",
      "Epoch [29/40], Step [8700/16026], Loss: 0.0218\n",
      "Epoch [29/40], Step [8800/16026], Loss: 0.0246\n",
      "Epoch [29/40], Step [8900/16026], Loss: 0.0237\n",
      "Epoch [29/40], Step [9000/16026], Loss: 0.0214\n",
      "Epoch [29/40], Step [9100/16026], Loss: 0.0203\n",
      "Epoch [29/40], Step [9200/16026], Loss: 0.0260\n",
      "Epoch [29/40], Step [9300/16026], Loss: 0.0288\n",
      "Epoch [29/40], Step [9400/16026], Loss: 0.0252\n",
      "Epoch [29/40], Step [9500/16026], Loss: 0.0122\n",
      "Epoch [29/40], Step [9600/16026], Loss: 0.0294\n",
      "Epoch [29/40], Step [9700/16026], Loss: 0.0189\n",
      "Epoch [29/40], Step [9800/16026], Loss: 0.0130\n",
      "Epoch [29/40], Step [9900/16026], Loss: 0.0146\n",
      "Epoch [29/40], Step [10000/16026], Loss: 0.0191\n",
      "Epoch [29/40], Step [10100/16026], Loss: 0.0185\n",
      "Epoch [29/40], Step [10200/16026], Loss: 0.0210\n",
      "Epoch [29/40], Step [10300/16026], Loss: 0.0130\n",
      "Epoch [29/40], Step [10400/16026], Loss: 0.0219\n",
      "Epoch [29/40], Step [10500/16026], Loss: 0.0321\n",
      "Epoch [29/40], Step [10600/16026], Loss: 0.0182\n",
      "Epoch [29/40], Step [10700/16026], Loss: 0.0245\n",
      "Epoch [29/40], Step [10800/16026], Loss: 0.0336\n",
      "Epoch [29/40], Step [10900/16026], Loss: 0.0190\n",
      "Epoch [29/40], Step [11000/16026], Loss: 0.0183\n",
      "Epoch [29/40], Step [11100/16026], Loss: 0.0191\n",
      "Epoch [29/40], Step [11200/16026], Loss: 0.0146\n",
      "Epoch [29/40], Step [11300/16026], Loss: 0.0196\n",
      "Epoch [29/40], Step [11400/16026], Loss: 0.0239\n",
      "Epoch [29/40], Step [11500/16026], Loss: 0.0220\n",
      "Epoch [29/40], Step [11600/16026], Loss: 0.0191\n",
      "Epoch [29/40], Step [11700/16026], Loss: 0.0258\n",
      "Epoch [29/40], Step [11800/16026], Loss: 0.0109\n",
      "Epoch [29/40], Step [11900/16026], Loss: 0.0198\n",
      "Epoch [29/40], Step [12000/16026], Loss: 0.0212\n",
      "Epoch [29/40], Step [12100/16026], Loss: 0.0225\n",
      "Epoch [29/40], Step [12200/16026], Loss: 0.0240\n",
      "Epoch [29/40], Step [12300/16026], Loss: 0.0213\n",
      "Epoch [29/40], Step [12400/16026], Loss: 0.0249\n",
      "Epoch [29/40], Step [12500/16026], Loss: 0.0283\n",
      "Epoch [29/40], Step [12600/16026], Loss: 0.0846\n",
      "Epoch [29/40], Step [12700/16026], Loss: 0.0186\n",
      "Epoch [29/40], Step [12800/16026], Loss: 0.0164\n",
      "Epoch [29/40], Step [12900/16026], Loss: 0.0181\n",
      "Epoch [29/40], Step [13000/16026], Loss: 0.0148\n",
      "Epoch [29/40], Step [13100/16026], Loss: 0.0195\n",
      "Epoch [29/40], Step [13200/16026], Loss: 0.0171\n",
      "Epoch [29/40], Step [13300/16026], Loss: 0.0170\n",
      "Epoch [29/40], Step [13400/16026], Loss: 0.0154\n",
      "Epoch [29/40], Step [13500/16026], Loss: 0.0231\n",
      "Epoch [29/40], Step [13600/16026], Loss: 0.0247\n",
      "Epoch [29/40], Step [13700/16026], Loss: 0.0142\n",
      "Epoch [29/40], Step [13800/16026], Loss: 0.0613\n",
      "Epoch [29/40], Step [13900/16026], Loss: 0.0245\n",
      "Epoch [29/40], Step [14000/16026], Loss: 0.0173\n",
      "Epoch [29/40], Step [14100/16026], Loss: 0.0149\n",
      "Epoch [29/40], Step [14200/16026], Loss: 0.0261\n",
      "Epoch [29/40], Step [14300/16026], Loss: 0.0242\n",
      "Epoch [29/40], Step [14400/16026], Loss: 0.0195\n",
      "Epoch [29/40], Step [14500/16026], Loss: 0.0247\n",
      "Epoch [29/40], Step [14600/16026], Loss: 0.0254\n",
      "Epoch [29/40], Step [14700/16026], Loss: 0.0102\n",
      "Epoch [29/40], Step [14800/16026], Loss: 0.0195\n",
      "Epoch [29/40], Step [14900/16026], Loss: 0.0211\n",
      "Epoch [29/40], Step [15000/16026], Loss: 0.0188\n",
      "Epoch [29/40], Step [15100/16026], Loss: 0.0269\n",
      "Epoch [29/40], Step [15200/16026], Loss: 0.0189\n",
      "Epoch [29/40], Step [15300/16026], Loss: 0.0132\n",
      "Epoch [29/40], Step [15400/16026], Loss: 0.0152\n",
      "Epoch [29/40], Step [15500/16026], Loss: 0.0365\n",
      "Epoch [29/40], Step [15600/16026], Loss: 0.0582\n",
      "Epoch [29/40], Step [15700/16026], Loss: 0.0339\n",
      "Epoch [29/40], Step [15800/16026], Loss: 0.0313\n",
      "Epoch [29/40], Step [15900/16026], Loss: 0.0235\n",
      "Epoch [29/40], Step [16000/16026], Loss: 0.0208\n",
      "Epoch [30/40], Step [100/16026], Loss: 0.0223\n",
      "Epoch [30/40], Step [200/16026], Loss: 0.0170\n",
      "Epoch [30/40], Step [300/16026], Loss: 0.0163\n",
      "Epoch [30/40], Step [400/16026], Loss: 0.0273\n",
      "Epoch [30/40], Step [500/16026], Loss: 0.0294\n",
      "Epoch [30/40], Step [600/16026], Loss: 0.0217\n",
      "Epoch [30/40], Step [700/16026], Loss: 0.0195\n",
      "Epoch [30/40], Step [800/16026], Loss: 0.0178\n",
      "Epoch [30/40], Step [900/16026], Loss: 0.0209\n",
      "Epoch [30/40], Step [1000/16026], Loss: 0.0221\n",
      "Epoch [30/40], Step [1100/16026], Loss: 0.0123\n",
      "Epoch [30/40], Step [1200/16026], Loss: 0.0189\n",
      "Epoch [30/40], Step [1300/16026], Loss: 0.0198\n",
      "Epoch [30/40], Step [1400/16026], Loss: 0.0278\n",
      "Epoch [30/40], Step [1500/16026], Loss: 0.0129\n",
      "Epoch [30/40], Step [1600/16026], Loss: 0.0326\n",
      "Epoch [30/40], Step [1700/16026], Loss: 0.0202\n",
      "Epoch [30/40], Step [1800/16026], Loss: 0.0328\n",
      "Epoch [30/40], Step [1900/16026], Loss: 0.0209\n",
      "Epoch [30/40], Step [2000/16026], Loss: 0.0203\n",
      "Epoch [30/40], Step [2100/16026], Loss: 0.0147\n",
      "Epoch [30/40], Step [2200/16026], Loss: 0.0299\n",
      "Epoch [30/40], Step [2300/16026], Loss: 0.0145\n",
      "Epoch [30/40], Step [2400/16026], Loss: 0.0225\n",
      "Epoch [30/40], Step [2500/16026], Loss: 0.0251\n",
      "Epoch [30/40], Step [2600/16026], Loss: 0.0230\n",
      "Epoch [30/40], Step [2700/16026], Loss: 0.0164\n",
      "Epoch [30/40], Step [2800/16026], Loss: 0.0166\n",
      "Epoch [30/40], Step [2900/16026], Loss: 0.0157\n",
      "Epoch [30/40], Step [3000/16026], Loss: 0.0194\n",
      "Epoch [30/40], Step [3100/16026], Loss: 0.0218\n",
      "Epoch [30/40], Step [3200/16026], Loss: 0.0185\n",
      "Epoch [30/40], Step [3300/16026], Loss: 0.0302\n",
      "Epoch [30/40], Step [3400/16026], Loss: 0.0309\n",
      "Epoch [30/40], Step [3500/16026], Loss: 0.0147\n",
      "Epoch [30/40], Step [3600/16026], Loss: 0.0300\n",
      "Epoch [30/40], Step [3700/16026], Loss: 0.0214\n",
      "Epoch [30/40], Step [3800/16026], Loss: 0.0184\n",
      "Epoch [30/40], Step [3900/16026], Loss: 0.0120\n",
      "Epoch [30/40], Step [4000/16026], Loss: 0.0186\n",
      "Epoch [30/40], Step [4100/16026], Loss: 0.0119\n",
      "Epoch [30/40], Step [4200/16026], Loss: 0.0194\n",
      "Epoch [30/40], Step [4300/16026], Loss: 0.0222\n",
      "Epoch [30/40], Step [4400/16026], Loss: 0.0157\n",
      "Epoch [30/40], Step [4500/16026], Loss: 0.0229\n",
      "Epoch [30/40], Step [4600/16026], Loss: 0.0381\n",
      "Epoch [30/40], Step [4700/16026], Loss: 0.0260\n",
      "Epoch [30/40], Step [4800/16026], Loss: 0.0191\n",
      "Epoch [30/40], Step [4900/16026], Loss: 0.0201\n",
      "Epoch [30/40], Step [5000/16026], Loss: 0.0181\n",
      "Epoch [30/40], Step [5100/16026], Loss: 0.0214\n",
      "Epoch [30/40], Step [5200/16026], Loss: 0.0151\n",
      "Epoch [30/40], Step [5300/16026], Loss: 0.0195\n",
      "Epoch [30/40], Step [5400/16026], Loss: 0.0238\n",
      "Epoch [30/40], Step [5500/16026], Loss: 0.0242\n",
      "Epoch [30/40], Step [5600/16026], Loss: 0.0218\n",
      "Epoch [30/40], Step [5700/16026], Loss: 0.0147\n",
      "Epoch [30/40], Step [5800/16026], Loss: 0.0209\n",
      "Epoch [30/40], Step [5900/16026], Loss: 0.0183\n",
      "Epoch [30/40], Step [6000/16026], Loss: 0.0221\n",
      "Epoch [30/40], Step [6100/16026], Loss: 0.0209\n",
      "Epoch [30/40], Step [6200/16026], Loss: 0.0209\n",
      "Epoch [30/40], Step [6300/16026], Loss: 0.0222\n",
      "Epoch [30/40], Step [6400/16026], Loss: 0.0185\n",
      "Epoch [30/40], Step [6500/16026], Loss: 0.0271\n",
      "Epoch [30/40], Step [6600/16026], Loss: 0.0236\n",
      "Epoch [30/40], Step [6700/16026], Loss: 0.0213\n",
      "Epoch [30/40], Step [6800/16026], Loss: 0.0211\n",
      "Epoch [30/40], Step [6900/16026], Loss: 0.0124\n",
      "Epoch [30/40], Step [7000/16026], Loss: 0.0253\n",
      "Epoch [30/40], Step [7100/16026], Loss: 0.0201\n",
      "Epoch [30/40], Step [7200/16026], Loss: 0.0207\n",
      "Epoch [30/40], Step [7300/16026], Loss: 0.0161\n",
      "Epoch [30/40], Step [7400/16026], Loss: 0.0177\n",
      "Epoch [30/40], Step [7500/16026], Loss: 0.0107\n",
      "Epoch [30/40], Step [7600/16026], Loss: 0.0195\n",
      "Epoch [30/40], Step [7700/16026], Loss: 0.0270\n",
      "Epoch [30/40], Step [7800/16026], Loss: 0.0124\n",
      "Epoch [30/40], Step [7900/16026], Loss: 0.0330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/40], Step [8000/16026], Loss: 0.0283\n",
      "Epoch [30/40], Step [8100/16026], Loss: 0.0141\n",
      "Epoch [30/40], Step [8200/16026], Loss: 0.0183\n",
      "Epoch [30/40], Step [8300/16026], Loss: 0.0126\n",
      "Epoch [30/40], Step [8400/16026], Loss: 0.0176\n",
      "Epoch [30/40], Step [8500/16026], Loss: 0.0173\n",
      "Epoch [30/40], Step [8600/16026], Loss: 0.0211\n",
      "Epoch [30/40], Step [8700/16026], Loss: 0.0141\n",
      "Epoch [30/40], Step [8800/16026], Loss: 0.0274\n",
      "Epoch [30/40], Step [8900/16026], Loss: 0.0237\n",
      "Epoch [30/40], Step [9000/16026], Loss: 0.0209\n",
      "Epoch [30/40], Step [9100/16026], Loss: 0.0319\n",
      "Epoch [30/40], Step [9200/16026], Loss: 0.0259\n",
      "Epoch [30/40], Step [9300/16026], Loss: 0.0157\n",
      "Epoch [30/40], Step [9400/16026], Loss: 0.0192\n",
      "Epoch [30/40], Step [9500/16026], Loss: 0.0190\n",
      "Epoch [30/40], Step [9600/16026], Loss: 0.0184\n",
      "Epoch [30/40], Step [9700/16026], Loss: 0.0111\n",
      "Epoch [30/40], Step [9800/16026], Loss: 0.0233\n",
      "Epoch [30/40], Step [9900/16026], Loss: 0.0171\n",
      "Epoch [30/40], Step [10000/16026], Loss: 0.0409\n",
      "Epoch [30/40], Step [10100/16026], Loss: 0.0258\n",
      "Epoch [30/40], Step [10200/16026], Loss: 0.0092\n",
      "Epoch [30/40], Step [10300/16026], Loss: 0.0242\n",
      "Epoch [30/40], Step [10400/16026], Loss: 0.0145\n",
      "Epoch [30/40], Step [10500/16026], Loss: 0.0182\n",
      "Epoch [30/40], Step [10600/16026], Loss: 0.0141\n",
      "Epoch [30/40], Step [10700/16026], Loss: 0.0236\n",
      "Epoch [30/40], Step [10800/16026], Loss: 0.0166\n",
      "Epoch [30/40], Step [10900/16026], Loss: 0.0081\n",
      "Epoch [30/40], Step [11000/16026], Loss: 0.0184\n",
      "Epoch [30/40], Step [11100/16026], Loss: 0.0325\n",
      "Epoch [30/40], Step [11200/16026], Loss: 0.0343\n",
      "Epoch [30/40], Step [11300/16026], Loss: 0.0251\n",
      "Epoch [30/40], Step [11400/16026], Loss: 0.0265\n",
      "Epoch [30/40], Step [11500/16026], Loss: 0.0201\n",
      "Epoch [30/40], Step [11600/16026], Loss: 0.0200\n",
      "Epoch [30/40], Step [11700/16026], Loss: 0.0231\n",
      "Epoch [30/40], Step [11800/16026], Loss: 0.0171\n",
      "Epoch [30/40], Step [11900/16026], Loss: 0.0249\n",
      "Epoch [30/40], Step [12000/16026], Loss: 0.0230\n",
      "Epoch [30/40], Step [12100/16026], Loss: 0.0220\n",
      "Epoch [30/40], Step [12200/16026], Loss: 0.0242\n",
      "Epoch [30/40], Step [12300/16026], Loss: 0.0307\n",
      "Epoch [30/40], Step [12400/16026], Loss: 0.0322\n",
      "Epoch [30/40], Step [12500/16026], Loss: 0.0180\n",
      "Epoch [30/40], Step [12600/16026], Loss: 0.0226\n",
      "Epoch [30/40], Step [12700/16026], Loss: 0.0200\n",
      "Epoch [30/40], Step [12800/16026], Loss: 0.0321\n",
      "Epoch [30/40], Step [12900/16026], Loss: 0.0095\n",
      "Epoch [30/40], Step [13000/16026], Loss: 0.0136\n",
      "Epoch [30/40], Step [13100/16026], Loss: 0.0234\n",
      "Epoch [30/40], Step [13200/16026], Loss: 0.0142\n",
      "Epoch [30/40], Step [13300/16026], Loss: 0.0184\n",
      "Epoch [30/40], Step [13400/16026], Loss: 0.0171\n",
      "Epoch [30/40], Step [13500/16026], Loss: 0.0165\n",
      "Epoch [30/40], Step [13600/16026], Loss: 0.0250\n",
      "Epoch [30/40], Step [13700/16026], Loss: 0.0164\n",
      "Epoch [30/40], Step [13800/16026], Loss: 0.0157\n",
      "Epoch [30/40], Step [13900/16026], Loss: 0.0322\n",
      "Epoch [30/40], Step [14000/16026], Loss: 0.0237\n",
      "Epoch [30/40], Step [14100/16026], Loss: 0.0125\n",
      "Epoch [30/40], Step [14200/16026], Loss: 0.0136\n",
      "Epoch [30/40], Step [14300/16026], Loss: 0.0106\n",
      "Epoch [30/40], Step [14400/16026], Loss: 0.0211\n",
      "Epoch [30/40], Step [14500/16026], Loss: 0.0213\n",
      "Epoch [30/40], Step [14600/16026], Loss: 0.0180\n",
      "Epoch [30/40], Step [14700/16026], Loss: 0.0162\n",
      "Epoch [30/40], Step [14800/16026], Loss: 0.0150\n",
      "Epoch [30/40], Step [14900/16026], Loss: 0.0190\n",
      "Epoch [30/40], Step [15000/16026], Loss: 0.0194\n",
      "Epoch [30/40], Step [15100/16026], Loss: 0.0357\n",
      "Epoch [30/40], Step [15200/16026], Loss: 0.0147\n",
      "Epoch [30/40], Step [15300/16026], Loss: 0.0275\n",
      "Epoch [30/40], Step [15400/16026], Loss: 0.0168\n",
      "Epoch [30/40], Step [15500/16026], Loss: 0.0175\n",
      "Epoch [30/40], Step [15600/16026], Loss: 0.0185\n",
      "Epoch [30/40], Step [15700/16026], Loss: 0.0222\n",
      "Epoch [30/40], Step [15800/16026], Loss: 0.0158\n",
      "Epoch [30/40], Step [15900/16026], Loss: 0.0215\n",
      "Epoch [30/40], Step [16000/16026], Loss: 0.0240\n",
      "Epoch [31/40], Step [100/16026], Loss: 0.0212\n",
      "Epoch [31/40], Step [200/16026], Loss: 0.0200\n",
      "Epoch [31/40], Step [300/16026], Loss: 0.0218\n",
      "Epoch [31/40], Step [400/16026], Loss: 0.0184\n",
      "Epoch [31/40], Step [500/16026], Loss: 0.0127\n",
      "Epoch [31/40], Step [600/16026], Loss: 0.0168\n",
      "Epoch [31/40], Step [700/16026], Loss: 0.0122\n",
      "Epoch [31/40], Step [800/16026], Loss: 0.0197\n",
      "Epoch [31/40], Step [900/16026], Loss: 0.0138\n",
      "Epoch [31/40], Step [1000/16026], Loss: 0.0256\n",
      "Epoch [31/40], Step [1100/16026], Loss: 0.0279\n",
      "Epoch [31/40], Step [1200/16026], Loss: 0.0198\n",
      "Epoch [31/40], Step [1300/16026], Loss: 0.0100\n",
      "Epoch [31/40], Step [1400/16026], Loss: 0.0307\n",
      "Epoch [31/40], Step [1500/16026], Loss: 0.0201\n",
      "Epoch [31/40], Step [1600/16026], Loss: 0.0262\n",
      "Epoch [31/40], Step [1700/16026], Loss: 0.0241\n",
      "Epoch [31/40], Step [1800/16026], Loss: 0.0203\n",
      "Epoch [31/40], Step [1900/16026], Loss: 0.0139\n",
      "Epoch [31/40], Step [2000/16026], Loss: 0.0154\n",
      "Epoch [31/40], Step [2100/16026], Loss: 0.0246\n",
      "Epoch [31/40], Step [2200/16026], Loss: 0.0249\n",
      "Epoch [31/40], Step [2300/16026], Loss: 0.0144\n",
      "Epoch [31/40], Step [2400/16026], Loss: 0.0287\n",
      "Epoch [31/40], Step [2500/16026], Loss: 0.0276\n",
      "Epoch [31/40], Step [2600/16026], Loss: 0.0176\n",
      "Epoch [31/40], Step [2700/16026], Loss: 0.0139\n",
      "Epoch [31/40], Step [2800/16026], Loss: 0.0189\n",
      "Epoch [31/40], Step [2900/16026], Loss: 0.0137\n",
      "Epoch [31/40], Step [3000/16026], Loss: 0.0153\n",
      "Epoch [31/40], Step [3100/16026], Loss: 0.0158\n",
      "Epoch [31/40], Step [3200/16026], Loss: 0.0207\n",
      "Epoch [31/40], Step [3300/16026], Loss: 0.0206\n",
      "Epoch [31/40], Step [3400/16026], Loss: 0.0176\n",
      "Epoch [31/40], Step [3500/16026], Loss: 0.0187\n",
      "Epoch [31/40], Step [3600/16026], Loss: 0.0232\n",
      "Epoch [31/40], Step [3700/16026], Loss: 0.0250\n",
      "Epoch [31/40], Step [3800/16026], Loss: 0.0190\n",
      "Epoch [31/40], Step [3900/16026], Loss: 0.0229\n",
      "Epoch [31/40], Step [4000/16026], Loss: 0.0190\n",
      "Epoch [31/40], Step [4100/16026], Loss: 0.0176\n",
      "Epoch [31/40], Step [4200/16026], Loss: 0.0244\n",
      "Epoch [31/40], Step [4300/16026], Loss: 0.0257\n",
      "Epoch [31/40], Step [4400/16026], Loss: 0.0217\n",
      "Epoch [31/40], Step [4500/16026], Loss: 0.0224\n",
      "Epoch [31/40], Step [4600/16026], Loss: 0.0238\n",
      "Epoch [31/40], Step [4700/16026], Loss: 0.0216\n",
      "Epoch [31/40], Step [4800/16026], Loss: 0.0266\n",
      "Epoch [31/40], Step [4900/16026], Loss: 0.0237\n",
      "Epoch [31/40], Step [5000/16026], Loss: 0.0178\n",
      "Epoch [31/40], Step [5100/16026], Loss: 0.0159\n",
      "Epoch [31/40], Step [5200/16026], Loss: 0.0171\n",
      "Epoch [31/40], Step [5300/16026], Loss: 0.0279\n",
      "Epoch [31/40], Step [5400/16026], Loss: 0.0201\n",
      "Epoch [31/40], Step [5500/16026], Loss: 0.0135\n",
      "Epoch [31/40], Step [5600/16026], Loss: 0.0148\n",
      "Epoch [31/40], Step [5700/16026], Loss: 0.0189\n",
      "Epoch [31/40], Step [5800/16026], Loss: 0.0291\n",
      "Epoch [31/40], Step [5900/16026], Loss: 0.0196\n",
      "Epoch [31/40], Step [6000/16026], Loss: 0.0141\n",
      "Epoch [31/40], Step [6100/16026], Loss: 0.0183\n",
      "Epoch [31/40], Step [6200/16026], Loss: 0.0260\n",
      "Epoch [31/40], Step [6300/16026], Loss: 0.0211\n",
      "Epoch [31/40], Step [6400/16026], Loss: 0.0104\n",
      "Epoch [31/40], Step [6500/16026], Loss: 0.0202\n",
      "Epoch [31/40], Step [6600/16026], Loss: 0.0159\n",
      "Epoch [31/40], Step [6700/16026], Loss: 0.0259\n",
      "Epoch [31/40], Step [6800/16026], Loss: 0.0210\n",
      "Epoch [31/40], Step [6900/16026], Loss: 0.0278\n",
      "Epoch [31/40], Step [7000/16026], Loss: 0.0112\n",
      "Epoch [31/40], Step [7100/16026], Loss: 0.0191\n",
      "Epoch [31/40], Step [7200/16026], Loss: 0.0234\n",
      "Epoch [31/40], Step [7300/16026], Loss: 0.0151\n",
      "Epoch [31/40], Step [7400/16026], Loss: 0.0223\n",
      "Epoch [31/40], Step [7500/16026], Loss: 0.0240\n",
      "Epoch [31/40], Step [7600/16026], Loss: 0.0160\n",
      "Epoch [31/40], Step [7700/16026], Loss: 0.0184\n",
      "Epoch [31/40], Step [7800/16026], Loss: 0.0286\n",
      "Epoch [31/40], Step [7900/16026], Loss: 0.0266\n",
      "Epoch [31/40], Step [8000/16026], Loss: 0.0183\n",
      "Epoch [31/40], Step [8100/16026], Loss: 0.0353\n",
      "Epoch [31/40], Step [8200/16026], Loss: 0.0265\n",
      "Epoch [31/40], Step [8300/16026], Loss: 0.0239\n",
      "Epoch [31/40], Step [8400/16026], Loss: 0.0162\n",
      "Epoch [31/40], Step [8500/16026], Loss: 0.0171\n",
      "Epoch [31/40], Step [8600/16026], Loss: 0.0172\n",
      "Epoch [31/40], Step [8700/16026], Loss: 0.0215\n",
      "Epoch [31/40], Step [8800/16026], Loss: 0.0134\n",
      "Epoch [31/40], Step [8900/16026], Loss: 0.0223\n",
      "Epoch [31/40], Step [9000/16026], Loss: 0.0149\n",
      "Epoch [31/40], Step [9100/16026], Loss: 0.0173\n",
      "Epoch [31/40], Step [9200/16026], Loss: 0.0211\n",
      "Epoch [31/40], Step [9300/16026], Loss: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/40], Step [9400/16026], Loss: 0.0103\n",
      "Epoch [31/40], Step [9500/16026], Loss: 0.0239\n",
      "Epoch [31/40], Step [9600/16026], Loss: 0.0139\n",
      "Epoch [31/40], Step [9700/16026], Loss: 0.0192\n",
      "Epoch [31/40], Step [9800/16026], Loss: 0.0288\n",
      "Epoch [31/40], Step [9900/16026], Loss: 0.0144\n",
      "Epoch [31/40], Step [10000/16026], Loss: 0.0193\n",
      "Epoch [31/40], Step [10100/16026], Loss: 0.0149\n",
      "Epoch [31/40], Step [10200/16026], Loss: 0.0234\n",
      "Epoch [31/40], Step [10300/16026], Loss: 0.0133\n",
      "Epoch [31/40], Step [10400/16026], Loss: 0.0206\n",
      "Epoch [31/40], Step [10500/16026], Loss: 0.0207\n",
      "Epoch [31/40], Step [10600/16026], Loss: 0.0141\n",
      "Epoch [31/40], Step [10700/16026], Loss: 0.0371\n",
      "Epoch [31/40], Step [10800/16026], Loss: 0.0186\n",
      "Epoch [31/40], Step [10900/16026], Loss: 0.0132\n",
      "Epoch [31/40], Step [11000/16026], Loss: 0.0279\n",
      "Epoch [31/40], Step [11100/16026], Loss: 0.0253\n",
      "Epoch [31/40], Step [11200/16026], Loss: 0.0120\n",
      "Epoch [31/40], Step [11300/16026], Loss: 0.0188\n",
      "Epoch [31/40], Step [11400/16026], Loss: 0.0118\n",
      "Epoch [31/40], Step [11500/16026], Loss: 0.0205\n",
      "Epoch [31/40], Step [11600/16026], Loss: 0.0148\n",
      "Epoch [31/40], Step [11700/16026], Loss: 0.0290\n",
      "Epoch [31/40], Step [11800/16026], Loss: 0.0117\n",
      "Epoch [31/40], Step [11900/16026], Loss: 0.0217\n",
      "Epoch [31/40], Step [12000/16026], Loss: 0.0205\n",
      "Epoch [31/40], Step [12100/16026], Loss: 0.0142\n",
      "Epoch [31/40], Step [12200/16026], Loss: 0.0176\n",
      "Epoch [31/40], Step [12300/16026], Loss: 0.0173\n",
      "Epoch [31/40], Step [12400/16026], Loss: 0.0276\n",
      "Epoch [31/40], Step [12500/16026], Loss: 0.0154\n",
      "Epoch [31/40], Step [12600/16026], Loss: 0.0179\n",
      "Epoch [31/40], Step [12700/16026], Loss: 0.0301\n",
      "Epoch [31/40], Step [12800/16026], Loss: 0.0168\n",
      "Epoch [31/40], Step [12900/16026], Loss: 0.0225\n",
      "Epoch [31/40], Step [13000/16026], Loss: 0.0125\n",
      "Epoch [31/40], Step [13100/16026], Loss: 0.0177\n",
      "Epoch [31/40], Step [13200/16026], Loss: 0.0215\n",
      "Epoch [31/40], Step [13300/16026], Loss: 0.0231\n",
      "Epoch [31/40], Step [13400/16026], Loss: 0.0107\n",
      "Epoch [31/40], Step [13500/16026], Loss: 0.0207\n",
      "Epoch [31/40], Step [13600/16026], Loss: 0.0156\n",
      "Epoch [31/40], Step [13700/16026], Loss: 0.0219\n",
      "Epoch [31/40], Step [13800/16026], Loss: 0.0270\n",
      "Epoch [31/40], Step [13900/16026], Loss: 0.0202\n",
      "Epoch [31/40], Step [14000/16026], Loss: 0.0235\n",
      "Epoch [31/40], Step [14100/16026], Loss: 0.0243\n",
      "Epoch [31/40], Step [14200/16026], Loss: 0.0182\n",
      "Epoch [31/40], Step [14300/16026], Loss: 0.0233\n",
      "Epoch [31/40], Step [14400/16026], Loss: 0.0174\n",
      "Epoch [31/40], Step [14500/16026], Loss: 0.0326\n",
      "Epoch [31/40], Step [14600/16026], Loss: 0.0122\n",
      "Epoch [31/40], Step [14700/16026], Loss: 0.0123\n",
      "Epoch [31/40], Step [14800/16026], Loss: 0.0337\n",
      "Epoch [31/40], Step [14900/16026], Loss: 0.0246\n",
      "Epoch [31/40], Step [15000/16026], Loss: 0.0212\n",
      "Epoch [31/40], Step [15100/16026], Loss: 0.0132\n",
      "Epoch [31/40], Step [15200/16026], Loss: 0.0279\n",
      "Epoch [31/40], Step [15300/16026], Loss: 0.0209\n",
      "Epoch [31/40], Step [15400/16026], Loss: 0.0217\n",
      "Epoch [31/40], Step [15500/16026], Loss: 0.0096\n",
      "Epoch [31/40], Step [15600/16026], Loss: 0.0200\n",
      "Epoch [31/40], Step [15700/16026], Loss: 0.0236\n",
      "Epoch [31/40], Step [15800/16026], Loss: 0.0191\n",
      "Epoch [31/40], Step [15900/16026], Loss: 0.0143\n",
      "Epoch [31/40], Step [16000/16026], Loss: 0.0170\n",
      "Epoch [32/40], Step [100/16026], Loss: 0.0246\n",
      "Epoch [32/40], Step [200/16026], Loss: 0.0099\n",
      "Epoch [32/40], Step [300/16026], Loss: 0.0173\n",
      "Epoch [32/40], Step [400/16026], Loss: 0.0324\n",
      "Epoch [32/40], Step [500/16026], Loss: 0.0258\n",
      "Epoch [32/40], Step [600/16026], Loss: 0.0251\n",
      "Epoch [32/40], Step [700/16026], Loss: 0.0351\n",
      "Epoch [32/40], Step [800/16026], Loss: 0.0182\n",
      "Epoch [32/40], Step [900/16026], Loss: 0.0251\n",
      "Epoch [32/40], Step [1000/16026], Loss: 0.0142\n",
      "Epoch [32/40], Step [1100/16026], Loss: 0.0147\n",
      "Epoch [32/40], Step [1200/16026], Loss: 0.0253\n",
      "Epoch [32/40], Step [1300/16026], Loss: 0.0219\n",
      "Epoch [32/40], Step [1400/16026], Loss: 0.0199\n",
      "Epoch [32/40], Step [1500/16026], Loss: 0.0202\n",
      "Epoch [32/40], Step [1600/16026], Loss: 0.0246\n",
      "Epoch [32/40], Step [1700/16026], Loss: 0.0407\n",
      "Epoch [32/40], Step [1800/16026], Loss: 0.0176\n",
      "Epoch [32/40], Step [1900/16026], Loss: 0.0107\n",
      "Epoch [32/40], Step [2000/16026], Loss: 0.0238\n",
      "Epoch [32/40], Step [2100/16026], Loss: 0.0182\n",
      "Epoch [32/40], Step [2200/16026], Loss: 0.0264\n",
      "Epoch [32/40], Step [2300/16026], Loss: 0.0260\n",
      "Epoch [32/40], Step [2400/16026], Loss: 0.0140\n",
      "Epoch [32/40], Step [2500/16026], Loss: 0.0113\n",
      "Epoch [32/40], Step [2600/16026], Loss: 0.0181\n",
      "Epoch [32/40], Step [2700/16026], Loss: 0.0219\n",
      "Epoch [32/40], Step [2800/16026], Loss: 0.0137\n",
      "Epoch [32/40], Step [2900/16026], Loss: 0.0238\n",
      "Epoch [32/40], Step [3000/16026], Loss: 0.0187\n",
      "Epoch [32/40], Step [3100/16026], Loss: 0.0267\n",
      "Epoch [32/40], Step [3200/16026], Loss: 0.0225\n",
      "Epoch [32/40], Step [3300/16026], Loss: 0.0146\n",
      "Epoch [32/40], Step [3400/16026], Loss: 0.0333\n",
      "Epoch [32/40], Step [3500/16026], Loss: 0.0183\n",
      "Epoch [32/40], Step [3600/16026], Loss: 0.0156\n",
      "Epoch [32/40], Step [3700/16026], Loss: 0.0156\n",
      "Epoch [32/40], Step [3800/16026], Loss: 0.0242\n",
      "Epoch [32/40], Step [3900/16026], Loss: 0.0285\n",
      "Epoch [32/40], Step [4000/16026], Loss: 0.0229\n",
      "Epoch [32/40], Step [4100/16026], Loss: 0.0188\n",
      "Epoch [32/40], Step [4200/16026], Loss: 0.0168\n",
      "Epoch [32/40], Step [4300/16026], Loss: 0.0218\n",
      "Epoch [32/40], Step [4400/16026], Loss: 0.0217\n",
      "Epoch [32/40], Step [4500/16026], Loss: 0.0241\n",
      "Epoch [32/40], Step [4600/16026], Loss: 0.0350\n",
      "Epoch [32/40], Step [4700/16026], Loss: 0.0383\n",
      "Epoch [32/40], Step [4800/16026], Loss: 0.0167\n",
      "Epoch [32/40], Step [4900/16026], Loss: 0.0207\n",
      "Epoch [32/40], Step [5000/16026], Loss: 0.0325\n",
      "Epoch [32/40], Step [5100/16026], Loss: 0.0154\n",
      "Epoch [32/40], Step [5200/16026], Loss: 0.0234\n",
      "Epoch [32/40], Step [5300/16026], Loss: 0.0211\n",
      "Epoch [32/40], Step [5400/16026], Loss: 0.0234\n",
      "Epoch [32/40], Step [5500/16026], Loss: 0.0274\n",
      "Epoch [32/40], Step [5600/16026], Loss: 0.0355\n",
      "Epoch [32/40], Step [5700/16026], Loss: 0.0354\n",
      "Epoch [32/40], Step [5800/16026], Loss: 0.0198\n",
      "Epoch [32/40], Step [5900/16026], Loss: 0.0227\n",
      "Epoch [32/40], Step [6000/16026], Loss: 0.0155\n",
      "Epoch [32/40], Step [6100/16026], Loss: 0.0214\n",
      "Epoch [32/40], Step [6200/16026], Loss: 0.0112\n",
      "Epoch [32/40], Step [6300/16026], Loss: 0.0136\n",
      "Epoch [32/40], Step [6400/16026], Loss: 0.0206\n",
      "Epoch [32/40], Step [6500/16026], Loss: 0.0148\n",
      "Epoch [32/40], Step [6600/16026], Loss: 0.0174\n",
      "Epoch [32/40], Step [6700/16026], Loss: 0.0313\n",
      "Epoch [32/40], Step [6800/16026], Loss: 0.0273\n",
      "Epoch [32/40], Step [6900/16026], Loss: 0.0200\n",
      "Epoch [32/40], Step [7000/16026], Loss: 0.0203\n",
      "Epoch [32/40], Step [7100/16026], Loss: 0.0178\n",
      "Epoch [32/40], Step [7200/16026], Loss: 0.0143\n",
      "Epoch [32/40], Step [7300/16026], Loss: 0.0150\n",
      "Epoch [32/40], Step [7400/16026], Loss: 0.0128\n",
      "Epoch [32/40], Step [7500/16026], Loss: 0.0194\n",
      "Epoch [32/40], Step [7600/16026], Loss: 0.0202\n",
      "Epoch [32/40], Step [7700/16026], Loss: 0.0182\n",
      "Epoch [32/40], Step [7800/16026], Loss: 0.0231\n",
      "Epoch [32/40], Step [7900/16026], Loss: 0.0248\n",
      "Epoch [32/40], Step [8000/16026], Loss: 0.0192\n",
      "Epoch [32/40], Step [8100/16026], Loss: 0.0230\n",
      "Epoch [32/40], Step [8200/16026], Loss: 0.0116\n",
      "Epoch [32/40], Step [8300/16026], Loss: 0.0138\n",
      "Epoch [32/40], Step [8400/16026], Loss: 0.0180\n",
      "Epoch [32/40], Step [8500/16026], Loss: 0.0218\n",
      "Epoch [32/40], Step [8600/16026], Loss: 0.0149\n",
      "Epoch [32/40], Step [8700/16026], Loss: 0.0133\n",
      "Epoch [32/40], Step [8800/16026], Loss: 0.0195\n",
      "Epoch [32/40], Step [8900/16026], Loss: 0.0182\n",
      "Epoch [32/40], Step [9000/16026], Loss: 0.0138\n",
      "Epoch [32/40], Step [9100/16026], Loss: 0.0175\n",
      "Epoch [32/40], Step [9200/16026], Loss: 0.0114\n",
      "Epoch [32/40], Step [9300/16026], Loss: 0.0301\n",
      "Epoch [32/40], Step [9400/16026], Loss: 0.0258\n",
      "Epoch [32/40], Step [9500/16026], Loss: 0.0178\n",
      "Epoch [32/40], Step [9600/16026], Loss: 0.0128\n",
      "Epoch [32/40], Step [9700/16026], Loss: 0.0159\n",
      "Epoch [32/40], Step [9800/16026], Loss: 0.0266\n",
      "Epoch [32/40], Step [9900/16026], Loss: 0.0206\n",
      "Epoch [32/40], Step [10000/16026], Loss: 0.0259\n",
      "Epoch [32/40], Step [10100/16026], Loss: 0.0215\n",
      "Epoch [32/40], Step [10200/16026], Loss: 0.0128\n",
      "Epoch [32/40], Step [10300/16026], Loss: 0.0280\n",
      "Epoch [32/40], Step [10400/16026], Loss: 0.0230\n",
      "Epoch [32/40], Step [10500/16026], Loss: 0.0105\n",
      "Epoch [32/40], Step [10600/16026], Loss: 0.0168\n",
      "Epoch [32/40], Step [10700/16026], Loss: 0.0191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/40], Step [10800/16026], Loss: 0.0137\n",
      "Epoch [32/40], Step [10900/16026], Loss: 0.0106\n",
      "Epoch [32/40], Step [11000/16026], Loss: 0.0176\n",
      "Epoch [32/40], Step [11100/16026], Loss: 0.0088\n",
      "Epoch [32/40], Step [11200/16026], Loss: 0.0212\n",
      "Epoch [32/40], Step [11300/16026], Loss: 0.0178\n",
      "Epoch [32/40], Step [11400/16026], Loss: 0.0272\n",
      "Epoch [32/40], Step [11500/16026], Loss: 0.0158\n",
      "Epoch [32/40], Step [11600/16026], Loss: 0.0233\n",
      "Epoch [32/40], Step [11700/16026], Loss: 0.0166\n",
      "Epoch [32/40], Step [11800/16026], Loss: 0.0188\n",
      "Epoch [32/40], Step [11900/16026], Loss: 0.0221\n",
      "Epoch [32/40], Step [12000/16026], Loss: 0.0242\n",
      "Epoch [32/40], Step [12100/16026], Loss: 0.0342\n",
      "Epoch [32/40], Step [12200/16026], Loss: 0.0225\n",
      "Epoch [32/40], Step [12300/16026], Loss: 0.0299\n",
      "Epoch [32/40], Step [12400/16026], Loss: 0.0224\n",
      "Epoch [32/40], Step [12500/16026], Loss: 0.0218\n",
      "Epoch [32/40], Step [12600/16026], Loss: 0.0183\n",
      "Epoch [32/40], Step [12700/16026], Loss: 0.0317\n",
      "Epoch [32/40], Step [12800/16026], Loss: 0.0117\n",
      "Epoch [32/40], Step [12900/16026], Loss: 0.0134\n",
      "Epoch [32/40], Step [13000/16026], Loss: 0.0328\n",
      "Epoch [32/40], Step [13100/16026], Loss: 0.0202\n",
      "Epoch [32/40], Step [13200/16026], Loss: 0.0240\n",
      "Epoch [32/40], Step [13300/16026], Loss: 0.0361\n",
      "Epoch [32/40], Step [13400/16026], Loss: 0.0249\n",
      "Epoch [32/40], Step [13500/16026], Loss: 0.0203\n",
      "Epoch [32/40], Step [13600/16026], Loss: 0.0143\n",
      "Epoch [32/40], Step [13700/16026], Loss: 0.0221\n",
      "Epoch [32/40], Step [13800/16026], Loss: 0.0183\n",
      "Epoch [32/40], Step [13900/16026], Loss: 0.0211\n",
      "Epoch [32/40], Step [14000/16026], Loss: 0.0227\n",
      "Epoch [32/40], Step [14100/16026], Loss: 0.0142\n",
      "Epoch [32/40], Step [14200/16026], Loss: 0.0258\n",
      "Epoch [32/40], Step [14300/16026], Loss: 0.0186\n",
      "Epoch [32/40], Step [14400/16026], Loss: 0.0240\n",
      "Epoch [32/40], Step [14500/16026], Loss: 0.0116\n",
      "Epoch [32/40], Step [14600/16026], Loss: 0.0216\n",
      "Epoch [32/40], Step [14700/16026], Loss: 0.0150\n",
      "Epoch [32/40], Step [14800/16026], Loss: 0.0105\n",
      "Epoch [32/40], Step [14900/16026], Loss: 0.0184\n",
      "Epoch [32/40], Step [15000/16026], Loss: 0.0194\n",
      "Epoch [32/40], Step [15100/16026], Loss: 0.0312\n",
      "Epoch [32/40], Step [15200/16026], Loss: 0.0136\n",
      "Epoch [32/40], Step [15300/16026], Loss: 0.0208\n",
      "Epoch [32/40], Step [15400/16026], Loss: 0.0321\n",
      "Epoch [32/40], Step [15500/16026], Loss: 0.0133\n",
      "Epoch [32/40], Step [15600/16026], Loss: 0.0186\n",
      "Epoch [32/40], Step [15700/16026], Loss: 0.0138\n",
      "Epoch [32/40], Step [15800/16026], Loss: 0.0191\n",
      "Epoch [32/40], Step [15900/16026], Loss: 0.0223\n",
      "Epoch [32/40], Step [16000/16026], Loss: 0.0115\n",
      "Epoch [33/40], Step [100/16026], Loss: 0.0162\n",
      "Epoch [33/40], Step [200/16026], Loss: 0.0146\n",
      "Epoch [33/40], Step [300/16026], Loss: 0.0150\n",
      "Epoch [33/40], Step [400/16026], Loss: 0.0193\n",
      "Epoch [33/40], Step [500/16026], Loss: 0.0222\n",
      "Epoch [33/40], Step [600/16026], Loss: 0.0179\n",
      "Epoch [33/40], Step [700/16026], Loss: 0.0319\n",
      "Epoch [33/40], Step [800/16026], Loss: 0.0174\n",
      "Epoch [33/40], Step [900/16026], Loss: 0.0169\n",
      "Epoch [33/40], Step [1000/16026], Loss: 0.0232\n",
      "Epoch [33/40], Step [1100/16026], Loss: 0.0167\n",
      "Epoch [33/40], Step [1200/16026], Loss: 0.0110\n",
      "Epoch [33/40], Step [1300/16026], Loss: 0.0179\n",
      "Epoch [33/40], Step [1400/16026], Loss: 0.0139\n",
      "Epoch [33/40], Step [1500/16026], Loss: 0.0165\n",
      "Epoch [33/40], Step [1600/16026], Loss: 0.0227\n",
      "Epoch [33/40], Step [1700/16026], Loss: 0.0256\n",
      "Epoch [33/40], Step [1800/16026], Loss: 0.0241\n",
      "Epoch [33/40], Step [1900/16026], Loss: 0.0174\n",
      "Epoch [33/40], Step [2000/16026], Loss: 0.0152\n",
      "Epoch [33/40], Step [2100/16026], Loss: 0.0129\n",
      "Epoch [33/40], Step [2200/16026], Loss: 0.0310\n",
      "Epoch [33/40], Step [2300/16026], Loss: 0.0183\n",
      "Epoch [33/40], Step [2400/16026], Loss: 0.0124\n",
      "Epoch [33/40], Step [2500/16026], Loss: 0.0098\n",
      "Epoch [33/40], Step [2600/16026], Loss: 0.0196\n",
      "Epoch [33/40], Step [2700/16026], Loss: 0.0143\n",
      "Epoch [33/40], Step [2800/16026], Loss: 0.0128\n",
      "Epoch [33/40], Step [2900/16026], Loss: 0.0185\n",
      "Epoch [33/40], Step [3000/16026], Loss: 0.0216\n",
      "Epoch [33/40], Step [3100/16026], Loss: 0.0206\n",
      "Epoch [33/40], Step [3200/16026], Loss: 0.0155\n",
      "Epoch [33/40], Step [3300/16026], Loss: 0.0267\n",
      "Epoch [33/40], Step [3400/16026], Loss: 0.0251\n",
      "Epoch [33/40], Step [3500/16026], Loss: 0.0165\n",
      "Epoch [33/40], Step [3600/16026], Loss: 0.0395\n",
      "Epoch [33/40], Step [3700/16026], Loss: 0.0210\n",
      "Epoch [33/40], Step [3800/16026], Loss: 0.0186\n",
      "Epoch [33/40], Step [3900/16026], Loss: 0.0320\n",
      "Epoch [33/40], Step [4000/16026], Loss: 0.0179\n",
      "Epoch [33/40], Step [4100/16026], Loss: 0.0208\n",
      "Epoch [33/40], Step [4200/16026], Loss: 0.0181\n",
      "Epoch [33/40], Step [4300/16026], Loss: 0.0268\n",
      "Epoch [33/40], Step [4400/16026], Loss: 0.0152\n",
      "Epoch [33/40], Step [4500/16026], Loss: 0.0134\n",
      "Epoch [33/40], Step [4600/16026], Loss: 0.0169\n",
      "Epoch [33/40], Step [4700/16026], Loss: 0.0201\n",
      "Epoch [33/40], Step [4800/16026], Loss: 0.0253\n",
      "Epoch [33/40], Step [4900/16026], Loss: 0.0252\n",
      "Epoch [33/40], Step [5000/16026], Loss: 0.0134\n",
      "Epoch [33/40], Step [5100/16026], Loss: 0.0164\n",
      "Epoch [33/40], Step [5200/16026], Loss: 0.0176\n",
      "Epoch [33/40], Step [5300/16026], Loss: 0.0214\n",
      "Epoch [33/40], Step [5400/16026], Loss: 0.0184\n",
      "Epoch [33/40], Step [5500/16026], Loss: 0.0159\n",
      "Epoch [33/40], Step [5600/16026], Loss: 0.0213\n",
      "Epoch [33/40], Step [5700/16026], Loss: 0.0216\n",
      "Epoch [33/40], Step [5800/16026], Loss: 0.0151\n",
      "Epoch [33/40], Step [5900/16026], Loss: 0.0233\n",
      "Epoch [33/40], Step [6000/16026], Loss: 0.0124\n",
      "Epoch [33/40], Step [6100/16026], Loss: 0.0198\n",
      "Epoch [33/40], Step [6200/16026], Loss: 0.0238\n",
      "Epoch [33/40], Step [6300/16026], Loss: 0.0171\n",
      "Epoch [33/40], Step [6400/16026], Loss: 0.0239\n",
      "Epoch [33/40], Step [6500/16026], Loss: 0.0165\n",
      "Epoch [33/40], Step [6600/16026], Loss: 0.0170\n",
      "Epoch [33/40], Step [6700/16026], Loss: 0.0298\n",
      "Epoch [33/40], Step [6800/16026], Loss: 0.0173\n",
      "Epoch [33/40], Step [6900/16026], Loss: 0.0230\n",
      "Epoch [33/40], Step [7000/16026], Loss: 0.0154\n",
      "Epoch [33/40], Step [7100/16026], Loss: 0.0186\n",
      "Epoch [33/40], Step [7200/16026], Loss: 0.0199\n",
      "Epoch [33/40], Step [7300/16026], Loss: 0.0172\n",
      "Epoch [33/40], Step [7400/16026], Loss: 0.0095\n",
      "Epoch [33/40], Step [7500/16026], Loss: 0.0187\n",
      "Epoch [33/40], Step [7600/16026], Loss: 0.0286\n",
      "Epoch [33/40], Step [7700/16026], Loss: 0.0214\n",
      "Epoch [33/40], Step [7800/16026], Loss: 0.0193\n",
      "Epoch [33/40], Step [7900/16026], Loss: 0.0159\n",
      "Epoch [33/40], Step [8000/16026], Loss: 0.0113\n",
      "Epoch [33/40], Step [8100/16026], Loss: 0.0559\n",
      "Epoch [33/40], Step [8200/16026], Loss: 0.0225\n",
      "Epoch [33/40], Step [8300/16026], Loss: 0.0103\n",
      "Epoch [33/40], Step [8400/16026], Loss: 0.0164\n",
      "Epoch [33/40], Step [8500/16026], Loss: 0.0176\n",
      "Epoch [33/40], Step [8600/16026], Loss: 0.0211\n",
      "Epoch [33/40], Step [8700/16026], Loss: 0.0245\n",
      "Epoch [33/40], Step [8800/16026], Loss: 0.0163\n",
      "Epoch [33/40], Step [8900/16026], Loss: 0.0145\n",
      "Epoch [33/40], Step [9000/16026], Loss: 0.0219\n",
      "Epoch [33/40], Step [9100/16026], Loss: 0.0102\n",
      "Epoch [33/40], Step [9200/16026], Loss: 0.0204\n",
      "Epoch [33/40], Step [9300/16026], Loss: 0.0239\n",
      "Epoch [33/40], Step [9400/16026], Loss: 0.0251\n",
      "Epoch [33/40], Step [9500/16026], Loss: 0.0165\n",
      "Epoch [33/40], Step [9600/16026], Loss: 0.0182\n",
      "Epoch [33/40], Step [9700/16026], Loss: 0.0145\n",
      "Epoch [33/40], Step [9800/16026], Loss: 0.0330\n",
      "Epoch [33/40], Step [9900/16026], Loss: 0.0253\n",
      "Epoch [33/40], Step [10000/16026], Loss: 0.0274\n",
      "Epoch [33/40], Step [10100/16026], Loss: 0.0220\n",
      "Epoch [33/40], Step [10200/16026], Loss: 0.0190\n",
      "Epoch [33/40], Step [10300/16026], Loss: 0.0238\n",
      "Epoch [33/40], Step [10400/16026], Loss: 0.0180\n",
      "Epoch [33/40], Step [10500/16026], Loss: 0.0257\n",
      "Epoch [33/40], Step [10600/16026], Loss: 0.0269\n",
      "Epoch [33/40], Step [10700/16026], Loss: 0.0199\n",
      "Epoch [33/40], Step [10800/16026], Loss: 0.0158\n",
      "Epoch [33/40], Step [10900/16026], Loss: 0.0308\n",
      "Epoch [33/40], Step [11000/16026], Loss: 0.0235\n",
      "Epoch [33/40], Step [11100/16026], Loss: 0.0167\n",
      "Epoch [33/40], Step [11200/16026], Loss: 0.0195\n",
      "Epoch [33/40], Step [11300/16026], Loss: 0.0178\n",
      "Epoch [33/40], Step [11400/16026], Loss: 0.0157\n",
      "Epoch [33/40], Step [11500/16026], Loss: 0.0196\n",
      "Epoch [33/40], Step [11600/16026], Loss: 0.0215\n",
      "Epoch [33/40], Step [11700/16026], Loss: 0.0305\n",
      "Epoch [33/40], Step [11800/16026], Loss: 0.0167\n",
      "Epoch [33/40], Step [11900/16026], Loss: 0.0266\n",
      "Epoch [33/40], Step [12000/16026], Loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/40], Step [12100/16026], Loss: 0.0202\n",
      "Epoch [33/40], Step [12200/16026], Loss: 0.0225\n",
      "Epoch [33/40], Step [12300/16026], Loss: 0.0212\n",
      "Epoch [33/40], Step [12400/16026], Loss: 0.0251\n",
      "Epoch [33/40], Step [12500/16026], Loss: 0.0265\n",
      "Epoch [33/40], Step [12600/16026], Loss: 0.0142\n",
      "Epoch [33/40], Step [12700/16026], Loss: 0.0284\n",
      "Epoch [33/40], Step [12800/16026], Loss: 0.0147\n",
      "Epoch [33/40], Step [12900/16026], Loss: 0.0162\n",
      "Epoch [33/40], Step [13000/16026], Loss: 0.0193\n",
      "Epoch [33/40], Step [13100/16026], Loss: 0.0128\n",
      "Epoch [33/40], Step [13200/16026], Loss: 0.0264\n",
      "Epoch [33/40], Step [13300/16026], Loss: 0.0282\n",
      "Epoch [33/40], Step [13400/16026], Loss: 0.0473\n",
      "Epoch [33/40], Step [13500/16026], Loss: 0.0143\n",
      "Epoch [33/40], Step [13600/16026], Loss: 0.0192\n",
      "Epoch [33/40], Step [13700/16026], Loss: 0.0154\n",
      "Epoch [33/40], Step [13800/16026], Loss: 0.0149\n",
      "Epoch [33/40], Step [13900/16026], Loss: 0.0199\n",
      "Epoch [33/40], Step [14000/16026], Loss: 0.0247\n",
      "Epoch [33/40], Step [14100/16026], Loss: 0.0204\n",
      "Epoch [33/40], Step [14200/16026], Loss: 0.0156\n",
      "Epoch [33/40], Step [14300/16026], Loss: 0.0183\n",
      "Epoch [33/40], Step [14400/16026], Loss: 0.0212\n",
      "Epoch [33/40], Step [14500/16026], Loss: 0.0209\n",
      "Epoch [33/40], Step [14600/16026], Loss: 0.0151\n",
      "Epoch [33/40], Step [14700/16026], Loss: 0.0124\n",
      "Epoch [33/40], Step [14800/16026], Loss: 0.0270\n",
      "Epoch [33/40], Step [14900/16026], Loss: 0.0134\n",
      "Epoch [33/40], Step [15000/16026], Loss: 0.0351\n",
      "Epoch [33/40], Step [15100/16026], Loss: 0.0130\n",
      "Epoch [33/40], Step [15200/16026], Loss: 0.0212\n",
      "Epoch [33/40], Step [15300/16026], Loss: 0.0117\n",
      "Epoch [33/40], Step [15400/16026], Loss: 0.0140\n",
      "Epoch [33/40], Step [15500/16026], Loss: 0.0215\n",
      "Epoch [33/40], Step [15600/16026], Loss: 0.0181\n",
      "Epoch [33/40], Step [15700/16026], Loss: 0.0192\n",
      "Epoch [33/40], Step [15800/16026], Loss: 0.0134\n",
      "Epoch [33/40], Step [15900/16026], Loss: 0.0142\n",
      "Epoch [33/40], Step [16000/16026], Loss: 0.0227\n",
      "Epoch [34/40], Step [100/16026], Loss: 0.0151\n",
      "Epoch [34/40], Step [200/16026], Loss: 0.0175\n",
      "Epoch [34/40], Step [300/16026], Loss: 0.0159\n",
      "Epoch [34/40], Step [400/16026], Loss: 0.0122\n",
      "Epoch [34/40], Step [500/16026], Loss: 0.0202\n",
      "Epoch [34/40], Step [600/16026], Loss: 0.0139\n",
      "Epoch [34/40], Step [700/16026], Loss: 0.0415\n",
      "Epoch [34/40], Step [800/16026], Loss: 0.0203\n",
      "Epoch [34/40], Step [900/16026], Loss: 0.0185\n",
      "Epoch [34/40], Step [1000/16026], Loss: 0.0240\n",
      "Epoch [34/40], Step [1100/16026], Loss: 0.0310\n",
      "Epoch [34/40], Step [1200/16026], Loss: 0.0246\n",
      "Epoch [34/40], Step [1300/16026], Loss: 0.0171\n",
      "Epoch [34/40], Step [1400/16026], Loss: 0.0159\n",
      "Epoch [34/40], Step [1500/16026], Loss: 0.0123\n",
      "Epoch [34/40], Step [1600/16026], Loss: 0.0270\n",
      "Epoch [34/40], Step [1700/16026], Loss: 0.0153\n",
      "Epoch [34/40], Step [1800/16026], Loss: 0.0168\n",
      "Epoch [34/40], Step [1900/16026], Loss: 0.0185\n",
      "Epoch [34/40], Step [2000/16026], Loss: 0.0199\n",
      "Epoch [34/40], Step [2100/16026], Loss: 0.0172\n",
      "Epoch [34/40], Step [2200/16026], Loss: 0.0150\n",
      "Epoch [34/40], Step [2300/16026], Loss: 0.0194\n",
      "Epoch [34/40], Step [2400/16026], Loss: 0.0181\n",
      "Epoch [34/40], Step [2500/16026], Loss: 0.0159\n",
      "Epoch [34/40], Step [2600/16026], Loss: 0.0136\n",
      "Epoch [34/40], Step [2700/16026], Loss: 0.0202\n",
      "Epoch [34/40], Step [2800/16026], Loss: 0.0237\n",
      "Epoch [34/40], Step [2900/16026], Loss: 0.0210\n",
      "Epoch [34/40], Step [3000/16026], Loss: 0.0192\n",
      "Epoch [34/40], Step [3100/16026], Loss: 0.0066\n",
      "Epoch [34/40], Step [3200/16026], Loss: 0.0296\n",
      "Epoch [34/40], Step [3300/16026], Loss: 0.0172\n",
      "Epoch [34/40], Step [3400/16026], Loss: 0.0156\n",
      "Epoch [34/40], Step [3500/16026], Loss: 0.0270\n",
      "Epoch [34/40], Step [3600/16026], Loss: 0.0176\n",
      "Epoch [34/40], Step [3700/16026], Loss: 0.0206\n",
      "Epoch [34/40], Step [3800/16026], Loss: 0.0172\n",
      "Epoch [34/40], Step [3900/16026], Loss: 0.0139\n",
      "Epoch [34/40], Step [4000/16026], Loss: 0.0206\n",
      "Epoch [34/40], Step [4100/16026], Loss: 0.0244\n",
      "Epoch [34/40], Step [4200/16026], Loss: 0.0201\n",
      "Epoch [34/40], Step [4300/16026], Loss: 0.0217\n",
      "Epoch [34/40], Step [4400/16026], Loss: 0.0161\n",
      "Epoch [34/40], Step [4500/16026], Loss: 0.0201\n",
      "Epoch [34/40], Step [4600/16026], Loss: 0.0250\n",
      "Epoch [34/40], Step [4700/16026], Loss: 0.0224\n",
      "Epoch [34/40], Step [4800/16026], Loss: 0.0174\n",
      "Epoch [34/40], Step [4900/16026], Loss: 0.0207\n",
      "Epoch [34/40], Step [5000/16026], Loss: 0.0228\n",
      "Epoch [34/40], Step [5100/16026], Loss: 0.0237\n",
      "Epoch [34/40], Step [5200/16026], Loss: 0.0158\n",
      "Epoch [34/40], Step [5300/16026], Loss: 0.0195\n",
      "Epoch [34/40], Step [5400/16026], Loss: 0.0208\n",
      "Epoch [34/40], Step [5500/16026], Loss: 0.0139\n",
      "Epoch [34/40], Step [5600/16026], Loss: 0.0238\n",
      "Epoch [34/40], Step [5700/16026], Loss: 0.0130\n",
      "Epoch [34/40], Step [5800/16026], Loss: 0.0199\n",
      "Epoch [34/40], Step [5900/16026], Loss: 0.0235\n",
      "Epoch [34/40], Step [6000/16026], Loss: 0.0180\n",
      "Epoch [34/40], Step [6100/16026], Loss: 0.0198\n",
      "Epoch [34/40], Step [6200/16026], Loss: 0.0305\n",
      "Epoch [34/40], Step [6300/16026], Loss: 0.0120\n",
      "Epoch [34/40], Step [6400/16026], Loss: 0.0182\n",
      "Epoch [34/40], Step [6500/16026], Loss: 0.0149\n",
      "Epoch [34/40], Step [6600/16026], Loss: 0.0183\n",
      "Epoch [34/40], Step [6700/16026], Loss: 0.0202\n",
      "Epoch [34/40], Step [6800/16026], Loss: 0.0221\n",
      "Epoch [34/40], Step [6900/16026], Loss: 0.0163\n",
      "Epoch [34/40], Step [7000/16026], Loss: 0.0195\n",
      "Epoch [34/40], Step [7100/16026], Loss: 0.0207\n",
      "Epoch [34/40], Step [7200/16026], Loss: 0.0218\n",
      "Epoch [34/40], Step [7300/16026], Loss: 0.0138\n",
      "Epoch [34/40], Step [7400/16026], Loss: 0.0195\n",
      "Epoch [34/40], Step [7500/16026], Loss: 0.0205\n",
      "Epoch [34/40], Step [7600/16026], Loss: 0.0191\n",
      "Epoch [34/40], Step [7700/16026], Loss: 0.0215\n",
      "Epoch [34/40], Step [7800/16026], Loss: 0.0196\n",
      "Epoch [34/40], Step [7900/16026], Loss: 0.0274\n",
      "Epoch [34/40], Step [8000/16026], Loss: 0.0210\n",
      "Epoch [34/40], Step [8100/16026], Loss: 0.0133\n",
      "Epoch [34/40], Step [8200/16026], Loss: 0.0171\n",
      "Epoch [34/40], Step [8300/16026], Loss: 0.0263\n",
      "Epoch [34/40], Step [8400/16026], Loss: 0.0116\n",
      "Epoch [34/40], Step [8500/16026], Loss: 0.0099\n",
      "Epoch [34/40], Step [8600/16026], Loss: 0.0273\n",
      "Epoch [34/40], Step [8700/16026], Loss: 0.0203\n",
      "Epoch [34/40], Step [8800/16026], Loss: 0.0179\n",
      "Epoch [34/40], Step [8900/16026], Loss: 0.0199\n",
      "Epoch [34/40], Step [9000/16026], Loss: 0.0117\n",
      "Epoch [34/40], Step [9100/16026], Loss: 0.0166\n",
      "Epoch [34/40], Step [9200/16026], Loss: 0.0310\n",
      "Epoch [34/40], Step [9300/16026], Loss: 0.0147\n",
      "Epoch [34/40], Step [9400/16026], Loss: 0.0140\n",
      "Epoch [34/40], Step [9500/16026], Loss: 0.0177\n",
      "Epoch [34/40], Step [9600/16026], Loss: 0.0236\n",
      "Epoch [34/40], Step [9700/16026], Loss: 0.0132\n",
      "Epoch [34/40], Step [9800/16026], Loss: 0.0357\n",
      "Epoch [34/40], Step [9900/16026], Loss: 0.0204\n",
      "Epoch [34/40], Step [10000/16026], Loss: 0.0223\n",
      "Epoch [34/40], Step [10100/16026], Loss: 0.0146\n",
      "Epoch [34/40], Step [10200/16026], Loss: 0.0185\n",
      "Epoch [34/40], Step [10300/16026], Loss: 0.0193\n",
      "Epoch [34/40], Step [10400/16026], Loss: 0.0202\n",
      "Epoch [34/40], Step [10500/16026], Loss: 0.0222\n",
      "Epoch [34/40], Step [10600/16026], Loss: 0.0235\n",
      "Epoch [34/40], Step [10700/16026], Loss: 0.0166\n",
      "Epoch [34/40], Step [10800/16026], Loss: 0.0233\n",
      "Epoch [34/40], Step [10900/16026], Loss: 0.0162\n",
      "Epoch [34/40], Step [11000/16026], Loss: 0.0194\n",
      "Epoch [34/40], Step [11100/16026], Loss: 0.0159\n",
      "Epoch [34/40], Step [11200/16026], Loss: 0.0166\n",
      "Epoch [34/40], Step [11300/16026], Loss: 0.0233\n",
      "Epoch [34/40], Step [11400/16026], Loss: 0.0179\n",
      "Epoch [34/40], Step [11500/16026], Loss: 0.0228\n",
      "Epoch [34/40], Step [11600/16026], Loss: 0.0251\n",
      "Epoch [34/40], Step [11700/16026], Loss: 0.0246\n",
      "Epoch [34/40], Step [11800/16026], Loss: 0.0183\n",
      "Epoch [34/40], Step [11900/16026], Loss: 0.0158\n",
      "Epoch [34/40], Step [12000/16026], Loss: 0.0183\n",
      "Epoch [34/40], Step [12100/16026], Loss: 0.0513\n",
      "Epoch [34/40], Step [12200/16026], Loss: 0.0224\n",
      "Epoch [34/40], Step [12300/16026], Loss: 0.0160\n",
      "Epoch [34/40], Step [12400/16026], Loss: 0.0221\n",
      "Epoch [34/40], Step [12500/16026], Loss: 0.0225\n",
      "Epoch [34/40], Step [12600/16026], Loss: 0.0138\n",
      "Epoch [34/40], Step [12700/16026], Loss: 0.0119\n",
      "Epoch [34/40], Step [12800/16026], Loss: 0.0138\n",
      "Epoch [34/40], Step [12900/16026], Loss: 0.0147\n",
      "Epoch [34/40], Step [13000/16026], Loss: 0.0180\n",
      "Epoch [34/40], Step [13100/16026], Loss: 0.0195\n",
      "Epoch [34/40], Step [13200/16026], Loss: 0.0214\n",
      "Epoch [34/40], Step [13300/16026], Loss: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/40], Step [13400/16026], Loss: 0.0161\n",
      "Epoch [34/40], Step [13500/16026], Loss: 0.0300\n",
      "Epoch [34/40], Step [13600/16026], Loss: 0.0260\n",
      "Epoch [34/40], Step [13700/16026], Loss: 0.0269\n",
      "Epoch [34/40], Step [13800/16026], Loss: 0.0203\n",
      "Epoch [34/40], Step [13900/16026], Loss: 0.0192\n",
      "Epoch [34/40], Step [14000/16026], Loss: 0.0169\n",
      "Epoch [34/40], Step [14100/16026], Loss: 0.0153\n",
      "Epoch [34/40], Step [14200/16026], Loss: 0.0164\n",
      "Epoch [34/40], Step [14300/16026], Loss: 0.0122\n",
      "Epoch [34/40], Step [14400/16026], Loss: 0.0221\n",
      "Epoch [34/40], Step [14500/16026], Loss: 0.0209\n",
      "Epoch [34/40], Step [14600/16026], Loss: 0.0275\n",
      "Epoch [34/40], Step [14700/16026], Loss: 0.0217\n",
      "Epoch [34/40], Step [14800/16026], Loss: 0.0170\n",
      "Epoch [34/40], Step [14900/16026], Loss: 0.0388\n",
      "Epoch [34/40], Step [15000/16026], Loss: 0.0173\n",
      "Epoch [34/40], Step [15100/16026], Loss: 0.0192\n",
      "Epoch [34/40], Step [15200/16026], Loss: 0.0236\n",
      "Epoch [34/40], Step [15300/16026], Loss: 0.0174\n",
      "Epoch [34/40], Step [15400/16026], Loss: 0.0282\n",
      "Epoch [34/40], Step [15500/16026], Loss: 0.0244\n",
      "Epoch [34/40], Step [15600/16026], Loss: 0.0211\n",
      "Epoch [34/40], Step [15700/16026], Loss: 0.0201\n",
      "Epoch [34/40], Step [15800/16026], Loss: 0.0198\n",
      "Epoch [34/40], Step [15900/16026], Loss: 0.0148\n",
      "Epoch [34/40], Step [16000/16026], Loss: 0.0125\n",
      "Epoch [35/40], Step [100/16026], Loss: 0.0176\n",
      "Epoch [35/40], Step [200/16026], Loss: 0.0170\n",
      "Epoch [35/40], Step [300/16026], Loss: 0.0261\n",
      "Epoch [35/40], Step [400/16026], Loss: 0.0169\n",
      "Epoch [35/40], Step [500/16026], Loss: 0.0273\n",
      "Epoch [35/40], Step [600/16026], Loss: 0.0107\n",
      "Epoch [35/40], Step [700/16026], Loss: 0.0142\n",
      "Epoch [35/40], Step [800/16026], Loss: 0.0189\n",
      "Epoch [35/40], Step [900/16026], Loss: 0.0158\n",
      "Epoch [35/40], Step [1000/16026], Loss: 0.0179\n",
      "Epoch [35/40], Step [1100/16026], Loss: 0.0115\n",
      "Epoch [35/40], Step [1200/16026], Loss: 0.0157\n",
      "Epoch [35/40], Step [1300/16026], Loss: 0.0204\n",
      "Epoch [35/40], Step [1400/16026], Loss: 0.0140\n",
      "Epoch [35/40], Step [1500/16026], Loss: 0.0206\n",
      "Epoch [35/40], Step [1600/16026], Loss: 0.0134\n",
      "Epoch [35/40], Step [1700/16026], Loss: 0.0244\n",
      "Epoch [35/40], Step [1800/16026], Loss: 0.0162\n",
      "Epoch [35/40], Step [1900/16026], Loss: 0.0231\n",
      "Epoch [35/40], Step [2000/16026], Loss: 0.0185\n",
      "Epoch [35/40], Step [2100/16026], Loss: 0.0201\n",
      "Epoch [35/40], Step [2200/16026], Loss: 0.0256\n",
      "Epoch [35/40], Step [2300/16026], Loss: 0.0212\n",
      "Epoch [35/40], Step [2400/16026], Loss: 0.0138\n",
      "Epoch [35/40], Step [2500/16026], Loss: 0.0156\n",
      "Epoch [35/40], Step [2600/16026], Loss: 0.0214\n",
      "Epoch [35/40], Step [2700/16026], Loss: 0.0112\n",
      "Epoch [35/40], Step [2800/16026], Loss: 0.0194\n",
      "Epoch [35/40], Step [2900/16026], Loss: 0.0203\n",
      "Epoch [35/40], Step [3000/16026], Loss: 0.0141\n",
      "Epoch [35/40], Step [3100/16026], Loss: 0.0188\n",
      "Epoch [35/40], Step [3200/16026], Loss: 0.0215\n",
      "Epoch [35/40], Step [3300/16026], Loss: 0.0260\n",
      "Epoch [35/40], Step [3400/16026], Loss: 0.0367\n",
      "Epoch [35/40], Step [3500/16026], Loss: 0.0253\n",
      "Epoch [35/40], Step [3600/16026], Loss: 0.0135\n",
      "Epoch [35/40], Step [3700/16026], Loss: 0.0218\n",
      "Epoch [35/40], Step [3800/16026], Loss: 0.0182\n",
      "Epoch [35/40], Step [3900/16026], Loss: 0.0143\n",
      "Epoch [35/40], Step [4000/16026], Loss: 0.0276\n",
      "Epoch [35/40], Step [4100/16026], Loss: 0.0169\n",
      "Epoch [35/40], Step [4200/16026], Loss: 0.0180\n",
      "Epoch [35/40], Step [4300/16026], Loss: 0.0135\n",
      "Epoch [35/40], Step [4400/16026], Loss: 0.0146\n",
      "Epoch [35/40], Step [4500/16026], Loss: 0.0222\n",
      "Epoch [35/40], Step [4600/16026], Loss: 0.0205\n",
      "Epoch [35/40], Step [4700/16026], Loss: 0.0214\n",
      "Epoch [35/40], Step [4800/16026], Loss: 0.0200\n",
      "Epoch [35/40], Step [4900/16026], Loss: 0.0191\n",
      "Epoch [35/40], Step [5000/16026], Loss: 0.0168\n",
      "Epoch [35/40], Step [5100/16026], Loss: 0.0217\n",
      "Epoch [35/40], Step [5200/16026], Loss: 0.0135\n",
      "Epoch [35/40], Step [5300/16026], Loss: 0.0149\n",
      "Epoch [35/40], Step [5400/16026], Loss: 0.0170\n",
      "Epoch [35/40], Step [5500/16026], Loss: 0.0264\n",
      "Epoch [35/40], Step [5600/16026], Loss: 0.0149\n",
      "Epoch [35/40], Step [5700/16026], Loss: 0.0161\n",
      "Epoch [35/40], Step [5800/16026], Loss: 0.0206\n",
      "Epoch [35/40], Step [5900/16026], Loss: 0.0097\n",
      "Epoch [35/40], Step [6000/16026], Loss: 0.0136\n",
      "Epoch [35/40], Step [6100/16026], Loss: 0.0136\n",
      "Epoch [35/40], Step [6200/16026], Loss: 0.0147\n",
      "Epoch [35/40], Step [6300/16026], Loss: 0.0216\n",
      "Epoch [35/40], Step [6400/16026], Loss: 0.0154\n",
      "Epoch [35/40], Step [6500/16026], Loss: 0.0158\n",
      "Epoch [35/40], Step [6600/16026], Loss: 0.0221\n",
      "Epoch [35/40], Step [6700/16026], Loss: 0.0360\n",
      "Epoch [35/40], Step [6800/16026], Loss: 0.0223\n",
      "Epoch [35/40], Step [6900/16026], Loss: 0.0222\n",
      "Epoch [35/40], Step [7000/16026], Loss: 0.0206\n",
      "Epoch [35/40], Step [7100/16026], Loss: 0.0172\n",
      "Epoch [35/40], Step [7200/16026], Loss: 0.0198\n",
      "Epoch [35/40], Step [7300/16026], Loss: 0.0350\n",
      "Epoch [35/40], Step [7400/16026], Loss: 0.0581\n",
      "Epoch [35/40], Step [7500/16026], Loss: 0.0253\n",
      "Epoch [35/40], Step [7600/16026], Loss: 0.0347\n",
      "Epoch [35/40], Step [7700/16026], Loss: 0.0166\n",
      "Epoch [35/40], Step [7800/16026], Loss: 0.0315\n",
      "Epoch [35/40], Step [7900/16026], Loss: 0.0251\n",
      "Epoch [35/40], Step [8000/16026], Loss: 0.0139\n",
      "Epoch [35/40], Step [8100/16026], Loss: 0.0224\n",
      "Epoch [35/40], Step [8200/16026], Loss: 0.0177\n",
      "Epoch [35/40], Step [8300/16026], Loss: 0.0146\n",
      "Epoch [35/40], Step [8400/16026], Loss: 0.0231\n",
      "Epoch [35/40], Step [8500/16026], Loss: 0.0166\n",
      "Epoch [35/40], Step [8600/16026], Loss: 0.0174\n",
      "Epoch [35/40], Step [8700/16026], Loss: 0.0226\n",
      "Epoch [35/40], Step [8800/16026], Loss: 0.0156\n",
      "Epoch [35/40], Step [8900/16026], Loss: 0.0150\n",
      "Epoch [35/40], Step [9000/16026], Loss: 0.0188\n",
      "Epoch [35/40], Step [9100/16026], Loss: 0.0182\n",
      "Epoch [35/40], Step [9200/16026], Loss: 0.0215\n",
      "Epoch [35/40], Step [9300/16026], Loss: 0.0135\n",
      "Epoch [35/40], Step [9400/16026], Loss: 0.0137\n",
      "Epoch [35/40], Step [9500/16026], Loss: 0.0286\n",
      "Epoch [35/40], Step [9600/16026], Loss: 0.0164\n",
      "Epoch [35/40], Step [9700/16026], Loss: 0.0234\n",
      "Epoch [35/40], Step [9800/16026], Loss: 0.0125\n",
      "Epoch [35/40], Step [9900/16026], Loss: 0.0156\n",
      "Epoch [35/40], Step [10000/16026], Loss: 0.0178\n",
      "Epoch [35/40], Step [10100/16026], Loss: 0.0201\n",
      "Epoch [35/40], Step [10200/16026], Loss: 0.0325\n",
      "Epoch [35/40], Step [10300/16026], Loss: 0.0239\n",
      "Epoch [35/40], Step [10400/16026], Loss: 0.0168\n",
      "Epoch [35/40], Step [10500/16026], Loss: 0.0262\n",
      "Epoch [35/40], Step [10600/16026], Loss: 0.0215\n",
      "Epoch [35/40], Step [10700/16026], Loss: 0.0145\n",
      "Epoch [35/40], Step [10800/16026], Loss: 0.0162\n",
      "Epoch [35/40], Step [10900/16026], Loss: 0.0144\n",
      "Epoch [35/40], Step [11000/16026], Loss: 0.0223\n",
      "Epoch [35/40], Step [11100/16026], Loss: 0.0279\n",
      "Epoch [35/40], Step [11200/16026], Loss: 0.0172\n",
      "Epoch [35/40], Step [11300/16026], Loss: 0.0116\n",
      "Epoch [35/40], Step [11400/16026], Loss: 0.0170\n",
      "Epoch [35/40], Step [11500/16026], Loss: 0.0352\n",
      "Epoch [35/40], Step [11600/16026], Loss: 0.0240\n",
      "Epoch [35/40], Step [11700/16026], Loss: 0.0140\n",
      "Epoch [35/40], Step [11800/16026], Loss: 0.0144\n",
      "Epoch [35/40], Step [11900/16026], Loss: 0.0260\n",
      "Epoch [35/40], Step [12000/16026], Loss: 0.0179\n",
      "Epoch [35/40], Step [12100/16026], Loss: 0.0240\n",
      "Epoch [35/40], Step [12200/16026], Loss: 0.0238\n",
      "Epoch [35/40], Step [12300/16026], Loss: 0.0153\n",
      "Epoch [35/40], Step [12400/16026], Loss: 0.0108\n",
      "Epoch [35/40], Step [12500/16026], Loss: 0.0167\n",
      "Epoch [35/40], Step [12600/16026], Loss: 0.0206\n",
      "Epoch [35/40], Step [12700/16026], Loss: 0.0131\n",
      "Epoch [35/40], Step [12800/16026], Loss: 0.0120\n",
      "Epoch [35/40], Step [12900/16026], Loss: 0.0270\n",
      "Epoch [35/40], Step [13000/16026], Loss: 0.0145\n",
      "Epoch [35/40], Step [13100/16026], Loss: 0.0249\n",
      "Epoch [35/40], Step [13200/16026], Loss: 0.0211\n",
      "Epoch [35/40], Step [13300/16026], Loss: 0.0161\n",
      "Epoch [35/40], Step [13400/16026], Loss: 0.0159\n",
      "Epoch [35/40], Step [13500/16026], Loss: 0.0151\n",
      "Epoch [35/40], Step [13600/16026], Loss: 0.0224\n",
      "Epoch [35/40], Step [13700/16026], Loss: 0.0168\n",
      "Epoch [35/40], Step [13800/16026], Loss: 0.0175\n",
      "Epoch [35/40], Step [13900/16026], Loss: 0.0241\n",
      "Epoch [35/40], Step [14000/16026], Loss: 0.0182\n",
      "Epoch [35/40], Step [14100/16026], Loss: 0.0175\n",
      "Epoch [35/40], Step [14200/16026], Loss: 0.0227\n",
      "Epoch [35/40], Step [14300/16026], Loss: 0.0213\n",
      "Epoch [35/40], Step [14400/16026], Loss: 0.0096\n",
      "Epoch [35/40], Step [14500/16026], Loss: 0.0145\n",
      "Epoch [35/40], Step [14600/16026], Loss: 0.0172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/40], Step [14700/16026], Loss: 0.0194\n",
      "Epoch [35/40], Step [14800/16026], Loss: 0.0145\n",
      "Epoch [35/40], Step [14900/16026], Loss: 0.0242\n",
      "Epoch [35/40], Step [15000/16026], Loss: 0.0162\n",
      "Epoch [35/40], Step [15100/16026], Loss: 0.0189\n",
      "Epoch [35/40], Step [15200/16026], Loss: 0.0192\n",
      "Epoch [35/40], Step [15300/16026], Loss: 0.0188\n",
      "Epoch [35/40], Step [15400/16026], Loss: 0.0186\n",
      "Epoch [35/40], Step [15500/16026], Loss: 0.0193\n",
      "Epoch [35/40], Step [15600/16026], Loss: 0.0142\n",
      "Epoch [35/40], Step [15700/16026], Loss: 0.0217\n",
      "Epoch [35/40], Step [15800/16026], Loss: 0.0252\n",
      "Epoch [35/40], Step [15900/16026], Loss: 0.0113\n",
      "Epoch [35/40], Step [16000/16026], Loss: 0.0182\n",
      "Epoch [36/40], Step [100/16026], Loss: 0.0239\n",
      "Epoch [36/40], Step [200/16026], Loss: 0.0207\n",
      "Epoch [36/40], Step [300/16026], Loss: 0.0155\n",
      "Epoch [36/40], Step [400/16026], Loss: 0.0389\n",
      "Epoch [36/40], Step [500/16026], Loss: 0.0232\n",
      "Epoch [36/40], Step [600/16026], Loss: 0.0179\n",
      "Epoch [36/40], Step [700/16026], Loss: 0.0340\n",
      "Epoch [36/40], Step [800/16026], Loss: 0.0172\n",
      "Epoch [36/40], Step [900/16026], Loss: 0.0236\n",
      "Epoch [36/40], Step [1000/16026], Loss: 0.0134\n",
      "Epoch [36/40], Step [1100/16026], Loss: 0.0187\n",
      "Epoch [36/40], Step [1200/16026], Loss: 0.0301\n",
      "Epoch [36/40], Step [1300/16026], Loss: 0.0173\n",
      "Epoch [36/40], Step [1400/16026], Loss: 0.0187\n",
      "Epoch [36/40], Step [1500/16026], Loss: 0.0192\n",
      "Epoch [36/40], Step [1600/16026], Loss: 0.0213\n",
      "Epoch [36/40], Step [1700/16026], Loss: 0.0386\n",
      "Epoch [36/40], Step [1800/16026], Loss: 0.0095\n",
      "Epoch [36/40], Step [1900/16026], Loss: 0.0219\n",
      "Epoch [36/40], Step [2000/16026], Loss: 0.0170\n",
      "Epoch [36/40], Step [2100/16026], Loss: 0.0207\n",
      "Epoch [36/40], Step [2200/16026], Loss: 0.0117\n",
      "Epoch [36/40], Step [2300/16026], Loss: 0.0229\n",
      "Epoch [36/40], Step [2400/16026], Loss: 0.0388\n",
      "Epoch [36/40], Step [2500/16026], Loss: 0.0182\n",
      "Epoch [36/40], Step [2600/16026], Loss: 0.0263\n",
      "Epoch [36/40], Step [2700/16026], Loss: 0.0312\n",
      "Epoch [36/40], Step [2800/16026], Loss: 0.0260\n",
      "Epoch [36/40], Step [2900/16026], Loss: 0.0145\n",
      "Epoch [36/40], Step [3000/16026], Loss: 0.0233\n",
      "Epoch [36/40], Step [3100/16026], Loss: 0.0152\n",
      "Epoch [36/40], Step [3200/16026], Loss: 0.0170\n",
      "Epoch [36/40], Step [3300/16026], Loss: 0.0225\n",
      "Epoch [36/40], Step [3400/16026], Loss: 0.0162\n",
      "Epoch [36/40], Step [3500/16026], Loss: 0.0178\n",
      "Epoch [36/40], Step [3600/16026], Loss: 0.0189\n",
      "Epoch [36/40], Step [3700/16026], Loss: 0.0276\n",
      "Epoch [36/40], Step [3800/16026], Loss: 0.0184\n",
      "Epoch [36/40], Step [3900/16026], Loss: 0.0203\n",
      "Epoch [36/40], Step [4000/16026], Loss: 0.0189\n",
      "Epoch [36/40], Step [4100/16026], Loss: 0.0250\n",
      "Epoch [36/40], Step [4200/16026], Loss: 0.0170\n",
      "Epoch [36/40], Step [4300/16026], Loss: 0.0241\n",
      "Epoch [36/40], Step [4400/16026], Loss: 0.0150\n",
      "Epoch [36/40], Step [4500/16026], Loss: 0.0182\n",
      "Epoch [36/40], Step [4600/16026], Loss: 0.0149\n",
      "Epoch [36/40], Step [4700/16026], Loss: 0.0214\n",
      "Epoch [36/40], Step [4800/16026], Loss: 0.0254\n",
      "Epoch [36/40], Step [4900/16026], Loss: 0.0210\n",
      "Epoch [36/40], Step [5000/16026], Loss: 0.0166\n",
      "Epoch [36/40], Step [5100/16026], Loss: 0.0180\n",
      "Epoch [36/40], Step [5200/16026], Loss: 0.0189\n",
      "Epoch [36/40], Step [5300/16026], Loss: 0.0163\n",
      "Epoch [36/40], Step [5400/16026], Loss: 0.0157\n",
      "Epoch [36/40], Step [5500/16026], Loss: 0.0084\n",
      "Epoch [36/40], Step [5600/16026], Loss: 0.0176\n",
      "Epoch [36/40], Step [5700/16026], Loss: 0.0185\n",
      "Epoch [36/40], Step [5800/16026], Loss: 0.0145\n",
      "Epoch [36/40], Step [5900/16026], Loss: 0.0112\n",
      "Epoch [36/40], Step [6000/16026], Loss: 0.0150\n",
      "Epoch [36/40], Step [6100/16026], Loss: 0.0366\n",
      "Epoch [36/40], Step [6200/16026], Loss: 0.0252\n",
      "Epoch [36/40], Step [6300/16026], Loss: 0.0170\n",
      "Epoch [36/40], Step [6400/16026], Loss: 0.0257\n",
      "Epoch [36/40], Step [6500/16026], Loss: 0.0645\n",
      "Epoch [36/40], Step [6600/16026], Loss: 0.0195\n",
      "Epoch [36/40], Step [6700/16026], Loss: 0.0121\n",
      "Epoch [36/40], Step [6800/16026], Loss: 0.0161\n",
      "Epoch [36/40], Step [6900/16026], Loss: 0.0217\n",
      "Epoch [36/40], Step [7000/16026], Loss: 0.0328\n",
      "Epoch [36/40], Step [7100/16026], Loss: 0.0106\n",
      "Epoch [36/40], Step [7200/16026], Loss: 0.0330\n",
      "Epoch [36/40], Step [7300/16026], Loss: 0.0163\n",
      "Epoch [36/40], Step [7400/16026], Loss: 0.0142\n",
      "Epoch [36/40], Step [7500/16026], Loss: 0.0151\n",
      "Epoch [36/40], Step [7600/16026], Loss: 0.0179\n",
      "Epoch [36/40], Step [7700/16026], Loss: 0.0214\n",
      "Epoch [36/40], Step [7800/16026], Loss: 0.0143\n",
      "Epoch [36/40], Step [7900/16026], Loss: 0.0161\n",
      "Epoch [36/40], Step [8000/16026], Loss: 0.0341\n",
      "Epoch [36/40], Step [8100/16026], Loss: 0.0210\n",
      "Epoch [36/40], Step [8200/16026], Loss: 0.0114\n",
      "Epoch [36/40], Step [8300/16026], Loss: 0.0184\n",
      "Epoch [36/40], Step [8400/16026], Loss: 0.0359\n",
      "Epoch [36/40], Step [8500/16026], Loss: 0.0240\n",
      "Epoch [36/40], Step [8600/16026], Loss: 0.0243\n",
      "Epoch [36/40], Step [8700/16026], Loss: 0.0344\n",
      "Epoch [36/40], Step [8800/16026], Loss: 0.0255\n",
      "Epoch [36/40], Step [8900/16026], Loss: 0.0226\n",
      "Epoch [36/40], Step [9000/16026], Loss: 0.0206\n",
      "Epoch [36/40], Step [9100/16026], Loss: 0.0230\n",
      "Epoch [36/40], Step [9200/16026], Loss: 0.0214\n",
      "Epoch [36/40], Step [9300/16026], Loss: 0.0167\n",
      "Epoch [36/40], Step [9400/16026], Loss: 0.0151\n",
      "Epoch [36/40], Step [9500/16026], Loss: 0.0142\n",
      "Epoch [36/40], Step [9600/16026], Loss: 0.0272\n",
      "Epoch [36/40], Step [9700/16026], Loss: 0.0159\n",
      "Epoch [36/40], Step [9800/16026], Loss: 0.0220\n",
      "Epoch [36/40], Step [9900/16026], Loss: 0.0150\n",
      "Epoch [36/40], Step [10000/16026], Loss: 0.0272\n",
      "Epoch [36/40], Step [10100/16026], Loss: 0.0162\n",
      "Epoch [36/40], Step [10200/16026], Loss: 0.0208\n",
      "Epoch [36/40], Step [10300/16026], Loss: 0.0320\n",
      "Epoch [36/40], Step [10400/16026], Loss: 0.0209\n",
      "Epoch [36/40], Step [10500/16026], Loss: 0.0238\n",
      "Epoch [36/40], Step [10600/16026], Loss: 0.0167\n",
      "Epoch [36/40], Step [10700/16026], Loss: 0.0226\n",
      "Epoch [36/40], Step [10800/16026], Loss: 0.0142\n",
      "Epoch [36/40], Step [10900/16026], Loss: 0.0243\n",
      "Epoch [36/40], Step [11000/16026], Loss: 0.0270\n",
      "Epoch [36/40], Step [11100/16026], Loss: 0.0175\n",
      "Epoch [36/40], Step [11200/16026], Loss: 0.0273\n",
      "Epoch [36/40], Step [11300/16026], Loss: 0.0175\n",
      "Epoch [36/40], Step [11400/16026], Loss: 0.0191\n",
      "Epoch [36/40], Step [11500/16026], Loss: 0.0133\n",
      "Epoch [36/40], Step [11600/16026], Loss: 0.0219\n",
      "Epoch [36/40], Step [11700/16026], Loss: 0.0229\n",
      "Epoch [36/40], Step [11800/16026], Loss: 0.0166\n",
      "Epoch [36/40], Step [11900/16026], Loss: 0.0192\n",
      "Epoch [36/40], Step [12000/16026], Loss: 0.0191\n",
      "Epoch [36/40], Step [12100/16026], Loss: 0.0192\n",
      "Epoch [36/40], Step [12200/16026], Loss: 0.0136\n",
      "Epoch [36/40], Step [12300/16026], Loss: 0.0169\n",
      "Epoch [36/40], Step [12400/16026], Loss: 0.0136\n",
      "Epoch [36/40], Step [12500/16026], Loss: 0.0184\n",
      "Epoch [36/40], Step [12600/16026], Loss: 0.0222\n",
      "Epoch [36/40], Step [12700/16026], Loss: 0.0228\n",
      "Epoch [36/40], Step [12800/16026], Loss: 0.0141\n",
      "Epoch [36/40], Step [12900/16026], Loss: 0.0201\n",
      "Epoch [36/40], Step [13000/16026], Loss: 0.0192\n",
      "Epoch [36/40], Step [13100/16026], Loss: 0.0135\n",
      "Epoch [36/40], Step [13200/16026], Loss: 0.0247\n",
      "Epoch [36/40], Step [13300/16026], Loss: 0.0290\n",
      "Epoch [36/40], Step [13400/16026], Loss: 0.0253\n",
      "Epoch [36/40], Step [13500/16026], Loss: 0.0191\n",
      "Epoch [36/40], Step [13600/16026], Loss: 0.0210\n",
      "Epoch [36/40], Step [13700/16026], Loss: 0.0250\n",
      "Epoch [36/40], Step [13800/16026], Loss: 0.0121\n",
      "Epoch [36/40], Step [13900/16026], Loss: 0.0211\n",
      "Epoch [36/40], Step [14000/16026], Loss: 0.0274\n",
      "Epoch [36/40], Step [14100/16026], Loss: 0.0184\n",
      "Epoch [36/40], Step [14200/16026], Loss: 0.0244\n",
      "Epoch [36/40], Step [14300/16026], Loss: 0.0171\n",
      "Epoch [36/40], Step [14400/16026], Loss: 0.0450\n",
      "Epoch [36/40], Step [14500/16026], Loss: 0.0245\n",
      "Epoch [36/40], Step [14600/16026], Loss: 0.0232\n",
      "Epoch [36/40], Step [14700/16026], Loss: 0.0218\n",
      "Epoch [36/40], Step [14800/16026], Loss: 0.0146\n",
      "Epoch [36/40], Step [14900/16026], Loss: 0.0113\n",
      "Epoch [36/40], Step [15000/16026], Loss: 0.0261\n",
      "Epoch [36/40], Step [15100/16026], Loss: 0.0192\n",
      "Epoch [36/40], Step [15200/16026], Loss: 0.0201\n",
      "Epoch [36/40], Step [15300/16026], Loss: 0.0164\n",
      "Epoch [36/40], Step [15400/16026], Loss: 0.0246\n",
      "Epoch [36/40], Step [15500/16026], Loss: 0.0200\n",
      "Epoch [36/40], Step [15600/16026], Loss: 0.0222\n",
      "Epoch [36/40], Step [15700/16026], Loss: 0.0153\n",
      "Epoch [36/40], Step [15800/16026], Loss: 0.0360\n",
      "Epoch [36/40], Step [15900/16026], Loss: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/40], Step [16000/16026], Loss: 0.0111\n",
      "Epoch [37/40], Step [100/16026], Loss: 0.0206\n",
      "Epoch [37/40], Step [200/16026], Loss: 0.0169\n",
      "Epoch [37/40], Step [300/16026], Loss: 0.0225\n",
      "Epoch [37/40], Step [400/16026], Loss: 0.0134\n",
      "Epoch [37/40], Step [500/16026], Loss: 0.0137\n",
      "Epoch [37/40], Step [600/16026], Loss: 0.0175\n",
      "Epoch [37/40], Step [700/16026], Loss: 0.0217\n",
      "Epoch [37/40], Step [800/16026], Loss: 0.0131\n",
      "Epoch [37/40], Step [900/16026], Loss: 0.0155\n",
      "Epoch [37/40], Step [1000/16026], Loss: 0.0279\n",
      "Epoch [37/40], Step [1100/16026], Loss: 0.0225\n",
      "Epoch [37/40], Step [1200/16026], Loss: 0.0249\n",
      "Epoch [37/40], Step [1300/16026], Loss: 0.0114\n",
      "Epoch [37/40], Step [1400/16026], Loss: 0.0144\n",
      "Epoch [37/40], Step [1500/16026], Loss: 0.0182\n",
      "Epoch [37/40], Step [1600/16026], Loss: 0.0239\n",
      "Epoch [37/40], Step [1700/16026], Loss: 0.0190\n",
      "Epoch [37/40], Step [1800/16026], Loss: 0.0187\n",
      "Epoch [37/40], Step [1900/16026], Loss: 0.0155\n",
      "Epoch [37/40], Step [2000/16026], Loss: 0.0162\n",
      "Epoch [37/40], Step [2100/16026], Loss: 0.0279\n",
      "Epoch [37/40], Step [2200/16026], Loss: 0.0146\n",
      "Epoch [37/40], Step [2300/16026], Loss: 0.0110\n",
      "Epoch [37/40], Step [2400/16026], Loss: 0.0139\n",
      "Epoch [37/40], Step [2500/16026], Loss: 0.0224\n",
      "Epoch [37/40], Step [2600/16026], Loss: 0.0271\n",
      "Epoch [37/40], Step [2700/16026], Loss: 0.0172\n",
      "Epoch [37/40], Step [2800/16026], Loss: 0.0171\n",
      "Epoch [37/40], Step [2900/16026], Loss: 0.0270\n",
      "Epoch [37/40], Step [3000/16026], Loss: 0.0401\n",
      "Epoch [37/40], Step [3100/16026], Loss: 0.0133\n",
      "Epoch [37/40], Step [3200/16026], Loss: 0.0149\n",
      "Epoch [37/40], Step [3300/16026], Loss: 0.0228\n",
      "Epoch [37/40], Step [3400/16026], Loss: 0.0305\n",
      "Epoch [37/40], Step [3500/16026], Loss: 0.0180\n",
      "Epoch [37/40], Step [3600/16026], Loss: 0.0201\n",
      "Epoch [37/40], Step [3700/16026], Loss: 0.0192\n",
      "Epoch [37/40], Step [3800/16026], Loss: 0.0242\n",
      "Epoch [37/40], Step [3900/16026], Loss: 0.0112\n",
      "Epoch [37/40], Step [4000/16026], Loss: 0.0192\n",
      "Epoch [37/40], Step [4100/16026], Loss: 0.0139\n",
      "Epoch [37/40], Step [4200/16026], Loss: 0.0281\n",
      "Epoch [37/40], Step [4300/16026], Loss: 0.0163\n",
      "Epoch [37/40], Step [4400/16026], Loss: 0.0224\n",
      "Epoch [37/40], Step [4500/16026], Loss: 0.0240\n",
      "Epoch [37/40], Step [4600/16026], Loss: 0.0320\n",
      "Epoch [37/40], Step [4700/16026], Loss: 0.0154\n",
      "Epoch [37/40], Step [4800/16026], Loss: 0.0155\n",
      "Epoch [37/40], Step [4900/16026], Loss: 0.0261\n",
      "Epoch [37/40], Step [5000/16026], Loss: 0.0339\n",
      "Epoch [37/40], Step [5100/16026], Loss: 0.0235\n",
      "Epoch [37/40], Step [5200/16026], Loss: 0.0237\n",
      "Epoch [37/40], Step [5300/16026], Loss: 0.0123\n",
      "Epoch [37/40], Step [5400/16026], Loss: 0.0209\n",
      "Epoch [37/40], Step [5500/16026], Loss: 0.0203\n",
      "Epoch [37/40], Step [5600/16026], Loss: 0.0173\n",
      "Epoch [37/40], Step [5700/16026], Loss: 0.0201\n",
      "Epoch [37/40], Step [5800/16026], Loss: 0.0211\n",
      "Epoch [37/40], Step [5900/16026], Loss: 0.0321\n",
      "Epoch [37/40], Step [6000/16026], Loss: 0.0253\n",
      "Epoch [37/40], Step [6100/16026], Loss: 0.0220\n",
      "Epoch [37/40], Step [6200/16026], Loss: 0.0189\n",
      "Epoch [37/40], Step [6300/16026], Loss: 0.0119\n",
      "Epoch [37/40], Step [6400/16026], Loss: 0.0244\n",
      "Epoch [37/40], Step [6500/16026], Loss: 0.0179\n",
      "Epoch [37/40], Step [6600/16026], Loss: 0.0134\n",
      "Epoch [37/40], Step [6700/16026], Loss: 0.0256\n",
      "Epoch [37/40], Step [6800/16026], Loss: 0.0216\n",
      "Epoch [37/40], Step [6900/16026], Loss: 0.0157\n",
      "Epoch [37/40], Step [7000/16026], Loss: 0.0395\n",
      "Epoch [37/40], Step [7100/16026], Loss: 0.0194\n",
      "Epoch [37/40], Step [7200/16026], Loss: 0.0149\n",
      "Epoch [37/40], Step [7300/16026], Loss: 0.0161\n",
      "Epoch [37/40], Step [7400/16026], Loss: 0.0160\n",
      "Epoch [37/40], Step [7500/16026], Loss: 0.0211\n",
      "Epoch [37/40], Step [7600/16026], Loss: 0.0275\n",
      "Epoch [37/40], Step [7700/16026], Loss: 0.0122\n",
      "Epoch [37/40], Step [7800/16026], Loss: 0.0167\n",
      "Epoch [37/40], Step [7900/16026], Loss: 0.0120\n",
      "Epoch [37/40], Step [8000/16026], Loss: 0.0318\n",
      "Epoch [37/40], Step [8100/16026], Loss: 0.0302\n",
      "Epoch [37/40], Step [8200/16026], Loss: 0.0124\n",
      "Epoch [37/40], Step [8300/16026], Loss: 0.0318\n",
      "Epoch [37/40], Step [8400/16026], Loss: 0.0238\n",
      "Epoch [37/40], Step [8500/16026], Loss: 0.0396\n",
      "Epoch [37/40], Step [8600/16026], Loss: 0.0176\n",
      "Epoch [37/40], Step [8700/16026], Loss: 0.0140\n",
      "Epoch [37/40], Step [8800/16026], Loss: 0.0139\n",
      "Epoch [37/40], Step [8900/16026], Loss: 0.0150\n",
      "Epoch [37/40], Step [9000/16026], Loss: 0.0207\n",
      "Epoch [37/40], Step [9100/16026], Loss: 0.0269\n",
      "Epoch [37/40], Step [9200/16026], Loss: 0.0222\n",
      "Epoch [37/40], Step [9300/16026], Loss: 0.0160\n",
      "Epoch [37/40], Step [9400/16026], Loss: 0.0145\n",
      "Epoch [37/40], Step [9500/16026], Loss: 0.0177\n",
      "Epoch [37/40], Step [9600/16026], Loss: 0.0127\n",
      "Epoch [37/40], Step [9700/16026], Loss: 0.0210\n",
      "Epoch [37/40], Step [9800/16026], Loss: 0.0126\n",
      "Epoch [37/40], Step [9900/16026], Loss: 0.0252\n",
      "Epoch [37/40], Step [10000/16026], Loss: 0.0173\n",
      "Epoch [37/40], Step [10100/16026], Loss: 0.0233\n",
      "Epoch [37/40], Step [10200/16026], Loss: 0.0182\n",
      "Epoch [37/40], Step [10300/16026], Loss: 0.0225\n",
      "Epoch [37/40], Step [10400/16026], Loss: 0.0161\n",
      "Epoch [37/40], Step [10500/16026], Loss: 0.0167\n",
      "Epoch [37/40], Step [10600/16026], Loss: 0.0284\n",
      "Epoch [37/40], Step [10700/16026], Loss: 0.0157\n",
      "Epoch [37/40], Step [10800/16026], Loss: 0.0163\n",
      "Epoch [37/40], Step [10900/16026], Loss: 0.0109\n",
      "Epoch [37/40], Step [11000/16026], Loss: 0.0135\n",
      "Epoch [37/40], Step [11100/16026], Loss: 0.0207\n",
      "Epoch [37/40], Step [11200/16026], Loss: 0.0157\n",
      "Epoch [37/40], Step [11300/16026], Loss: 0.0180\n",
      "Epoch [37/40], Step [11400/16026], Loss: 0.0133\n",
      "Epoch [37/40], Step [11500/16026], Loss: 0.0158\n",
      "Epoch [37/40], Step [11600/16026], Loss: 0.0130\n",
      "Epoch [37/40], Step [11700/16026], Loss: 0.0210\n",
      "Epoch [37/40], Step [11800/16026], Loss: 0.0085\n",
      "Epoch [37/40], Step [11900/16026], Loss: 0.0149\n",
      "Epoch [37/40], Step [12000/16026], Loss: 0.0180\n",
      "Epoch [37/40], Step [12100/16026], Loss: 0.0259\n",
      "Epoch [37/40], Step [12200/16026], Loss: 0.0251\n",
      "Epoch [37/40], Step [12300/16026], Loss: 0.0168\n",
      "Epoch [37/40], Step [12400/16026], Loss: 0.0226\n",
      "Epoch [37/40], Step [12500/16026], Loss: 0.0194\n",
      "Epoch [37/40], Step [12600/16026], Loss: 0.0281\n",
      "Epoch [37/40], Step [12700/16026], Loss: 0.0181\n",
      "Epoch [37/40], Step [12800/16026], Loss: 0.0156\n",
      "Epoch [37/40], Step [12900/16026], Loss: 0.0298\n",
      "Epoch [37/40], Step [13000/16026], Loss: 0.0101\n",
      "Epoch [37/40], Step [13100/16026], Loss: 0.0162\n",
      "Epoch [37/40], Step [13200/16026], Loss: 0.0188\n",
      "Epoch [37/40], Step [13300/16026], Loss: 0.0165\n",
      "Epoch [37/40], Step [13400/16026], Loss: 0.0183\n",
      "Epoch [37/40], Step [13500/16026], Loss: 0.0303\n",
      "Epoch [37/40], Step [13600/16026], Loss: 0.0258\n",
      "Epoch [37/40], Step [13700/16026], Loss: 0.0236\n",
      "Epoch [37/40], Step [13800/16026], Loss: 0.0228\n",
      "Epoch [37/40], Step [13900/16026], Loss: 0.0219\n",
      "Epoch [37/40], Step [14000/16026], Loss: 0.0230\n",
      "Epoch [37/40], Step [14100/16026], Loss: 0.0155\n",
      "Epoch [37/40], Step [14200/16026], Loss: 0.0228\n",
      "Epoch [37/40], Step [14300/16026], Loss: 0.0199\n",
      "Epoch [37/40], Step [14400/16026], Loss: 0.0174\n",
      "Epoch [37/40], Step [14500/16026], Loss: 0.0092\n",
      "Epoch [37/40], Step [14600/16026], Loss: 0.0163\n",
      "Epoch [37/40], Step [14700/16026], Loss: 0.0200\n",
      "Epoch [37/40], Step [14800/16026], Loss: 0.0301\n",
      "Epoch [37/40], Step [14900/16026], Loss: 0.0265\n",
      "Epoch [37/40], Step [15000/16026], Loss: 0.0184\n",
      "Epoch [37/40], Step [15100/16026], Loss: 0.0172\n",
      "Epoch [37/40], Step [15200/16026], Loss: 0.0196\n",
      "Epoch [37/40], Step [15300/16026], Loss: 0.0158\n",
      "Epoch [37/40], Step [15400/16026], Loss: 0.0207\n",
      "Epoch [37/40], Step [15500/16026], Loss: 0.0227\n",
      "Epoch [37/40], Step [15600/16026], Loss: 0.0180\n",
      "Epoch [37/40], Step [15700/16026], Loss: 0.0265\n",
      "Epoch [37/40], Step [15800/16026], Loss: 0.0232\n",
      "Epoch [37/40], Step [15900/16026], Loss: 0.0137\n",
      "Epoch [37/40], Step [16000/16026], Loss: 0.0189\n",
      "Epoch [38/40], Step [100/16026], Loss: 0.0212\n",
      "Epoch [38/40], Step [200/16026], Loss: 0.0200\n",
      "Epoch [38/40], Step [300/16026], Loss: 0.0184\n",
      "Epoch [38/40], Step [400/16026], Loss: 0.0133\n",
      "Epoch [38/40], Step [500/16026], Loss: 0.0208\n",
      "Epoch [38/40], Step [600/16026], Loss: 0.0213\n",
      "Epoch [38/40], Step [700/16026], Loss: 0.0341\n",
      "Epoch [38/40], Step [800/16026], Loss: 0.0213\n",
      "Epoch [38/40], Step [900/16026], Loss: 0.0122\n",
      "Epoch [38/40], Step [1000/16026], Loss: 0.0243\n",
      "Epoch [38/40], Step [1100/16026], Loss: 0.0285\n",
      "Epoch [38/40], Step [1200/16026], Loss: 0.0219\n",
      "Epoch [38/40], Step [1300/16026], Loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/40], Step [1400/16026], Loss: 0.0197\n",
      "Epoch [38/40], Step [1500/16026], Loss: 0.0215\n",
      "Epoch [38/40], Step [1600/16026], Loss: 0.0174\n",
      "Epoch [38/40], Step [1700/16026], Loss: 0.0217\n",
      "Epoch [38/40], Step [1800/16026], Loss: 0.0250\n",
      "Epoch [38/40], Step [1900/16026], Loss: 0.0110\n",
      "Epoch [38/40], Step [2000/16026], Loss: 0.0186\n",
      "Epoch [38/40], Step [2100/16026], Loss: 0.0222\n",
      "Epoch [38/40], Step [2200/16026], Loss: 0.0184\n",
      "Epoch [38/40], Step [2300/16026], Loss: 0.0284\n",
      "Epoch [38/40], Step [2400/16026], Loss: 0.0164\n",
      "Epoch [38/40], Step [2500/16026], Loss: 0.0172\n",
      "Epoch [38/40], Step [2600/16026], Loss: 0.0135\n",
      "Epoch [38/40], Step [2700/16026], Loss: 0.0190\n",
      "Epoch [38/40], Step [2800/16026], Loss: 0.0185\n",
      "Epoch [38/40], Step [2900/16026], Loss: 0.0200\n",
      "Epoch [38/40], Step [3000/16026], Loss: 0.0147\n",
      "Epoch [38/40], Step [3100/16026], Loss: 0.0137\n",
      "Epoch [38/40], Step [3200/16026], Loss: 0.0145\n",
      "Epoch [38/40], Step [3300/16026], Loss: 0.0186\n",
      "Epoch [38/40], Step [3400/16026], Loss: 0.0216\n",
      "Epoch [38/40], Step [3500/16026], Loss: 0.0230\n",
      "Epoch [38/40], Step [3600/16026], Loss: 0.0179\n",
      "Epoch [38/40], Step [3700/16026], Loss: 0.0220\n",
      "Epoch [38/40], Step [3800/16026], Loss: 0.0669\n",
      "Epoch [38/40], Step [3900/16026], Loss: 0.0122\n",
      "Epoch [38/40], Step [4000/16026], Loss: 0.0189\n",
      "Epoch [38/40], Step [4100/16026], Loss: 0.0295\n",
      "Epoch [38/40], Step [4200/16026], Loss: 0.0139\n",
      "Epoch [38/40], Step [4300/16026], Loss: 0.0122\n",
      "Epoch [38/40], Step [4400/16026], Loss: 0.0126\n",
      "Epoch [38/40], Step [4500/16026], Loss: 0.0207\n",
      "Epoch [38/40], Step [4600/16026], Loss: 0.0215\n",
      "Epoch [38/40], Step [4700/16026], Loss: 0.0132\n",
      "Epoch [38/40], Step [4800/16026], Loss: 0.0167\n",
      "Epoch [38/40], Step [4900/16026], Loss: 0.0256\n",
      "Epoch [38/40], Step [5000/16026], Loss: 0.0156\n",
      "Epoch [38/40], Step [5100/16026], Loss: 0.0119\n",
      "Epoch [38/40], Step [5200/16026], Loss: 0.0189\n",
      "Epoch [38/40], Step [5300/16026], Loss: 0.0291\n",
      "Epoch [38/40], Step [5400/16026], Loss: 0.0130\n",
      "Epoch [38/40], Step [5500/16026], Loss: 0.0180\n",
      "Epoch [38/40], Step [5600/16026], Loss: 0.0244\n",
      "Epoch [38/40], Step [5700/16026], Loss: 0.0186\n",
      "Epoch [38/40], Step [5800/16026], Loss: 0.0181\n",
      "Epoch [38/40], Step [5900/16026], Loss: 0.0163\n",
      "Epoch [38/40], Step [6000/16026], Loss: 0.0247\n",
      "Epoch [38/40], Step [6100/16026], Loss: 0.0191\n",
      "Epoch [38/40], Step [6200/16026], Loss: 0.0273\n",
      "Epoch [38/40], Step [6300/16026], Loss: 0.0160\n",
      "Epoch [38/40], Step [6400/16026], Loss: 0.0135\n",
      "Epoch [38/40], Step [6500/16026], Loss: 0.0263\n",
      "Epoch [38/40], Step [6600/16026], Loss: 0.0219\n",
      "Epoch [38/40], Step [6700/16026], Loss: 0.0129\n",
      "Epoch [38/40], Step [6800/16026], Loss: 0.0142\n",
      "Epoch [38/40], Step [6900/16026], Loss: 0.0168\n",
      "Epoch [38/40], Step [7000/16026], Loss: 0.0125\n",
      "Epoch [38/40], Step [7100/16026], Loss: 0.0285\n",
      "Epoch [38/40], Step [7200/16026], Loss: 0.0163\n",
      "Epoch [38/40], Step [7300/16026], Loss: 0.0190\n",
      "Epoch [38/40], Step [7400/16026], Loss: 0.0208\n",
      "Epoch [38/40], Step [7500/16026], Loss: 0.0135\n",
      "Epoch [38/40], Step [7600/16026], Loss: 0.0149\n",
      "Epoch [38/40], Step [7700/16026], Loss: 0.0259\n",
      "Epoch [38/40], Step [7800/16026], Loss: 0.0372\n",
      "Epoch [38/40], Step [7900/16026], Loss: 0.0295\n",
      "Epoch [38/40], Step [8000/16026], Loss: 0.0260\n",
      "Epoch [38/40], Step [8100/16026], Loss: 0.0100\n",
      "Epoch [38/40], Step [8200/16026], Loss: 0.0179\n",
      "Epoch [38/40], Step [8300/16026], Loss: 0.0116\n",
      "Epoch [38/40], Step [8400/16026], Loss: 0.0254\n",
      "Epoch [38/40], Step [8500/16026], Loss: 0.0136\n",
      "Epoch [38/40], Step [8600/16026], Loss: 0.0200\n",
      "Epoch [38/40], Step [8700/16026], Loss: 0.0167\n",
      "Epoch [38/40], Step [8800/16026], Loss: 0.0316\n",
      "Epoch [38/40], Step [8900/16026], Loss: 0.0185\n",
      "Epoch [38/40], Step [9000/16026], Loss: 0.0130\n",
      "Epoch [38/40], Step [9100/16026], Loss: 0.0172\n",
      "Epoch [38/40], Step [9200/16026], Loss: 0.0147\n",
      "Epoch [38/40], Step [9300/16026], Loss: 0.0219\n",
      "Epoch [38/40], Step [9400/16026], Loss: 0.0282\n",
      "Epoch [38/40], Step [9500/16026], Loss: 0.0267\n",
      "Epoch [38/40], Step [9600/16026], Loss: 0.0188\n",
      "Epoch [38/40], Step [9700/16026], Loss: 0.0251\n",
      "Epoch [38/40], Step [9800/16026], Loss: 0.0149\n",
      "Epoch [38/40], Step [9900/16026], Loss: 0.0202\n",
      "Epoch [38/40], Step [10000/16026], Loss: 0.0139\n",
      "Epoch [38/40], Step [10100/16026], Loss: 0.0174\n",
      "Epoch [38/40], Step [10200/16026], Loss: 0.0217\n",
      "Epoch [38/40], Step [10300/16026], Loss: 0.0222\n",
      "Epoch [38/40], Step [10400/16026], Loss: 0.0492\n",
      "Epoch [38/40], Step [10500/16026], Loss: 0.0253\n",
      "Epoch [38/40], Step [10600/16026], Loss: 0.0085\n",
      "Epoch [38/40], Step [10700/16026], Loss: 0.0165\n",
      "Epoch [38/40], Step [10800/16026], Loss: 0.0285\n",
      "Epoch [38/40], Step [10900/16026], Loss: 0.0122\n",
      "Epoch [38/40], Step [11000/16026], Loss: 0.0163\n",
      "Epoch [38/40], Step [11100/16026], Loss: 0.0259\n",
      "Epoch [38/40], Step [11200/16026], Loss: 0.0217\n",
      "Epoch [38/40], Step [11300/16026], Loss: 0.0228\n",
      "Epoch [38/40], Step [11400/16026], Loss: 0.0213\n",
      "Epoch [38/40], Step [11500/16026], Loss: 0.0174\n",
      "Epoch [38/40], Step [11600/16026], Loss: 0.0281\n",
      "Epoch [38/40], Step [11700/16026], Loss: 0.0204\n",
      "Epoch [38/40], Step [11800/16026], Loss: 0.0161\n",
      "Epoch [38/40], Step [11900/16026], Loss: 0.0157\n",
      "Epoch [38/40], Step [12000/16026], Loss: 0.0192\n",
      "Epoch [38/40], Step [12100/16026], Loss: 0.0111\n",
      "Epoch [38/40], Step [12200/16026], Loss: 0.0264\n",
      "Epoch [38/40], Step [12300/16026], Loss: 0.0159\n",
      "Epoch [38/40], Step [12400/16026], Loss: 0.0156\n",
      "Epoch [38/40], Step [12500/16026], Loss: 0.0162\n",
      "Epoch [38/40], Step [12600/16026], Loss: 0.0183\n",
      "Epoch [38/40], Step [12700/16026], Loss: 0.0226\n",
      "Epoch [38/40], Step [12800/16026], Loss: 0.0303\n",
      "Epoch [38/40], Step [12900/16026], Loss: 0.0189\n",
      "Epoch [38/40], Step [13000/16026], Loss: 0.0358\n",
      "Epoch [38/40], Step [13100/16026], Loss: 0.0122\n",
      "Epoch [38/40], Step [13200/16026], Loss: 0.0212\n",
      "Epoch [38/40], Step [13300/16026], Loss: 0.0190\n",
      "Epoch [38/40], Step [13400/16026], Loss: 0.0205\n",
      "Epoch [38/40], Step [13500/16026], Loss: 0.0196\n",
      "Epoch [38/40], Step [13600/16026], Loss: 0.0298\n",
      "Epoch [38/40], Step [13700/16026], Loss: 0.0109\n",
      "Epoch [38/40], Step [13800/16026], Loss: 0.0154\n",
      "Epoch [38/40], Step [13900/16026], Loss: 0.0199\n",
      "Epoch [38/40], Step [14000/16026], Loss: 0.0232\n",
      "Epoch [38/40], Step [14100/16026], Loss: 0.0234\n",
      "Epoch [38/40], Step [14200/16026], Loss: 0.0192\n",
      "Epoch [38/40], Step [14300/16026], Loss: 0.0220\n",
      "Epoch [38/40], Step [14400/16026], Loss: 0.0215\n",
      "Epoch [38/40], Step [14500/16026], Loss: 0.0213\n",
      "Epoch [38/40], Step [14600/16026], Loss: 0.0102\n",
      "Epoch [38/40], Step [14700/16026], Loss: 0.0115\n",
      "Epoch [38/40], Step [14800/16026], Loss: 0.0173\n",
      "Epoch [38/40], Step [14900/16026], Loss: 0.0176\n",
      "Epoch [38/40], Step [15000/16026], Loss: 0.0196\n",
      "Epoch [38/40], Step [15100/16026], Loss: 0.0177\n",
      "Epoch [38/40], Step [15200/16026], Loss: 0.0127\n",
      "Epoch [38/40], Step [15300/16026], Loss: 0.0224\n",
      "Epoch [38/40], Step [15400/16026], Loss: 0.0263\n",
      "Epoch [38/40], Step [15500/16026], Loss: 0.0117\n",
      "Epoch [38/40], Step [15600/16026], Loss: 0.0126\n",
      "Epoch [38/40], Step [15700/16026], Loss: 0.0181\n",
      "Epoch [38/40], Step [15800/16026], Loss: 0.0240\n",
      "Epoch [38/40], Step [15900/16026], Loss: 0.0170\n",
      "Epoch [38/40], Step [16000/16026], Loss: 0.0165\n",
      "Epoch [39/40], Step [100/16026], Loss: 0.0100\n",
      "Epoch [39/40], Step [200/16026], Loss: 0.0194\n",
      "Epoch [39/40], Step [300/16026], Loss: 0.0172\n",
      "Epoch [39/40], Step [400/16026], Loss: 0.0216\n",
      "Epoch [39/40], Step [500/16026], Loss: 0.0180\n",
      "Epoch [39/40], Step [600/16026], Loss: 0.0132\n",
      "Epoch [39/40], Step [700/16026], Loss: 0.0201\n",
      "Epoch [39/40], Step [800/16026], Loss: 0.0190\n",
      "Epoch [39/40], Step [900/16026], Loss: 0.0216\n",
      "Epoch [39/40], Step [1000/16026], Loss: 0.0186\n",
      "Epoch [39/40], Step [1100/16026], Loss: 0.0624\n",
      "Epoch [39/40], Step [1200/16026], Loss: 0.0216\n",
      "Epoch [39/40], Step [1300/16026], Loss: 0.0130\n",
      "Epoch [39/40], Step [1400/16026], Loss: 0.0343\n",
      "Epoch [39/40], Step [1500/16026], Loss: 0.0332\n",
      "Epoch [39/40], Step [1600/16026], Loss: 0.0222\n",
      "Epoch [39/40], Step [1700/16026], Loss: 0.0267\n",
      "Epoch [39/40], Step [1800/16026], Loss: 0.0184\n",
      "Epoch [39/40], Step [1900/16026], Loss: 0.0199\n",
      "Epoch [39/40], Step [2000/16026], Loss: 0.0169\n",
      "Epoch [39/40], Step [2100/16026], Loss: 0.0082\n",
      "Epoch [39/40], Step [2200/16026], Loss: 0.0276\n",
      "Epoch [39/40], Step [2300/16026], Loss: 0.0351\n",
      "Epoch [39/40], Step [2400/16026], Loss: 0.0163\n",
      "Epoch [39/40], Step [2500/16026], Loss: 0.0192\n",
      "Epoch [39/40], Step [2600/16026], Loss: 0.0166\n",
      "Epoch [39/40], Step [2700/16026], Loss: 0.0115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/40], Step [2800/16026], Loss: 0.0126\n",
      "Epoch [39/40], Step [2900/16026], Loss: 0.0222\n",
      "Epoch [39/40], Step [3000/16026], Loss: 0.0177\n",
      "Epoch [39/40], Step [3100/16026], Loss: 0.0226\n",
      "Epoch [39/40], Step [3200/16026], Loss: 0.0149\n",
      "Epoch [39/40], Step [3300/16026], Loss: 0.0235\n",
      "Epoch [39/40], Step [3400/16026], Loss: 0.0227\n",
      "Epoch [39/40], Step [3500/16026], Loss: 0.0156\n",
      "Epoch [39/40], Step [3600/16026], Loss: 0.0320\n",
      "Epoch [39/40], Step [3700/16026], Loss: 0.0145\n",
      "Epoch [39/40], Step [3800/16026], Loss: 0.0127\n",
      "Epoch [39/40], Step [3900/16026], Loss: 0.0211\n",
      "Epoch [39/40], Step [4000/16026], Loss: 0.0120\n",
      "Epoch [39/40], Step [4100/16026], Loss: 0.0282\n",
      "Epoch [39/40], Step [4200/16026], Loss: 0.0187\n",
      "Epoch [39/40], Step [4300/16026], Loss: 0.0213\n",
      "Epoch [39/40], Step [4400/16026], Loss: 0.0290\n",
      "Epoch [39/40], Step [4500/16026], Loss: 0.0234\n",
      "Epoch [39/40], Step [4600/16026], Loss: 0.0239\n",
      "Epoch [39/40], Step [4700/16026], Loss: 0.0202\n",
      "Epoch [39/40], Step [4800/16026], Loss: 0.0188\n",
      "Epoch [39/40], Step [4900/16026], Loss: 0.0181\n",
      "Epoch [39/40], Step [5000/16026], Loss: 0.0122\n",
      "Epoch [39/40], Step [5100/16026], Loss: 0.0182\n",
      "Epoch [39/40], Step [5200/16026], Loss: 0.0260\n",
      "Epoch [39/40], Step [5300/16026], Loss: 0.0172\n",
      "Epoch [39/40], Step [5400/16026], Loss: 0.0174\n",
      "Epoch [39/40], Step [5500/16026], Loss: 0.0170\n",
      "Epoch [39/40], Step [5600/16026], Loss: 0.0222\n",
      "Epoch [39/40], Step [5700/16026], Loss: 0.0348\n",
      "Epoch [39/40], Step [5800/16026], Loss: 0.0192\n",
      "Epoch [39/40], Step [5900/16026], Loss: 0.0209\n",
      "Epoch [39/40], Step [6000/16026], Loss: 0.0179\n",
      "Epoch [39/40], Step [6100/16026], Loss: 0.0197\n",
      "Epoch [39/40], Step [6200/16026], Loss: 0.0166\n",
      "Epoch [39/40], Step [6300/16026], Loss: 0.0113\n",
      "Epoch [39/40], Step [6400/16026], Loss: 0.0134\n",
      "Epoch [39/40], Step [6500/16026], Loss: 0.0172\n",
      "Epoch [39/40], Step [6600/16026], Loss: 0.0199\n",
      "Epoch [39/40], Step [6700/16026], Loss: 0.0221\n",
      "Epoch [39/40], Step [6800/16026], Loss: 0.0164\n",
      "Epoch [39/40], Step [6900/16026], Loss: 0.0319\n",
      "Epoch [39/40], Step [7000/16026], Loss: 0.0073\n",
      "Epoch [39/40], Step [7100/16026], Loss: 0.0277\n",
      "Epoch [39/40], Step [7200/16026], Loss: 0.0256\n",
      "Epoch [39/40], Step [7300/16026], Loss: 0.0233\n",
      "Epoch [39/40], Step [7400/16026], Loss: 0.0156\n",
      "Epoch [39/40], Step [7500/16026], Loss: 0.0188\n",
      "Epoch [39/40], Step [7600/16026], Loss: 0.0213\n",
      "Epoch [39/40], Step [7700/16026], Loss: 0.0185\n",
      "Epoch [39/40], Step [7800/16026], Loss: 0.0183\n",
      "Epoch [39/40], Step [7900/16026], Loss: 0.0228\n",
      "Epoch [39/40], Step [8000/16026], Loss: 0.0236\n",
      "Epoch [39/40], Step [8100/16026], Loss: 0.0181\n",
      "Epoch [39/40], Step [8200/16026], Loss: 0.0312\n",
      "Epoch [39/40], Step [8300/16026], Loss: 0.0172\n",
      "Epoch [39/40], Step [8400/16026], Loss: 0.0165\n",
      "Epoch [39/40], Step [8500/16026], Loss: 0.0172\n",
      "Epoch [39/40], Step [8600/16026], Loss: 0.0257\n",
      "Epoch [39/40], Step [8700/16026], Loss: 0.0259\n",
      "Epoch [39/40], Step [8800/16026], Loss: 0.0251\n",
      "Epoch [39/40], Step [8900/16026], Loss: 0.0137\n",
      "Epoch [39/40], Step [9000/16026], Loss: 0.0081\n",
      "Epoch [39/40], Step [9100/16026], Loss: 0.0450\n",
      "Epoch [39/40], Step [9200/16026], Loss: 0.0268\n",
      "Epoch [39/40], Step [9300/16026], Loss: 0.0161\n",
      "Epoch [39/40], Step [9400/16026], Loss: 0.0115\n",
      "Epoch [39/40], Step [9500/16026], Loss: 0.0126\n",
      "Epoch [39/40], Step [9600/16026], Loss: 0.0224\n",
      "Epoch [39/40], Step [9700/16026], Loss: 0.0211\n",
      "Epoch [39/40], Step [9800/16026], Loss: 0.0159\n",
      "Epoch [39/40], Step [9900/16026], Loss: 0.0206\n",
      "Epoch [39/40], Step [10000/16026], Loss: 0.0708\n",
      "Epoch [39/40], Step [10100/16026], Loss: 0.0188\n",
      "Epoch [39/40], Step [10200/16026], Loss: 0.0102\n",
      "Epoch [39/40], Step [10300/16026], Loss: 0.0208\n",
      "Epoch [39/40], Step [10400/16026], Loss: 0.0173\n",
      "Epoch [39/40], Step [10500/16026], Loss: 0.0308\n",
      "Epoch [39/40], Step [10600/16026], Loss: 0.0202\n",
      "Epoch [39/40], Step [10700/16026], Loss: 0.0209\n",
      "Epoch [39/40], Step [10800/16026], Loss: 0.0256\n",
      "Epoch [39/40], Step [10900/16026], Loss: 0.0261\n",
      "Epoch [39/40], Step [11000/16026], Loss: 0.0154\n",
      "Epoch [39/40], Step [11100/16026], Loss: 0.0109\n",
      "Epoch [39/40], Step [11200/16026], Loss: 0.0216\n",
      "Epoch [39/40], Step [11300/16026], Loss: 0.0243\n",
      "Epoch [39/40], Step [11400/16026], Loss: 0.0300\n",
      "Epoch [39/40], Step [11500/16026], Loss: 0.0166\n",
      "Epoch [39/40], Step [11600/16026], Loss: 0.0172\n",
      "Epoch [39/40], Step [11700/16026], Loss: 0.0182\n",
      "Epoch [39/40], Step [11800/16026], Loss: 0.0261\n",
      "Epoch [39/40], Step [11900/16026], Loss: 0.0135\n",
      "Epoch [39/40], Step [12000/16026], Loss: 0.0204\n",
      "Epoch [39/40], Step [12100/16026], Loss: 0.0221\n",
      "Epoch [39/40], Step [12200/16026], Loss: 0.0153\n",
      "Epoch [39/40], Step [12300/16026], Loss: 0.0170\n",
      "Epoch [39/40], Step [12400/16026], Loss: 0.0124\n",
      "Epoch [39/40], Step [12500/16026], Loss: 0.0212\n",
      "Epoch [39/40], Step [12600/16026], Loss: 0.0208\n",
      "Epoch [39/40], Step [12700/16026], Loss: 0.0152\n",
      "Epoch [39/40], Step [12800/16026], Loss: 0.0222\n",
      "Epoch [39/40], Step [12900/16026], Loss: 0.0163\n",
      "Epoch [39/40], Step [13000/16026], Loss: 0.0162\n",
      "Epoch [39/40], Step [13100/16026], Loss: 0.0238\n",
      "Epoch [39/40], Step [13200/16026], Loss: 0.0157\n",
      "Epoch [39/40], Step [13300/16026], Loss: 0.0309\n",
      "Epoch [39/40], Step [13400/16026], Loss: 0.0168\n",
      "Epoch [39/40], Step [13500/16026], Loss: 0.0192\n",
      "Epoch [39/40], Step [13600/16026], Loss: 0.0102\n",
      "Epoch [39/40], Step [13700/16026], Loss: 0.0184\n",
      "Epoch [39/40], Step [13800/16026], Loss: 0.0178\n",
      "Epoch [39/40], Step [13900/16026], Loss: 0.0138\n",
      "Epoch [39/40], Step [14000/16026], Loss: 0.0183\n",
      "Epoch [39/40], Step [14100/16026], Loss: 0.0173\n",
      "Epoch [39/40], Step [14200/16026], Loss: 0.0200\n",
      "Epoch [39/40], Step [14300/16026], Loss: 0.0194\n",
      "Epoch [39/40], Step [14400/16026], Loss: 0.0185\n",
      "Epoch [39/40], Step [14500/16026], Loss: 0.0089\n",
      "Epoch [39/40], Step [14600/16026], Loss: 0.0159\n",
      "Epoch [39/40], Step [14700/16026], Loss: 0.0188\n",
      "Epoch [39/40], Step [14800/16026], Loss: 0.0158\n",
      "Epoch [39/40], Step [14900/16026], Loss: 0.0222\n",
      "Epoch [39/40], Step [15000/16026], Loss: 0.0161\n",
      "Epoch [39/40], Step [15100/16026], Loss: 0.0240\n",
      "Epoch [39/40], Step [15200/16026], Loss: 0.0223\n",
      "Epoch [39/40], Step [15300/16026], Loss: 0.0134\n",
      "Epoch [39/40], Step [15400/16026], Loss: 0.0306\n",
      "Epoch [39/40], Step [15500/16026], Loss: 0.0127\n",
      "Epoch [39/40], Step [15600/16026], Loss: 0.0203\n",
      "Epoch [39/40], Step [15700/16026], Loss: 0.0136\n",
      "Epoch [39/40], Step [15800/16026], Loss: 0.0148\n",
      "Epoch [39/40], Step [15900/16026], Loss: 0.0255\n",
      "Epoch [39/40], Step [16000/16026], Loss: 0.0233\n",
      "Epoch [40/40], Step [100/16026], Loss: 0.0136\n",
      "Epoch [40/40], Step [200/16026], Loss: 0.0586\n",
      "Epoch [40/40], Step [300/16026], Loss: 0.0253\n",
      "Epoch [40/40], Step [400/16026], Loss: 0.0112\n",
      "Epoch [40/40], Step [500/16026], Loss: 0.0160\n",
      "Epoch [40/40], Step [600/16026], Loss: 0.0214\n",
      "Epoch [40/40], Step [700/16026], Loss: 0.0135\n",
      "Epoch [40/40], Step [800/16026], Loss: 0.0130\n",
      "Epoch [40/40], Step [900/16026], Loss: 0.0303\n",
      "Epoch [40/40], Step [1000/16026], Loss: 0.0196\n",
      "Epoch [40/40], Step [1100/16026], Loss: 0.0227\n",
      "Epoch [40/40], Step [1200/16026], Loss: 0.0213\n",
      "Epoch [40/40], Step [1300/16026], Loss: 0.0138\n",
      "Epoch [40/40], Step [1400/16026], Loss: 0.0165\n",
      "Epoch [40/40], Step [1500/16026], Loss: 0.0111\n",
      "Epoch [40/40], Step [1600/16026], Loss: 0.0138\n",
      "Epoch [40/40], Step [1700/16026], Loss: 0.0162\n",
      "Epoch [40/40], Step [1800/16026], Loss: 0.0131\n",
      "Epoch [40/40], Step [1900/16026], Loss: 0.0172\n",
      "Epoch [40/40], Step [2000/16026], Loss: 0.0179\n",
      "Epoch [40/40], Step [2100/16026], Loss: 0.0098\n",
      "Epoch [40/40], Step [2200/16026], Loss: 0.0135\n",
      "Epoch [40/40], Step [2300/16026], Loss: 0.0198\n",
      "Epoch [40/40], Step [2400/16026], Loss: 0.0273\n",
      "Epoch [40/40], Step [2500/16026], Loss: 0.0115\n",
      "Epoch [40/40], Step [2600/16026], Loss: 0.0246\n",
      "Epoch [40/40], Step [2700/16026], Loss: 0.0172\n",
      "Epoch [40/40], Step [2800/16026], Loss: 0.0193\n",
      "Epoch [40/40], Step [2900/16026], Loss: 0.0290\n",
      "Epoch [40/40], Step [3000/16026], Loss: 0.0240\n",
      "Epoch [40/40], Step [3100/16026], Loss: 0.0196\n",
      "Epoch [40/40], Step [3200/16026], Loss: 0.0174\n",
      "Epoch [40/40], Step [3300/16026], Loss: 0.0263\n",
      "Epoch [40/40], Step [3400/16026], Loss: 0.0200\n",
      "Epoch [40/40], Step [3500/16026], Loss: 0.0154\n",
      "Epoch [40/40], Step [3600/16026], Loss: 0.0176\n",
      "Epoch [40/40], Step [3700/16026], Loss: 0.0118\n",
      "Epoch [40/40], Step [3800/16026], Loss: 0.0177\n",
      "Epoch [40/40], Step [3900/16026], Loss: 0.0183\n",
      "Epoch [40/40], Step [4000/16026], Loss: 0.0185\n",
      "Epoch [40/40], Step [4100/16026], Loss: 0.0175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/40], Step [4200/16026], Loss: 0.0545\n",
      "Epoch [40/40], Step [4300/16026], Loss: 0.0198\n",
      "Epoch [40/40], Step [4400/16026], Loss: 0.0219\n",
      "Epoch [40/40], Step [4500/16026], Loss: 0.0242\n",
      "Epoch [40/40], Step [4600/16026], Loss: 0.0184\n",
      "Epoch [40/40], Step [4700/16026], Loss: 0.0158\n",
      "Epoch [40/40], Step [4800/16026], Loss: 0.0218\n",
      "Epoch [40/40], Step [4900/16026], Loss: 0.0110\n",
      "Epoch [40/40], Step [5000/16026], Loss: 0.0190\n",
      "Epoch [40/40], Step [5100/16026], Loss: 0.0251\n",
      "Epoch [40/40], Step [5200/16026], Loss: 0.0176\n",
      "Epoch [40/40], Step [5300/16026], Loss: 0.0205\n",
      "Epoch [40/40], Step [5400/16026], Loss: 0.0160\n",
      "Epoch [40/40], Step [5500/16026], Loss: 0.0210\n",
      "Epoch [40/40], Step [5600/16026], Loss: 0.0181\n",
      "Epoch [40/40], Step [5700/16026], Loss: 0.0180\n",
      "Epoch [40/40], Step [5800/16026], Loss: 0.0139\n",
      "Epoch [40/40], Step [5900/16026], Loss: 0.0263\n",
      "Epoch [40/40], Step [6000/16026], Loss: 0.0227\n",
      "Epoch [40/40], Step [6100/16026], Loss: 0.0190\n",
      "Epoch [40/40], Step [6200/16026], Loss: 0.0185\n",
      "Epoch [40/40], Step [6300/16026], Loss: 0.0139\n",
      "Epoch [40/40], Step [6400/16026], Loss: 0.0207\n",
      "Epoch [40/40], Step [6500/16026], Loss: 0.0227\n",
      "Epoch [40/40], Step [6600/16026], Loss: 0.0118\n",
      "Epoch [40/40], Step [6700/16026], Loss: 0.0194\n",
      "Epoch [40/40], Step [6800/16026], Loss: 0.0147\n",
      "Epoch [40/40], Step [6900/16026], Loss: 0.0100\n",
      "Epoch [40/40], Step [7000/16026], Loss: 0.0174\n",
      "Epoch [40/40], Step [7100/16026], Loss: 0.0204\n",
      "Epoch [40/40], Step [7200/16026], Loss: 0.0221\n",
      "Epoch [40/40], Step [7300/16026], Loss: 0.0153\n",
      "Epoch [40/40], Step [7400/16026], Loss: 0.0135\n",
      "Epoch [40/40], Step [7500/16026], Loss: 0.0250\n",
      "Epoch [40/40], Step [7600/16026], Loss: 0.0145\n",
      "Epoch [40/40], Step [7700/16026], Loss: 0.0155\n",
      "Epoch [40/40], Step [7800/16026], Loss: 0.0213\n",
      "Epoch [40/40], Step [7900/16026], Loss: 0.0144\n",
      "Epoch [40/40], Step [8000/16026], Loss: 0.0220\n",
      "Epoch [40/40], Step [8100/16026], Loss: 0.0230\n",
      "Epoch [40/40], Step [8200/16026], Loss: 0.0169\n",
      "Epoch [40/40], Step [8300/16026], Loss: 0.0181\n",
      "Epoch [40/40], Step [8400/16026], Loss: 0.0543\n",
      "Epoch [40/40], Step [8500/16026], Loss: 0.0269\n",
      "Epoch [40/40], Step [8600/16026], Loss: 0.0238\n",
      "Epoch [40/40], Step [8700/16026], Loss: 0.0157\n",
      "Epoch [40/40], Step [8800/16026], Loss: 0.0185\n",
      "Epoch [40/40], Step [8900/16026], Loss: 0.0267\n",
      "Epoch [40/40], Step [9000/16026], Loss: 0.0157\n",
      "Epoch [40/40], Step [9100/16026], Loss: 0.0230\n",
      "Epoch [40/40], Step [9200/16026], Loss: 0.0141\n",
      "Epoch [40/40], Step [9300/16026], Loss: 0.0171\n",
      "Epoch [40/40], Step [9400/16026], Loss: 0.0245\n",
      "Epoch [40/40], Step [9500/16026], Loss: 0.0127\n",
      "Epoch [40/40], Step [9600/16026], Loss: 0.0155\n",
      "Epoch [40/40], Step [9700/16026], Loss: 0.0111\n",
      "Epoch [40/40], Step [9800/16026], Loss: 0.0177\n",
      "Epoch [40/40], Step [9900/16026], Loss: 0.0267\n",
      "Epoch [40/40], Step [10000/16026], Loss: 0.0144\n",
      "Epoch [40/40], Step [10100/16026], Loss: 0.0175\n",
      "Epoch [40/40], Step [10200/16026], Loss: 0.0221\n",
      "Epoch [40/40], Step [10300/16026], Loss: 0.0272\n",
      "Epoch [40/40], Step [10400/16026], Loss: 0.0326\n",
      "Epoch [40/40], Step [10500/16026], Loss: 0.0255\n",
      "Epoch [40/40], Step [10600/16026], Loss: 0.0181\n",
      "Epoch [40/40], Step [10700/16026], Loss: 0.0124\n",
      "Epoch [40/40], Step [10800/16026], Loss: 0.0216\n",
      "Epoch [40/40], Step [10900/16026], Loss: 0.0166\n",
      "Epoch [40/40], Step [11000/16026], Loss: 0.0248\n",
      "Epoch [40/40], Step [11100/16026], Loss: 0.0185\n",
      "Epoch [40/40], Step [11200/16026], Loss: 0.0266\n",
      "Epoch [40/40], Step [11300/16026], Loss: 0.0195\n",
      "Epoch [40/40], Step [11400/16026], Loss: 0.0154\n",
      "Epoch [40/40], Step [11500/16026], Loss: 0.0302\n",
      "Epoch [40/40], Step [11600/16026], Loss: 0.0222\n",
      "Epoch [40/40], Step [11700/16026], Loss: 0.0195\n",
      "Epoch [40/40], Step [11800/16026], Loss: 0.0229\n",
      "Epoch [40/40], Step [11900/16026], Loss: 0.0316\n",
      "Epoch [40/40], Step [12000/16026], Loss: 0.0113\n",
      "Epoch [40/40], Step [12100/16026], Loss: 0.0294\n",
      "Epoch [40/40], Step [12200/16026], Loss: 0.0270\n",
      "Epoch [40/40], Step [12300/16026], Loss: 0.0214\n",
      "Epoch [40/40], Step [12400/16026], Loss: 0.0122\n",
      "Epoch [40/40], Step [12500/16026], Loss: 0.0239\n",
      "Epoch [40/40], Step [12600/16026], Loss: 0.0173\n",
      "Epoch [40/40], Step [12700/16026], Loss: 0.0277\n",
      "Epoch [40/40], Step [12800/16026], Loss: 0.0214\n",
      "Epoch [40/40], Step [12900/16026], Loss: 0.0215\n",
      "Epoch [40/40], Step [13000/16026], Loss: 0.0139\n",
      "Epoch [40/40], Step [13100/16026], Loss: 0.0145\n",
      "Epoch [40/40], Step [13200/16026], Loss: 0.0184\n",
      "Epoch [40/40], Step [13300/16026], Loss: 0.0222\n",
      "Epoch [40/40], Step [13400/16026], Loss: 0.0157\n",
      "Epoch [40/40], Step [13500/16026], Loss: 0.0216\n",
      "Epoch [40/40], Step [13600/16026], Loss: 0.0237\n",
      "Epoch [40/40], Step [13700/16026], Loss: 0.0182\n",
      "Epoch [40/40], Step [13800/16026], Loss: 0.0152\n",
      "Epoch [40/40], Step [13900/16026], Loss: 0.0244\n",
      "Epoch [40/40], Step [14000/16026], Loss: 0.0140\n",
      "Epoch [40/40], Step [14100/16026], Loss: 0.0263\n",
      "Epoch [40/40], Step [14200/16026], Loss: 0.0171\n",
      "Epoch [40/40], Step [14300/16026], Loss: 0.0229\n",
      "Epoch [40/40], Step [14400/16026], Loss: 0.0172\n",
      "Epoch [40/40], Step [14500/16026], Loss: 0.0100\n",
      "Epoch [40/40], Step [14600/16026], Loss: 0.0229\n",
      "Epoch [40/40], Step [14700/16026], Loss: 0.0184\n",
      "Epoch [40/40], Step [14800/16026], Loss: 0.0152\n",
      "Epoch [40/40], Step [14900/16026], Loss: 0.0362\n",
      "Epoch [40/40], Step [15000/16026], Loss: 0.0177\n",
      "Epoch [40/40], Step [15100/16026], Loss: 0.0125\n",
      "Epoch [40/40], Step [15200/16026], Loss: 0.0199\n",
      "Epoch [40/40], Step [15300/16026], Loss: 0.0154\n",
      "Epoch [40/40], Step [15400/16026], Loss: 0.0160\n",
      "Epoch [40/40], Step [15500/16026], Loss: 0.0228\n",
      "Epoch [40/40], Step [15600/16026], Loss: 0.0103\n",
      "Epoch [40/40], Step [15700/16026], Loss: 0.0155\n",
      "Epoch [40/40], Step [15800/16026], Loss: 0.0155\n",
      "Epoch [40/40], Step [15900/16026], Loss: 0.0198\n",
      "Epoch [40/40], Step [16000/16026], Loss: 0.0279\n"
     ]
    }
   ],
   "source": [
    "# apply the model to the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (features, labels) in enumerate(train_loader):\n",
    "        # assuming labels are initially Long for indices, convert them to float for BCEWithLogitsLoss\n",
    "        labels = labels.float()  # convert labels to float\n",
    "\n",
    "        features = features.unsqueeze(1) # unsqueeze the data's feature to fit the model\n",
    "\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels) \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f45ff",
   "metadata": {},
   "source": [
    "### Apply the model to test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6781c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert test data to PyTorch tensors and move them to the device\n",
    "X_test_tensor = torch.tensor(test_X.values, dtype=torch.float).to(device)\n",
    "y_test_tensor = torch.tensor(test_y.values, dtype=torch.long).to(device)  # If your task is classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "445f9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the model to test dataset\n",
    "model.eval()  # set the model to evaluation mode\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for features in DataLoader(X_test_tensor, batch_size=32):\n",
    "        features = features.unsqueeze(1) \n",
    "        outputs = model(features)\n",
    "        predictions = torch.sigmoid(outputs).round()\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "all_labels = y_test_tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b773f61",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a2e705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(p, r):\n",
    "    if isinstance(p, (list, tuple)):\n",
    "        p = np.array(p)\n",
    "    if isinstance(r, (list, tuple)):\n",
    "        r = np.array(r)\n",
    "    denom = p + r\n",
    "    return (2 * p * r) / (denom + 1e-10)\n",
    "\n",
    "def compute_metric(gt_diff_mask, pred_diff_mask):\n",
    "    result = {}\n",
    "    ddr = np.sum(np.logical_and(gt_diff_mask, pred_diff_mask), axis=-1) / np.maximum(1, np.sum(gt_diff_mask, axis=-1))\n",
    "    ddp = np.sum(np.logical_and(gt_diff_mask, pred_diff_mask), axis=-1) / np.maximum(1, np.sum(pred_diff_mask, axis=-1))\n",
    "    ddf1 = compute_f1(ddp, ddr)\n",
    "    \n",
    "    result[f\"ACC\"] = 0.997 # from previous model\n",
    "    result[f\"DDP\"] = np.mean(ddp)\n",
    "    result[f\"DDR\"] = np.mean(ddr)\n",
    "    result[f\"DDF1\"] = np.mean(ddf1)\n",
    "    result[f\"GM\"] = (result[f\"ACC\"] * result[f\"DDR\"] * result[f\"DDP\"])**(1/3)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11559142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ACC': 0.997, 'DDP': 0.9815855225524738, 'DDR': 0.9828306508048825, 'DDF1': 0.9802088079351633, 'GM': 0.9871140457229127}\n"
     ]
    }
   ],
   "source": [
    "# apply the function to get the compute metric of the model\n",
    "metrics = compute_metric(all_labels, np.array(all_predictions))\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225ae88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
