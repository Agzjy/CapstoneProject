{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data & network ...\n",
      "Start testing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timte\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\attention.cpp:152.)\n",
      "  return torch._native_multi_head_attention(\n",
      "c:\\Users\\timte\\.conda\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "from network import Network\n",
    "from dataset import load_dataset\n",
    "from utils import mean, evaluate_ddx, evaluate_cls\n",
    "\n",
    "batch_size = 64\n",
    "vocab_size = 531\n",
    "en_seq_len = 80\n",
    "de_seq_len = 40\n",
    "features = 128\n",
    "heads = 4\n",
    "layers = 6\n",
    "output_size = 54\n",
    "drop_rate = 0.1\n",
    "\n",
    "print('Loading data & network ...')\n",
    "_, test_loader = load_dataset(batch_size=batch_size, num_workers=0)\n",
    "\n",
    "network = Network(vocab_size=vocab_size,\n",
    "                  en_seq_len=en_seq_len,\n",
    "                  de_seq_len=de_seq_len,\n",
    "                  features=features,\n",
    "                  heads=heads,\n",
    "                  n_layer=layers,\n",
    "                  output_size=output_size,\n",
    "                  dropout_rate=drop_rate).cuda()\n",
    "\n",
    "network.load_state_dict(torch.load('./weights/model_3.h5'))\n",
    "\n",
    "print('Start testing ...')\n",
    "\n",
    "# test\n",
    "network.eval()\n",
    "test_acc_ddx, test_acc_cls = [], []\n",
    "tic = time.time()\n",
    "\n",
    "np_true_ddx = []\n",
    "np_pred_ddx = []\n",
    "\n",
    "np_true_cls = []\n",
    "np_pred_cls = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for n, (en_in, de_in, de_out, path) in enumerate(test_loader):\n",
    "        en_in, de_in, de_out, path = en_in.cuda(), de_in.cuda(), de_out.cuda(), path.cuda()\n",
    "        # de_out = one_hot(de_out, output_size)\n",
    "\n",
    "        # forward\n",
    "        de_out_pred, path_pred = network(en_input=en_in, de_input=de_in)\n",
    "\n",
    "        # store\n",
    "        np_true_ddx.append(de_out.detach().cpu().numpy())\n",
    "        np_pred_ddx.append(torch.argmax(de_out_pred, dim=-1).detach().cpu().numpy())\n",
    "        np_true_cls.append(path.detach().cpu().numpy())\n",
    "        np_pred_cls.append(torch.argmax(path_pred, dim=-1).detach().cpu().numpy())\n",
    "\n",
    "        # evaluate\n",
    "        ddx_acc = evaluate_ddx(true=de_out, pred=de_out_pred)\n",
    "        cls_acc = evaluate_cls(true=path, pred=path_pred)\n",
    "        test_acc_ddx.append(ddx_acc.item())\n",
    "        test_acc_cls.append(cls_acc.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "pred_array = np.zeros((len(np_pred_ddx) * len(np_pred_ddx[0]), 49))\n",
    "true_array = np.zeros((len(np_pred_ddx) * len(np_pred_ddx[0]), 49))\n",
    "for n, (batch, t_batch) in enumerate(zip(np_pred_ddx, np_true_ddx)):\n",
    "    for m, (pred, g_true) in enumerate(zip(batch, t_batch)):\n",
    "        pred_list = (pred[pred > 4] - 5).tolist()\n",
    "        pred_array[n*64 + m + 1, pred_list] = 1\n",
    "        true_list = (g_true[g_true > 4] - 5).tolist()\n",
    "        true_array[n*64 + m + 1, true_list] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric_utils import compute_metric\n",
    "\n",
    "result = compute_metric(true_array.astype(bool), pred_array.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ACC': 0.997,\n",
       " 'DDR': 0.9502523651778649,\n",
       " 'DDP': 0.9808009051315227,\n",
       " 'DDF1': 0.9628743745408825,\n",
       " 'GM': 0.9758243669151401}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3c06e3e46abf38078fe4dac36a0085ec2b134ebbd73dd076183d243eeca6918f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
