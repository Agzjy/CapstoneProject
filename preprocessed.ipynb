{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import scipy.stats as stats\n",
        "from sklearn import preprocessing\n",
        "%matplotlib inline\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SequentialFeatureSelector as sfs\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from scipy import stats\n",
        "from scipy.stats import linregress"
      ],
      "metadata": {
        "id": "jR13h9bd4fiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import dataset\n",
        "train = pd.read_csv('~/Desktop/trainProcessed.csv')\n",
        "validate = pd.read_csv('~/Desktop/validateProcessed.csv')\n",
        "test = pd.read_csv('~/Desktop/testProcessed.csv')"
      ],
      "metadata": {
        "id": "UQ4XnwMk4ffe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "pathology_dict = json.load(open('/content/drive/MyDrive/release_conditions.json', 'r'))\n",
        "evidences_dict = json.load(open('/content/drive/MyDrive/release_evidences.json', 'r'))"
      ],
      "metadata": {
        "id": "vQsUgiNy4fYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_typo(df):\n",
        "    for n, i in df.iterrows():\n",
        "        if i['PATHOLOGY'] not in pathology_dict.keys():\n",
        "            print(f\"{n} has a typo in pathology: {i['PATHOLOGY']}\")\n",
        "            df.drop[n]\n",
        "        for evidence in i['EVIDENCES']:\n",
        "            evidence_split = evidence.split('_@_')\n",
        "            question = evidence_split[0]\n",
        "            if question not in evidences_dict.keys():\n",
        "                print(f'{n} has a typo in question: {evidence}')\n",
        "                df.drop[n]\n",
        "                continue\n",
        "            if len(evidence_split) > 1:\n",
        "                value = evidence_split[1]\n",
        "                if value not in evidences_dict[question][\"possible-values\"] \\\n",
        "                    and value not in [str(e) for e in evidences_dict[question][\"possible-values\"]]:\n",
        "                    print(f'{n} has a typo in value: {evidence}')\n",
        "                    df.drop[n]"
      ],
      "metadata": {
        "id": "bbIZB8Td4rJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(df):\n",
        "    unique_items = set(item for sublist in df['EVIDENCES'] for item in sublist)\n",
        "    encoded_evidence = pd.DataFrame(0, index=df.index, columns=list(unique_items))\n",
        "    for item in unique_items:\n",
        "        encoded_evidence[item] = df['EVIDENCES'].apply(lambda x: item in x)\n",
        "    return encoded_evidence.astype(int)"
      ],
      "metadata": {
        "id": "gyrS7qaJ4tS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def readingData(df):\n",
        "  # Get an overview of data\n",
        "  print(\"DataFrame shape: \"+str(df.shape))\n",
        "\n",
        "  # Deal with Nan value and Duplicate\n",
        "  print(df.isna().sum())\n",
        "  df.dropna()\n",
        "  print('Total Duplicate: '+str(df.duplicated().sum()))\n",
        "  df.drop_duplicates()\n",
        "\n",
        "  # Turn variable \"EVIDENCES\" from string to list\n",
        "  evidences = []\n",
        "  for evidence_row in df['EVIDENCES']:\n",
        "    evidences.append([evidence.strip(\" ''\") for evidence in evidence_row.strip(\"[]\").split(\",\") ])\n",
        "  df['EVIDENCES'] = evidences\n",
        "\n",
        "  # Drop Outlier\n",
        "  df = df[(df['AGE'] <= 120) & (df['AGE'] >= 0)]\n",
        "\n",
        "  # Check Typo\n",
        "  check_typo(df)\n",
        "\n",
        "  # Data Encoding\n",
        "  df['SEX'] = df['SEX'].map({'M': 0, 'F': 1})\n",
        "  encoded_df = one_hot_encode(df)\n",
        "  df = df.drop('EVIDENCES', axis=1).join(encoded_df)\n",
        "  print(df.head())\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "DQ1KdgKU4vFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train=readingData(train)\n",
        "validate=readingData(validate)\n",
        "test=readingData(test)"
      ],
      "metadata": {
        "id": "z9XyB_YA4vAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_columns = pd.Series(list(train.columns) + list(validate.columns) + list(test.columns)).drop_duplicates()\n",
        "train = train.reindex(columns=all_columns, fill_value=0)\n",
        "validate = validate.reindex(columns=all_columns, fill_value=0)\n",
        "test = test.reindex(columns=all_columns, fill_value=0)"
      ],
      "metadata": {
        "id": "kCK-TnRP44GU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}